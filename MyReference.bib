
@inproceedings{anDCStoreDeduplicationBasedCloudofClouds2019,
  title = {{{DCStore}}: {{A Deduplication-Based Cloud-of-Clouds Storage Service}}},
  shorttitle = {{{DCStore}}},
  booktitle = {2019 {{IEEE International Conference}} on {{Web Services}} ({{ICWS}})},
  author = {An, Bo and Li, Yan and Ma, Junming and Huang, Gang and Chen, Xiangqun and Cao, Donggang},
  year = {2019},
  month = jul,
  pages = {291--295},
  publisher = {{IEEE}},
  address = {{Milan, Italy}},
  doi = {10.1109/icws.2019.00056},
  isbn = {978-1-72812-717-0},
  keywords = {可看🎈},
  file = {F\:\\Zotero文献数据\\storage\\E4UCIKDM\\An et al_2019_DCStore.pdf}
}
% == BibTeX quality report for anDCStoreDeduplicationBasedCloudofClouds2019:
% ? Unsure about the formatting of the booktitle
% ? Title looks like it was stored in title-case in Zotero
% ? unused Library catalog ("DOI.org (Crossref)")
% ? unused Url ("https://ieeexplore.ieee.org/document/8818404/")

@article{aoJiYuJuanJiShenJingWangLuoDeFuZhuFenAnFangFaYanJiu,
  title = {{基于卷积神经网络的辅助分案方法研究}},
  author = {敖, 绍林 and 秦, 永彬 and 黄, 瑞章 and 陈, 艳平 and 刘, 丽娟 and 郑, 庆华 and 陈, 昌恒 and 程, 少芬},
  journal = {大数据},
  pages = {1--16},
  issn = {2096-0271},
  abstract = {分案是指法院受理的案件在具体法官之间的分配。法院系统中主要有人工指定分案和简单随机分案两种模式。无法做到人案的自动匹配，存在金钱案、关系案等弊端。目前分案方法的相关研究主要存在法官表示和案件匹配两个困难。结合法官历史审判数据，在法官 表示中融合法官擅长的审判领域，提出一种融合审判质量的法官表示方法。然后，通过卷积神经网络(CNN)学习案件表示和法官表示中不同粒度的抽象语义特征向量，计算案件和多个法官的特征向量间的余弦相似度，以向量相似度表示案件与法官的匹配度，输出前N个匹配值高的法官作为为案件的推荐法官。在贵州省某法院真实数据下进行实验，结果表明，该方法推荐法官的精准度比传统方法高80\%。},
  langid = {chinese},
  keywords = {convolutional neural network,smart court,smart division,text representation,中文🌈,卷积神经网络,文本表示,智慧法院,智能分案},
  file = {F\:\\Zotero文献数据\\storage\\2G4WEN2M\\敖 et al_基于卷积神经网络的辅助分案方法研究.pdf}
}
% == BibTeX quality report for aoJiYuJuanJiShenJingWangLuoDeFuZhuFenAnFangFaYanJiu:
% Missing required field 'year'
% ? unused Library catalog ("CNKI")
% ? unused Url ("https://t.cnki.net/kcms/detail?v=2RSegAH8zSppJxUbQguIQdy3Wb3OsFebDg7jTiy-xK3sEf0uaAF0-3oH6emQd0AzUL_pxVr6rT2EIykrK6VqFlzeraZ4FYx09a7KE1I6vJtYTrLk4fycUw==&uniplatform=NZKPT")

@article{arslanDataAssistedReliabilityModel2020,
  title = {A {{Data-Assisted Reliability Model}} for {{Carrier-Assisted Cold Data Storage Systems}}},
  author = {Arslan, Suayb S. and Peng, James and Goker, Turguy},
  year = {2020},
  month = apr,
  journal = {Reliability Engineering \& System Safety},
  volume = {196},
  eprint = {1911.00329},
  eprinttype = {arxiv},
  pages = {106708},
  issn = {09518320},
  doi = {10.1016/j.ress.2019.106708},
  abstract = {Cold data storage systems are used to allow long term digital preservation for institutions' archives. The common functionality among cold and warm/hot data storage is that the data is stored on some physical medium for read-back at a later time. However in cold storage, write and read operations are not necessarily done in the same exact geographical location. Hence, a third party assistance is typically utilized to bring together the medium and the drive. On the other hand, the reliability modeling of such a decomposed system poses few challenges that do not necessarily exist in other warm/hot storage alternatives such as fault detection and absence of the carrier, all totaling up to the data unavailability issues. In this paper, we propose a generalized non-homogenous Markov model that encompasses the aging of the carriers in order to address the requirements of today's cold data storage systems in which the data is encoded and spread across multiple nodes for the long-term data retention. We have derived useful lower/upper bounds on the overall system availability. Furthermore, the collected field data is used to estimate parameters of a Weibull distribution to accurately predict the lifetime of the carriers in an example scale-out setting. In this study, we numerically demonstrate the significance of carriers' presence and the key role that their timely maintenance plays on the long-term reliability and availability of the stored content.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Performance},
  file = {F\:\\Zotero文献数据\\storage\\7U8TMKIW\\Arslan et al_2020_A Data-Assisted Reliability Model for Carrier-Assisted Cold Data Storage Systems.pdf;F\:\\Zotero文献数据\\storage\\RJ5RERPR\\1911.html}
}
% == BibTeX quality report for arslanDataAssistedReliabilityModel2020:
% ? Title looks like it was stored in title-case in Zotero
% ? unused Url ("http://arxiv.org/abs/1911.00329")

@inproceedings{baiFastRecoveryTechniques2019,
  title = {Fast {{Recovery Techniques}} for {{Erasure-coded Clusters}} in {{Non-uniform Traffic Network}}},
  booktitle = {Proceedings of the 48th {{International Conference}} on {{Parallel Processing}}},
  author = {Bai, Yunren and Xu, Zihan and Wang, Haixia and Wang, Dongsheng},
  year = {2019},
  month = aug,
  pages = {1--10},
  publisher = {{ACM}},
  address = {{Kyoto Japan}},
  doi = {10/gjrjsp},
  abstract = {Nowadays many practical systems adopt erasure codes to ensure reliability and reduce storage overhead. However, erasure codes also bring in low recovery performance. The network links in practice, such as peer-to-peer and cross-data network, always have nonuniform bandwidth because of various reasons. To reduce recovery time, we propose Parallel Pipeline Tree (PPT) and Parallel Pipeline Cross-Tree (PPCT) to speed up single-node and multiple-node recovery in non-uniform tra\dbend c network environment, respectively. By utilizing bandwidth gap among links, PPT constructs a tree path based on bandwidth and pipelines the data in parallel. By sharing tra\dbend c pressure of requesters with helpers, PPCT constructs a tree-like path and pipelines the data in parallel without additional helpers. We also theoretically explain the e\dbend ect of PPT and PPCT used in uniform network environment. The experiments implemented on geo-distributed Amazon EC2 show that the time reduction reaches up to 37.2\% with PPCT over traditional technique and reaches up to 89.2\%, 76.4\% and 21.6\% with PPT over traditional technique, Partial-Parallel-Repair and Repair Pipelining, respectively. PPT and PPCT signi\dbend cantly improve the performance of erasure codes' recovery.},
  isbn = {978-1-4503-6295-5},
  langid = {english},
  keywords = {Reading🌟,可看🎈},
  file = {F\:\\Zotero文献数据\\storage\\L9FA7Q3X\\Bai et al_2019_Fast Recovery Techniques for Erasure-coded Clusters in Non-uniform Traffic.pdf}
}
% == BibTeX quality report for baiFastRecoveryTechniques2019:
% ? unused Conference name ("ICPP 2019: 48th International Conference on Parallel Processing")
% ? unused Library catalog ("DOI.org (Crossref)")
% ? unused Url ("https://dl.acm.org/doi/10.1145/3337821.3337831")

@article{balajiErasureCodingDistributed2018,
  title = {Erasure Coding for Distributed Storage: An Overview},
  shorttitle = {Erasure Coding for Distributed Storage},
  author = {Balaji, S. B. and Krishnan, M. Nikhil and Vajha, Myna and Ramkumar, Vinayak and Sasidharan, Birenjith and Kumar, P. Vijay},
  year = {2018},
  month = oct,
  journal = {Science China Information Sciences},
  volume = {61},
  number = {10},
  pages = {100301},
  issn = {1674-733X, 1869-1919},
  doi = {10/gjrd9z},
  abstract = {In a distributed storage system, code symbols are dispersed across space in nodes or storage units as opposed to time. In settings such as that of a large data center, an important consideration is the efficient repair of a failed node. Efficient repair calls for erasure codes that in the face of node failure, are efficient in terms of minimizing the amount of repair data transferred over the network, the amount of data accessed at a helper node as well as the number of helper nodes contacted. Coding theory has evolved to handle these challenges by introducing two new classes of erasure codes, namely regenerating codes and locally recoverable codes as well as by coming up with novel ways to repair the ubiquitous Reed-Solomon code. This survey provides an overview of the efforts in this direction that have taken place over the past decade.},
  langid = {english},
  keywords = {可看🎈},
  annotation = {00046},
  file = {F\:\\Zotero文献数据\\storage\\RVKSMUM8\\Balaji et al_2018_Erasure coding for distributed storage.pdf}
}
% == BibTeX quality report for balajiErasureCodingDistributed2018:
% ? unused Journal abbreviation ("Sci. China Inf. Sci.")
% ? unused Library catalog ("DOI.org (Crossref)")
% ? unused Url ("http://link.springer.com/10.1007/s11432-018-9482-6")

@article{balajiErasureCodingDistributed2018a,
  title = {Erasure Coding for Distributed Storage: An Overview},
  shorttitle = {Erasure Coding for Distributed Storage},
  author = {Balaji, S. B. and Krishnan, M. Nikhil and Vajha, Myna and Ramkumar, Vinayak and Sasidharan, Birenjith and Kumar, P. Vijay},
  year = {2018},
  month = oct,
  journal = {Science China Information Sciences},
  volume = {61},
  number = {10},
  pages = {100301},
  issn = {1674-733X, 1869-1919},
  doi = {10.1007/s11432-018-9482-6},
  abstract = {In a distributed storage system, code symbols are dispersed across space in nodes or storage units as opposed to time. In settings such as that of a large data center, an important consideration is the efficient repair of a failed node. Efficient repair calls for erasure codes that in the face of node failure, are efficient in terms of minimizing the amount of repair data transferred over the network, the amount of data accessed at a helper node as well as the number of helper nodes contacted. Coding theory has evolved to handle these challenges by introducing two new classes of erasure codes, namely regenerating codes and locally recoverable codes as well as by coming up with novel ways to repair the ubiquitous Reed-Solomon code. This survey provides an overview of the efforts in this direction that have taken place over the past decade.},
  langid = {english},
  keywords = {可看🎈},
  file = {F\:\\Zotero文献数据\\storage\\V5TSQBQP\\Balaji 等。 - 2018 - Erasure coding for distributed storage an overvie.pdf}
}
% == BibTeX quality report for balajiErasureCodingDistributed2018a:
% ? unused Journal abbreviation ("Sci. China Inf. Sci.")
% ? unused Library catalog ("DOI.org (Crossref)")
% ? unused Url ("http://link.springer.com/10.1007/s11432-018-9482-6")

@article{baoReducingNetworkCost2020,
  title = {Reducing Network Cost of Data Repair in Erasure-Coded Cross-Datacenter Storage},
  author = {Bao, Han and Wang, Yijie and Xu, Fangliang},
  year = {2020},
  month = jan,
  journal = {Future Generation Computer Systems},
  volume = {102},
  pages = {494--506},
  issn = {0167-739X},
  doi = {10.1016/j.future.2019.08.027},
  abstract = {Nowadays, cross-datacenter storage is widely used because of its high disaster-tolerance. Moreover, the erasure code is gradually being applied to cross-datacenter storage since it offers the same reliability as replication with a significant decrease in the amount of storage required. However, the network cost of repairing erasure-coded data in existing cross-datacenter storage (repair cost of cross-datacenter erasure code) is high, which usually results in a long repair time. To reduce the repair time by reducing the repair cost, in this paper, we study both the encoding method and repair method of cross-datacenter erasure code. First, we propose the concept of average weighted locality, which is proportional to the average repair cost of cross-datacenter erasure code. Then, we propose a network environment-adaptive encoding method of cross-datacenter erasure code (NEC). Under different network environments and encoding parameters, NEC can compute the approximate optimal generator matrix and data placement scheme online in a parallel heuristic way to achieve the approximate smallest average weighted locality. After that, we propose a hybrid-structured repair method of cross-datacenter erasure code (HRepair), which can achieve a good tradeoff between repair cost and repair efficiency by constructing a hybrid tree-star transmission topology to organize data transmission in the repair process. Experiments show that: Compared with several state-of-the-art erasure codes, NEC can reduce the repair cost and repair time by 26.8\%\textendash 40\% and 13.9\%-37.1\%. Besides, HRepair can reduce repair cost and repair time further.},
  langid = {english},
  keywords = {Cross-datacenter storage,Erasure code,Fault-tolerance,Locality},
  file = {F\:\\Zotero文献数据\\storage\\DH2U2Z59\\Bao et al_2020_Reducing network cost of data repair in erasure-coded cross-datacenter storage.pdf;F\:\\Zotero文献数据\\storage\\6DA4C3ZX\\S0167739X19311422.html;F\:\\Zotero文献数据\\storage\\CSEUYBL9\\S0167739X19311422.html}
}
% == BibTeX quality report for baoReducingNetworkCost2020:
% ? unused Library catalog ("ScienceDirect")
% ? unused Url ("http://www.sciencedirect.com/science/article/pii/S0167739X19311422")

@article{caoPopularityawareReconstructionTechnique2020,
  title = {A Popularity-Aware Reconstruction Technique in Erasure-Coded Storage Systems},
  author = {Cao, Ting and Peng, Xiaopu and Zhang, Chaowei and Tekreeti, Taha Khalid Al and Mao, Jianzhou and Qin, Xiao and Huang, Jianzhong},
  year = {2020},
  month = dec,
  journal = {Journal of Parallel and Distributed Computing},
  volume = {146},
  pages = {122--138},
  issn = {0743-7315},
  doi = {10.1016/j.jpdc.2020.08.003},
  abstract = {In this study, we develop a novel data reconstruction technique for parallel storage systems housed in modern data centers. We advocate for erasure-coded data storage systems to archive warm data (a.k.a., unpopular data), which attract a limited number of accesses or updates. Different from hot or cold data, warm data have to be treated in a distinctive way to optimize system performance and storage-space utilization. We pay particular attention to efficient data reconstruction in which faulty data nodes are rebuilt while responding to I/O requests. To achieve this goal, we employ two machine-learning algorithms to offer online data reconstruction in erasure coded storage systems. Our data reconstruction technique is conducive to recovering faulty nodes while boosting read performance for requests accessing data residing on the faulty nodes. Our system is reliant on a clustering mechanism to group files into multiple clusters, in each of which files share similar features. Furthermore, we implement a prediction module where a list of future popular data is projected by keeping track of historical I/O accesses. This popular-data list, in turn, provides predictions on files that are likely to be accessed in the not-too-distant future. The prediction module is responsible for computing similarities among users, thereby setting up priority levels of data blocks to be reconstructed. We implement our data reconstruction scheme in an erasure-coded parallel storage system to recover files with a guidance from the popular-data list. Our experimental results confirm that our system speeds up the data recovery of parallel storage systems while maintaining a high data access performance for on-line users.},
  langid = {english},
  keywords = {Aware♥️,Clustering,Erasure-coded data storage,Online reconstruction,Popularity awareness,Reading🌟,Warm data,可看🎈},
  file = {F\:\\Zotero文献数据\\storage\\RLUS36QG\\Cao et al_2020_A popularity-aware reconstruction technique in erasure-coded storage systems.pdf;F\:\\Zotero文献数据\\storage\\6M8LLLUI\\S0743731520303439.html;F\:\\Zotero文献数据\\storage\\GLXZ6PI3\\S0743731520303439.html}
}
% == BibTeX quality report for caoPopularityawareReconstructionTechnique2020:
% ? unused Library catalog ("ScienceDirect")
% ? unused Url ("http://www.sciencedirect.com/science/article/pii/S0743731520303439")

@article{cengRongQiYunZhongJiYuStackelbergBoYiDeDongTaiYiGouDiaoDuFangFa2021,
  title = {{容器云中基于Stackelberg博弈的动态异构调度方法}},
  author = {曾, 威 and 扈, 红超 and 李, 凌书 and 霍, 树民},
  year = {2021},
  journal = {网络与信息安全学报},
  volume = {7},
  number = {03},
  pages = {95--104},
  issn = {2096-109X},
  abstract = {容器技术以其灵活、高效的特性促进了云计算的快速发展,但同时引入了如同驻攻击、逃逸攻击和共模攻击等安全威胁。针对这些安全威胁,提出一种容器云中基于Stackelberg博弈的动态异构式调度方法。首先,构建异构镜像资源池以抑制云上基于共模漏洞的攻击扩散;进而,将攻防交互过程建模为Stackelberg博弈模型;最后,对攻防模型进行分析,将系统调度问题建模为混合整数非线性规划问题以求解系统最优调度策略。实验证明,所提方法能够提升云平台的防御效果,降低系统防御开销。},
  langid = {chinese},
  keywords = {container scheduling,moving target defense,Stackelberg game,Stackelberg博弈,中文🌈,云安全,容器调度,移动目标防御 cloud security},
  file = {F\:\\Zotero文献数据\\storage\\7F5T7MSJ\\曾 et al_2021_容器云中基于Stackelberg博弈的动态异构调度方法.pdf}
}
% == BibTeX quality report for cengRongQiYunZhongJiYuStackelbergBoYiDeDongTaiYiGouDiaoDuFangFa2021:
% ? unused Library catalog ("CNKI")
% ? unused Url ("https://kns.cnki.net/KCMS/detail/detail.aspx?dbcode=CJFD&dbname=CJFDLAST2021&filename=WXAQ202103008&v=")

@article{chouhanInvestigationOptimalData2020,
  title = {Investigation of {{Optimal Data Encoding Parameters Based}} on {{User Preference}} for {{Cloud Storage}}},
  author = {Chouhan, Vikas and Peddoju, Sateesh K.},
  year = {2020},
  journal = {IEEE Access},
  volume = {8},
  pages = {75105--75118},
  issn = {2169-3536},
  doi = {10/gkdtmq},
  keywords = {Reading🌟},
  annotation = {00001},
  file = {F\:\\Zotero文献数据\\storage\\UP5VUYWN\\Chouhan_Peddoju_2020_Investigation of Optimal Data Encoding Parameters Based on User Preference for.pdf}
}
% == BibTeX quality report for chouhanInvestigationOptimalData2020:
% ? Title looks like it was stored in title-case in Zotero
% ? unused Library catalog ("DOI.org (Crossref)")
% ? unused Url ("https://ieeexplore.ieee.org/document/9067840/")


% == BibTeX quality report for ford2010availability:
% ? Unsure about the formatting of the booktitle

@article{fordAvailabilityGloballyDistributed,
  title = {Availability in {{Globally Distributed Storage Systems}}},
  author = {Ford, Daniel and Labelle, Francois and Popovici, Florentina I and Stokely, Murray and Truong, Van-Anh and Barroso, Luiz and Grimes, Carrie and Quinlan, Sean},
  pages = {14},
  abstract = {Highly available cloud storage is often implemented with complex, multi-tiered distributed systems built on top of clusters of commodity servers and disk drives. Sophisticated management, load balancing and recovery techniques are needed to achieve high performance and availability amidst an abundance of failure sources that include software, hardware, network connectivity, and power issues. While there is a relative wealth of failure studies of individual components of storage systems, such as disk drives, relatively little has been reported so far on the overall availability behavior of large cloudbased storage services.},
  langid = {english},
  file = {F\:\\Zotero文献数据\\storage\\QX753F58\\Ford 等。 - Availability in Globally Distributed Storage Syste.pdf}
}
% == BibTeX quality report for fordAvailabilityGloballyDistributed:
% Missing required field 'journal'
% Missing required field 'year'
% ? Title looks like it was stored in title-case in Zotero
% ? unused Library catalog ("Zotero")

@article{fukataniLightweightDynamicRedundancy2019,
  title = {Lightweight Dynamic Redundancy Control for Server-Based Storage},
  author = {Fukatani, Takayuki and Hanh Le, Hieu and Yokota, Haruo},
  year = {2019},
  journal = {Proceedings of the IEEE Symposium on Reliable Distributed Systems},
  pages = {295--304},
  publisher = {{IEEE}},
  issn = {10609857},
  doi = {10.1109/SRDS47363.2019.00042},
  abstract = {The recent performance improvements in commodity hardware have made commodity server-based storage a practical alternative to dedicated-storage appliances. Because of the low reliability of commodity servers, data redundancy across multiple servers is required for high availability of a server-based storage system. However, the extra storage capacity required to enable this redundancy increases the system cost significantly. Although erasure coding (EC) is a promising approach to reducing the amount of redundant data, it is only available in systems using distributed storage. There remains the need to reduce the performance overhead of using distributed storage, which involves much network traffic and metadata processing. In this paper, we propose a lightweight redundancy-control method called 'dynamic redundancy control' for server-based storage systems. Our method adds additional file metadata for EC to the local filesystem, enabling the system to take advantage of EC with reduced network traffic and metadata processing. In addition, our method dynamically controls the data redundancy in user data between replication and EC to improve the capacity efficiency while mitigating performance degradation. Our experiments show that our method achieves up to 76\% less processing time for a metadata-intensive workload, up to 150\% higher read performance, and up to 147\% better online-transaction-processing performance than CephFS, a widely used alternative system. In addition, our method successfully improves capacity efficiency while mitigating performance degradation.},
  isbn = {0769567118},
  keywords = {AdaptiveCode🌏,Data redundancy,Erasure code,Python🐍,Reading🌟,Replication,Storage,可看🎈},
  file = {F\:\\Zotero文献数据\\storage\\BZ57MTU8\\Fukatani et al_2019_Lightweight dynamic redundancy control for server-based storage.pdf}
}

@article{fuSimulationAnalysisRedundancy2018,
  title = {A {{Simulation Analysis}} of {{Redundancy}} and {{Reliability}} in {{Primary Storage Deduplication}}},
  author = {Fu, Min and Han, Shujie and Lee, Patrick P.C. and Feng, Dan and Chen, Zuoning and Xiao, Yu},
  year = {2018},
  journal = {IEEE Transactions on Computers},
  volume = {67},
  number = {9},
  pages = {1259--1272},
  issn = {00189340},
  doi = {10.1109/TC.2018.2808496},
  abstract = {Deduplication has been widely used to improve storage efficiency in modern primary and secondary storage systems, yet how deduplication fundamentally affects storage system reliability remains debatable. This paper aims to analyze and compare storage system reliability with and without deduplication in primary workloads using public file system snapshots from two research groups. We first study the redundancy characteristics of the file system snapshots. We then propose a trace-driven, deduplication-aware simulation framework to analyze data loss in both chunk and file levels due to sector errors and whole-disk failures. Compared to without deduplication, our analysis shows that deduplication consistently reduces the damage of sector errors due to intra-file redundancy elimination, but potentially increases the damages of whole-disk failures if the highly referenced chunks are not carefully placed on disk. To improve reliability, we examine a deliberate copy technique that stores and repairs first the most referenced chunks in a small dedicated physical area (e.g., 1 percent of the physical capacity), and demonstrate its effectiveness through our simulation framework.},
  keywords = {CUHK📕,Deduplication,experiments and implementation,primary storage systems,Reading🌟,reliability},
  file = {F\:\\Zotero文献数据\\storage\\W7NML5N7\\Fu et al_2018_A Simulation Analysis of Redundancy and Reliability in Primary Storage.pdf}
}
% == BibTeX quality report for fuSimulationAnalysisRedundancy2018:
% ? Title looks like it was stored in title-case in Zotero

@article{gandelmanTreeplicationErasureCode2020,
  title = {Treeplication: {{An Erasure Code}} for {{Distributed Full Recovery}} under the {{Random Multiset Channel}}},
  shorttitle = {Treeplication},
  author = {Gandelman, Michael and Cassuto, Yuval},
  year = {2020},
  month = feb,
  journal = {arXiv:2002.09895 [cs, math]},
  eprint = {2002.09895},
  eprinttype = {arxiv},
  primaryclass = {cs, math},
  abstract = {This paper presents a new erasure code called Treeplication designed for distributed recovery of the full information word, while most prior work in coding for distributed storage only supports distributed repair of individual symbols. A Treeplication code for \$k\$ information symbols is defined on a binary tree with \$2k-1\$ vertices, along with a distribution for selecting code symbols from the tree layers. We analyze and optimize the code under a random-multiset model, which captures the system property that the nodes available for recovery are drawn randomly from the nodes storing the code symbols. Treeplication codes are shown to have full-recovery communication-cost comparable to replication, while offering much better recoverability.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Information Theory,Reading🌟,可看🎈},
  file = {F\:\\Zotero文献数据\\storage\\NRJLJU2Z\\Gandelman_Cassuto_2020_Treeplication.pdf;F\:\\Zotero文献数据\\storage\\F78IJXG8\\2002.html}
}
% == BibTeX quality report for gandelmanTreeplicationErasureCode2020:
% ? Possibly abbreviated journal title arXiv:2002.09895 [cs, math]
% ? Title looks like it was stored in title-case in Zotero
% ? unused Url ("http://arxiv.org/abs/2002.09895")

@article{haiWangLuoGongNengXuNiHuaHuanJingZhongDaGuiMoZiYuanZhuangTaiJianCeCeLue2019,
  title = {{网络功能虚拟化环境中大规模资源状态监测策略}},
  author = {海, 梅生 and 伊, 鹏 and 江, 逸茗 and 谢, 记超},
  year = {2019},
  journal = {网络与信息安全学报},
  volume = {5},
  number = {06},
  pages = {42--49},
  issn = {2096-109X},
  abstract = {在网络功能虚拟化(NFV)环境中,为了提高网络中基础设施资源利用率,高效动态部署服务功能链,编排管理域需要对网络中底层资源及虚拟网络功能状态进行实时监测,但实时监测会产生大量通信开销。提出了网络通信开销最小化的智能分布式监测策略,通过改进的标签传播算法智能划分子网并选择代理监测节点,实现了对资源和虚拟功能状态的高效监测,并使监测信息通信开销最小。仿真结果表明,所提监测策略使网络中监测信息通信开销降低约13\%。},
  langid = {chinese},
  keywords = {agent node,communication overhead,monitoring,中文🌈,代理节点 network function virtualization,监测,网络与信息安全学报🌊,网络功能虚拟化,通信开销},
  annotation = {1 citations(CNKI)[2021-07-19]},
  file = {F\:\\Zotero文献数据\\storage\\IHLYWGS2\\海 et al_2019_网络功能虚拟化环境中大规模资源状态监测策略.pdf}
}
% == BibTeX quality report for haiWangLuoGongNengXuNiHuaHuanJingZhongDaGuiMoZiYuanZhuangTaiJianCeCeLue2019:
% ? unused Library catalog ("CNKI")
% ? unused Url ("https://kns.cnki.net/KCMS/detail/detail.aspx?dbcode=CJFD&dbname=CJFDLAST2019&filename=WXAQ201906005&v=")

@inproceedings{hanAdaptiveDiskFailure2020,
  title = {Toward {{Adaptive Disk Failure Prediction}} via {{Stream Mining}}},
  booktitle = {2020 {{IEEE}} 40th {{International Conference}} on {{Distributed Computing Systems}} ({{ICDCS}})},
  author = {Han, Shujie and Lee, Patrick P. C. and Shen, Zhirong and He, Cheng and Liu, Yi and Huang, Tao},
  year = {2020},
  month = nov,
  pages = {628--638},
  publisher = {{IEEE}},
  address = {{Singapore, Singapore}},
  doi = {10.1109/ICDCS47774.2020.00044},
  isbn = {978-1-72817-002-2},
  keywords = {CUHK📕,可看🎈},
  file = {F\:\\Zotero文献数据\\storage\\XXESPULH\\icdcs20.pdf}
}
% == BibTeX quality report for hanAdaptiveDiskFailure2020:
% ? Unsure about the formatting of the booktitle
% ? Title looks like it was stored in title-case in Zotero
% ? unused Library catalog ("DOI.org (Crossref)")
% ? unused Url ("https://ieeexplore.ieee.org/document/9355640/")

@article{huExploitingCombinedLocality,
  title = {Exploiting {{Combined Locality}} for {{Wide-Stripe Erasure Coding}} in {{Distributed Storage}}},
  author = {Hu, Yuchong and Cheng, Liangfeng and Yao, Qiaori and Lee, Patrick P C and Wang, Weichun and Chen, Wei},
  pages = {17},
  abstract = {Erasure coding is a low-cost redundancy mechanism for distributed storage systems by storing stripes of data and parity chunks. Wide stripes are recently proposed to suppress the fraction of parity chunks in a stripe to achieve extreme storage savings. However, wide stripes aggravate the repair penalty, while existing repair-efficient approaches for erasure coding cannot effectively address wide stripes. In this paper, we propose combined locality, the first mechanism that systematically addresses the wide-stripe repair problem via the combination of both parity locality and topology locality. We further augment combined locality with efficient encoding and update schemes. Experiments on Amazon EC2 show that combined locality reduces the single-chunk repair time by up to 90.5\% compared to locality-based state-of-the-arts, with only a redundancy of as low as 1.063\texttimes.},
  langid = {english},
  keywords = {⛔ No DOI found,可看🎈},
  file = {F\:\\Zotero文献数据\\storage\\PVC8IALL\\Hu 等。 - Exploiting Combined Locality for Wide-Stripe Erasu.pdf}
}
% == BibTeX quality report for huExploitingCombinedLocality:
% Missing required field 'journal'
% Missing required field 'year'
% ? Title looks like it was stored in title-case in Zotero
% ? unused Library catalog ("Zotero")

@phdthesis{jiangFenBuShiCunChuZhongJiuShanMaLiuShuiXianXiuFuJiShuDeYanJiu2020,
  type = {{硕士}},
  title = {{分布式存储中纠删码流水线修复技术的研究}},
  author = {江, 小玉},
  year = {2020},
  abstract = {随着区块链、机器学习、人工智能等前沿科技的发展,每天都会产生海量的数据,如何存储及处理这些数据成为大数据研究领域的热点。分布式存储可以实现大规模的存储需求,但系统中的节点时常出现故障而导致存储数据丢失。为了保证数据的安全性和可靠性,选用纠删码作为数据容错机制,在节点发生故障之后对失效数据进行有效地修复。不过,纠删码修复过程中必须从其他可用于解码计算的节点上下载数据,占用的网络带宽较多、修复时间较长,致使数据读取性能下降。如果修复速度较慢,甚至不如节点发生故障的速度,系统的可靠性将无法维持。流水线是目前效率最高的数据传输网络结构,流水线修复方法(Repair Pipelining,RP)可显著缩短修复时间,提高修复效率,但仍然存在一些缺陷(例如,负载不均衡)。基于此,本课题重点研究分布式存储中纠删码流水线修复技术的若干相关问题。首先,提出基于负载均衡的流水线修复方法(Repair Pipelining based on Node Load Balancing,NLB-RP),处理RP修复过程中节点负载不平衡的问题。RP中改善了节点负载不均衡的情况,但仍有改进空间。NLB-RP中通过添加不同构造的数据传输路径来平衡节点负载,并选取更多节点加入修复,进一步减少节点负载。综合理论分析及实验数据,可以证明NLB-RP从局部上平衡、从整体上减轻了节点负载,并且没有引入新的修复代价。与RP相比,NLB-RP的节点负载方差计算结果为0,这说明各个节点具有相同的负载。因此,NLB-RP是一种具有最优负载均衡性的修复方法。其次,设计部分并行的流水线修复方法(Partially Parallel Repair Pipelining for Multiple Failures,PPRP)以提高多节点修复效率。构建基于流水线路径的多节点修复模型,将修复操作划分为多个并行的部分以此提高流水线的并行度,降低了总的修复时间。与此同时,部分节点传输计算中间数据以此避免冗余传输本地数据,降低了总的修复带宽。最后,基于Piggybacking码设计去冗余流水线修复方法(Repair Pipelining for Reducing Redundancy based on Piggbacking,Pig-RP)以扩展流水线修复方法并应用于其他编码策略。Piggybacking码具有低修复带宽和低磁盘I/O开销,但缺乏快速修复方法。因此,利用流水线网络结构加速其修复过程。先基于单节点修复设计Pig-RP,再扩展到多节点修复场景中。修复单节点时,Pig-RP主要通过降低拥塞度来降低修复时间。修复多个节点时,Pig-RP不仅降低拥塞度,还大幅度降低修复带宽和磁盘I/O开销,从而减少总的修复时间。},
  collaborator = {袁, 丁},
  langid = {chinese},
  school = {四川师范大学},
  keywords = {erasure codes,load balance,multi-node repair,piggybacking,Piggybacking distributed storage,repair pipelining,分布式存储,多节点修复,流水线,硕士🎓,纠删码,负载均衡},
  file = {F\:\\Zotero文献数据\\storage\\A34G8US6\\分布式存储中纠删码流水线修复技术的研究_江小玉.caj}
}
% == BibTeX quality report for jiangFenBuShiCunChuZhongJiuShanMaLiuShuiXianXiuFuJiShuDeYanJiu2020:
% ? unused Library catalog ("CNKI")
% ? unused Url ("https://kns.cnki.net/KCMS/detail/detail.aspx?dbcode=CMFD&dbname=CMFD202002&filename=1020747291.nh&v=")

@article{jinEvaluationMechanismBased2018,
  title = {An {{Evaluation Mechanism Based}} on {{HDFS}} in {{Unstable Network Environment}}},
  author = {Jin, Xiaoyu and Ji, Xilin and Yang, Yang and Gao, Zhipeng and Qiu, Xuesong},
  year = {2018},
  journal = {Proceedings - 2018 IEEE International Conference on Big Data and Smart Computing, BigComp 2018},
  pages = {270--277},
  doi = {10.1109/BigComp.2018.00047},
  abstract = {Reliability of distributed storage is a key issue for storage of big data. This paper presents an evaluation mechanism for the popular distributed file system (HDFS). The evaluation mechanism (RST) is based on HDFS in unstable network environment. The RST can be divided into two parts, one part (NE) is that the NameNode evaluates the storage reliability of DataNode, the other part (CE) is that clients evaluate the communication quality between the client and DataNodes. This paper also proposes strategies of data redundancy and file reading and writing based on RST. The experimental results show that the strategy of data redundancy improves the availability of data and the process of data access improves the success rate of communication in unstable network environment.},
  isbn = {9781538636497},
  keywords = {distributed storage,evaluation mechanism,MATLAB🚀,Reading🌟,reliability,unstable network},
  file = {F\:\\Zotero文献数据\\storage\\A8UZWD2K\\Jin et al_2018_An Evaluation Mechanism Based on HDFS in Unstable Network Environment.pdf}
}
% == BibTeX quality report for jinEvaluationMechanismBased2018:
% ? Title looks like it was stored in title-case in Zotero

@article{kimEfficientTechniquesParallel2019,
  title = {Efficient Techniques of Parallel Recovery for Erasure-Coding-Based Distributed File Systems},
  author = {Kim, Dong-Oh and Kim, Hong-Yeon and Kim, Young-Kyun and Kim, Jeong-Joon},
  year = {2019},
  month = dec,
  journal = {Computing},
  volume = {101},
  number = {12},
  pages = {1861--1884},
  issn = {0010-485X, 1436-5057},
  doi = {10.1007/s00607-019-00714-7},
  abstract = {Replication has been widely used to ensure the data availability in a distributed file system. In recent years, erasure coding (EC) has been adopted to overcome the problem of space efficiency in Replication. However, EC has various performance degrading factors such as parity calculation and degraded input/output. In particular, the recovery performance of EC is degraded because of various factors when the distributed file systems become large. Nonetheless, few studies have been conducted to improve the recovery performance. Thus, this paper proposes an efficient parallel recovery technique in an EC-based distributed file system. We describe the contention avoidance method, chunk allocation method, and asynchronous recovery method, to improve the parallel recovery performance. The contention avoidance method can minimize the contention for resources. The chunk allocation method and asynchronous recovery method can increase the efficiency of the parallel recovery. Finally, we verify that when the proposed parallel recovery technique in this paper is applied to actual distributed file systems, its recovery performance is improved by 263\% compared to that of existing methods in the performance evaluation.},
  langid = {english},
  keywords = {可看🎈},
  file = {F\:\\Zotero文献数据\\storage\\WI4JW9WZ\\Kim 等。 - 2019 - Efficient techniques of parallel recovery for eras.pdf}
}
% == BibTeX quality report for kimEfficientTechniquesParallel2019:
% ? unused Library catalog ("DOI.org (Crossref)")
% ? unused Url ("http://link.springer.com/10.1007/s00607-019-00714-7")

@article{kimErasureCodingBasedStorageRecovery2021,
  title = {Erasure-{{Coding-Based Storage}} and {{Recovery}} for {{Distributed Exascale Storage Systems}}},
  author = {Kim, Jeong-Joon},
  year = {2021},
  month = apr,
  journal = {Applied Sciences},
  volume = {11},
  number = {8},
  pages = {3298},
  issn = {2076-3417},
  doi = {10.3390/app11083298},
  abstract = {Various techniques have been used in distributed file systems for data availability and stability. Typically, a method for storing data in a replication technique-based distributed file system is used, but due to the problem of space efficiency, an erasure-coding (EC) technique has been utilized more recently. The EC technique improves the space efficiency problem more than the replication technique does. However, the EC technique has various performance degradation factors, such as encoding and decoding and input and output (I/O) degradation. Thus, this study proposes a buffering and combining technique in which various I/O requests that occurred during encoding in an EC-based distributed file system are combined into one and processed. In addition, it proposes four recovery measures (disk input/output load distribution, random block layout, multi-threadbased parallel recovery, and matrix recycle technique) to distribute the disk input/output loads generated during decoding.},
  langid = {english},
  keywords = {可看🎈},
  file = {F\:\\Zotero文献数据\\storage\\SCEJDTWB\\Kim - 2021 - Erasure-Coding-Based Storage and Recovery for Dist.pdf}
}
% == BibTeX quality report for kimErasureCodingBasedStorageRecovery2021:
% ? Title looks like it was stored in title-case in Zotero
% ? unused Library catalog ("DOI.org (Crossref)")
% ? unused Url ("https://www.mdpi.com/2076-3417/11/8/3298")

@article{kumarCodeConstructionsDistributed2018,
  title = {Code Constructions for Distributed Storage with Low Repair Bandwidth and Low Repair Complexity},
  author = {Kumar, Siddhartha and Graell I Amat, Alexandre and Andriyanova, Iryna and Brannstrom, Fredrik and Rosnes, Eirik},
  year = {2018},
  journal = {IEEE Transactions on Communications},
  volume = {66},
  number = {12},
  pages = {5847--5860},
  publisher = {{IEEE}},
  issn = {15580857},
  doi = {10.1109/TCOMM.2018.2858765},
  abstract = {We present the construction of a family of erasure correcting codes for distributed storage which achieve low repair bandwidth and complexity at the expense of a lower fault tolerance. The construction is based on two classes of codes, where the primary goal of the first class of codes is to provide fault tolerance, while the second class aims at reducing the repair bandwidth and repair complexity. The repair procedure is a two-step procedure where parts of the failed node are repaired in the first step using the first code. The downloaded symbols during the first step are cached in the memory and used to repair the remaining erased data symbols at minimal additional read cost during the second step. The first class of codes is based on maximum distance separable (MDS) codes modified using piggybacks, while the second class is designed to reduce the number of additional symbols that need to be downloaded to repair the remaining erased symbols. We numerically show that the proposed codes achieve better repair bandwidth compared to MDS codes, codes constructed using piggybacks, and local reconstruction/Pyramid codes, while a better repair complexity is achieved when compared to MDS, Zigzag, Pyramid codes, and codes constructed using piggybacks.},
  keywords = {Code concatenation,codes for distributed storage,important,piggybacking,repair bandwidth,repair complexity},
  file = {F\:\\Zotero文献数据\\storage\\9QSBMG6Q\\Kumar et al_2018_Code constructions for distributed storage with low repair bandwidth and low.pdf}
}

@article{lengZiYuanGongYaoJiChuSheShiShuJuTongBuDeGaiJinFangFaYanJiu2021,
  title = {{资源公钥基础设施数据同步的改进方法研究}},
  author = {冷, 峰 and 赵, 琦 and 延, 志伟 and 曾, 宇},
  year = {2021},
  journal = {网络与信息安全学报},
  volume = {7},
  number = {03},
  pages = {123--133},
  issn = {2096-109X},
  abstract = {资源公钥基础设施(RPKI)依赖方需定期从资料库系统同步数据进行信息验证。为了完成数据同步,当前主流的方式是采用Rsync和RRDP两种技术,但各自存在着相关问题。针对上述问题,通过分析研究依赖方从资料库同步数据的方式,建立了数学模型,并根据两种技术各自面临的相关问题,提出了一种改进的RPKI数据同步方法,分析了传统数据同步手段与改进方法各自的优缺点以及适应的场景,为优化RPKI的部署应用提供了参考。},
  langid = {chinese},
  keywords = {data synchronization,mathematical model,routing decision,中文🌈,数学模型 resource public key infrastructure,数据同步,资源公钥基础设施,路由决策},
  file = {F\:\\Zotero文献数据\\storage\\PZR6T9ED\\冷 et al_2021_资源公钥基础设施数据同步的改进方法研究.pdf}
}
% == BibTeX quality report for lengZiYuanGongYaoJiChuSheShiShuJuTongBuDeGaiJinFangFaYanJiu2021:
% ? unused Library catalog ("CNKI")
% ? unused Url ("https://kns.cnki.net/KCMS/detail/detail.aspx?dbcode=CJFD&dbname=CJFDLAST2021&filename=WXAQ202103011&v=")

@inproceedings{liAutomatedIntelligentHealing2021,
  title = {Automated {{Intelligent Healing}} in {{Cloud-Scale Data Centers}}},
  booktitle = {2021 40th {{International Symposium}} on {{Reliable Distributed Systems}} ({{SRDS}})},
  author = {Li, Rui and Cheng, Zhinan and Lee, Patrick P. C. and Wang, Pinghui and Qiang, Yi and Lan, Lin and He, Cheng and Lu, Jinlong and Wang, Mian and Ding, Xinquan},
  year = {2021},
  month = sep,
  pages = {244--253},
  publisher = {{IEEE}},
  address = {{Chicago, IL, USA}},
  doi = {10.1109/SRDS53918.2021.00032},
  abstract = {Modern cloud-scale data centers necessitate selfhealing (i.e., the automation of detecting and repairing component failures) to support reliable and scalable cloud services in the face of prevalent failures. Traditional policy-based self-healing solutions rely on expert knowledge to define the proper policies for choosing repair actions, and hence are error-prone and non-scalable in practical deployment. We propose AIHS, an automated intelligent healing system that applies machine learning to achieve scalable self-healing in cloud-scale data centers. AIHS is designed as a fullfledged, general pipeline that supports various machine learning models for predicting accurate repair actions based on raw monitoring logs. We conduct extensive trace-driven and production experiments, and show that AIHS achieves higher prediction accuracy than current self-healing solutions and successfully fixes 92.4\% of the total of 33.7 million production failures over seven months. AIHS also reduces 51\% of unavailable time of each failed server on average compared to policy-based self-healing. AIHS is now deployed in production cloud-scale data centers at Alibaba with a total of 600 K servers. We open-source a Python prototype that reproduces the self-healing pipeline of AIHS for public validation.},
  isbn = {978-1-66543-819-3},
  langid = {english},
  keywords = {可看🎈},
  file = {F\:\\Zotero文献数据\\storage\\YY3JWM2E\\Li 等。 - 2021 - Automated Intelligent Healing in Cloud-Scale Data .pdf}
}
% == BibTeX quality report for liAutomatedIntelligentHealing2021:
% ? Unsure about the formatting of the booktitle
% ? Title looks like it was stored in title-case in Zotero
% ? unused Library catalog ("DOI.org (Crossref)")
% ? unused Url ("https://ieeexplore.ieee.org/document/9603508/")

@article{liDemandAwareErasureCoding2021,
  title = {Demand-{{Aware Erasure Coding}} for {{Distributed Storage Systems}}},
  author = {Li, Jun and Li, Baochun},
  year = {2021},
  month = apr,
  journal = {IEEE Transactions on Cloud Computing},
  volume = {9},
  number = {2},
  pages = {532--545},
  issn = {2168-7161, 2372-0018},
  doi = {10.1109/TCC.2018.2885306},
  keywords = {Aware♥️,可看🎈}
}
% == BibTeX quality report for liDemandAwareErasureCoding2021:
% ? Title looks like it was stored in title-case in Zotero
% ? unused Journal abbreviation ("IEEE Trans. Cloud Comput.")
% ? unused Library catalog ("DOI.org (Crossref)")
% ? unused Url ("https://ieeexplore.ieee.org/document/8576648/")

@article{liEfficientOnetoOnePiggybacking2019,
  title = {An {{Efficient One-to-One Piggybacking Design}} for {{Distributed Storage Systems}}},
  author = {Li, Guiyang and Lin, Xing and Tang, Xiaohu},
  year = {2019},
  month = dec,
  journal = {IEEE Transactions on Communications},
  volume = {67},
  number = {12},
  pages = {8193--8205},
  publisher = {{Institute of Electrical and Electronics Engineers Inc.}},
  issn = {15580857},
  doi = {10.1109/TCOMM.2019.2941933},
  abstract = {As a kind of erasure code, piggybacking has been applied in practice since it can significantly reduce the repair bandwidth of distributed storage systems. Currently, several efficient piggybacking designs have been proposed. In this paper, we propose a more efficient 'one-to-one' piggybacking design (OOP) to further reduce the repair bandwidth. Different from the existing piggybacking designs, OOP adopts a simple encoding principle that one parity node only piggybacks symbols from one substripe. Particularly, OOP takes into account the efficient repair of systematic nodes and parity nodes simultaneously. It is shown that for OOP design, the optimal number of substripes is (\$\textbackslash backslash\$sqrt \{r-1\}+r-1) , the average repair bandwidth ratio of systematic nodes can be as low as \$\textbackslash backslash\$frac \{2\$\textbackslash backslash\$sqrt \{r-1\}+1\}\{2\$\textbackslash backslash\$sqrt \{r-1\}+r\} , and the average repair bandwidth ratio of parity nodes reaches \$\textbackslash backslash\$left(\{\$\textbackslash backslash\$frac \{\$\textbackslash backslash\$sqrt \{r-1\}+1\}\{r\}+\$\textbackslash backslash\$frac \{(r-1)\^\{2\}-\$\textbackslash backslash\$sqrt \{(r-1)\^\{3\}\}\}\{rk\}\}\$\textbackslash backslash\$right). In contrast to the existing piggybacking designs, OOP can further reduce the repair bandwidth of both system nodes and parity nodes.},
  keywords = {Distributed storage system,MDS code,parity node,piggybacking,systematic node},
  file = {F\:\\Zotero文献数据\\storage\\8DVZIVW9\\Li et al_2019_An Efficient One-to-One Piggybacking Design for Distributed Storage Systems.pdf}
}
% == BibTeX quality report for liEfficientOnetoOnePiggybacking2019:
% ? Title looks like it was stored in title-case in Zotero
% ? unused Url ("https://ieeexplore.ieee.org/document/8840906/")

@article{liERStoreHybridStorage2021,
  title = {{{ER-Store}}: {{A Hybrid Storage Mechanism}} with {{Erasure Coding}} and {{Replication}} in {{Distributed Database Systems}}},
  shorttitle = {{{ER-Store}}},
  author = {Li, Zijian and Xiao, Chuqiao},
  editor = {Qian, Jiangbo},
  year = {2021},
  month = sep,
  journal = {Scientific Programming},
  volume = {2021},
  pages = {1--13},
  issn = {1875-919X, 1058-9244},
  doi = {10.1155/2021/9910942},
  abstract = {In distributed database systems, as cluster scales grow, efficiency and availability become critical considerations. In a cluster, a common approach to high availability is using replication, but this is inefficient due to its low storage utilization. Erasure coding can provide data reliability while ensuring high storage utilization. However, due to the large number of coding and decoding operations required by the CPU, it is not suitable for some frequently updated data. In order to optimize the storage efficiency of the data in the distributed system without affecting the availability of the data, this paper proposes a data temperature recognition algorithm that can distinguish data tablets and divides data tablets into three types, cold, warm, and hot, according to the frequency of access. Combining three replicas and erasure coding technology, ER-store is proposed, a hybrid storage mechanism for different data types. At the same time, we combined the read-write separation architecture of the distributed database system to design the data temperature conversion cycle, which reduces the computational overhead caused by frequent updates of erasure coding technology. We have implemented this design on the CBase database system based on the read-write separation architecture, and the experimental results show that it can save 14.6\%\textendash 18.3\% of the storage space while meeting the efficient access performance of the system.},
  langid = {english},
  keywords = {可看🎈},
  file = {F\:\\Zotero文献数据\\storage\\8QJANWT2\\9910942.pdf}
}
% == BibTeX quality report for liERStoreHybridStorage2021:
% ? Title looks like it was stored in title-case in Zotero
% ? unused Library catalog ("DOI.org (Crossref)")
% ? unused Url ("https://www.hindawi.com/journals/sp/2021/9910942/")

@article{liJiYuYiQunYouHuaSuanFaDeJiuShanMaCunChuXiTongShuJuGengXinFangAn2021,
  title = {{基于蚁群优化算法的纠删码存储系统数据更新方案}},
  author = {李, 乾 and 胡, 玉鹏 and 叶, 振宇 and 肖, 叶 and 秦拯},
  year = {2021},
  journal = {计算机研究与发展},
  volume = {58},
  number = {02},
  pages = {305--318},
  issn = {1000-1239},
  abstract = {由于纠删码具备高可用性和高存储空间有效性的特点,采用纠删码为大规模分布式存储系统提供数据持久性已成为事实标准.然而,纠删码的密集型更新操作将导致大量的数据传输和I/O开销.如何减少数据传输量,优化现有网络资源的利用率,以提高纠删码的更新效率,成为纠删码存储系统面临的重要挑战.然而,在多重服务质量(quality of service, QoS)指标下,目前对纠删码更新效率的优化研究很少.针对此问题,提出一种基于蚁群优化算法的多数据节点更新方案(ant colony optimization algorithm based multiple data nodes update scheme, ACOUS),采用2阶段数据更新方式以优化多数据节点更新过程.具体而言,基于多目标蚁群优化更新路由算法(multi-objective ant colony optimization update routing algorithm, MACOU)所构建的多目标更新树,2阶段数据更新方式能有效地进行数据增量收集和校验增量分发.大量的实验结果表明,在典型的数据中心网络拓扑结构下,与TA-Update方案相比,所提方案能够在保证算法收敛的前提下,以可忽略的计算开销为代价,将更新时延降低26\%～37\%.},
  langid = {chinese},
  keywords = {ant colony optimization,data update,erasure codes,update delay,中文🌈,分布式存储系统,数据更新,更新时延 distributed storage system,纠删码,蚁群优化},
  annotation = {{$<$}北大核心, EI, CSCD{$>$}},
  file = {F\:\\Zotero文献数据\\storage\\KV8IGA3X\\李 et al_2021_基于蚁群优化算法的纠删码存储系统数据更新方案.pdf}
}
% == BibTeX quality report for liJiYuYiQunYouHuaSuanFaDeJiuShanMaCunChuXiTongShuJuGengXinFangAn2021:
% ? unused Library catalog ("CNKI")
% ? unused Url ("https://kns.cnki.net/KCMS/detail/detail.aspx?dbcode=CJFD&dbname=CJFDLAST2021&filename=JFYZ202102009&v=")

@article{liJointSchedulingSource2018,
  title = {Joint {{Scheduling}} and {{Source Selection}} for {{Background Traffic}} in {{Erasure-Coded Storage}}},
  author = {Li, S. and Lan, T. and Ra, M. and Panta, R.},
  year = {2018},
  month = dec,
  journal = {IEEE Transactions on Parallel and Distributed Systems},
  volume = {29},
  number = {12},
  pages = {2826--2837},
  issn = {1558-2183},
  doi = {10/gfnv5c},
  abstract = {Erasure-coded storage systems have gained considerable adoption recently since they can provide the same level of reliability with significantly lower storage overhead compared to replicated systems. However, background traffic of such systems \textendash{} e.g., repair, rebalance, backup and recovery traffic \textendash{} often has large volume and consumes significant network resources. Independently scheduling such tasks and selecting their sources can easily create interference among data flows, causing severe deadline violation. We show that the well-known heuristic scheduling algorithms fail to consider important constraints, thus resulting in unsatisfactory performance. In this paper, we claim that an optimal scheduling algorithm, which aims to maximize the number of background tasks completed before deadlines, must simultaneously consider task deadline, network topology, chunk placement, and time-varying resource availability. We first show that the corresponding optimization problem is NP-hard. Then we propose a novel algorithm, called Linear Programming for Selected Tasks (LPST) to maximize the number of successful tasks and improve overall utilization of the datacenter network. It jointly schedules tasks and selects their sources based on a notion of Remaining Time Flexibility, which measures the slackness of the starting time of a task. We evaluated the efficacy of our algorithm using extensive simulations and validate the results with experiments in a real cloud environment. Our results show that, under certain scenarios, LPST can perform 7x\$\textbackslash sim\$ 10x better than the heuristics which blindly treat the infrastructure as a collection of homogeneous resources, and 21.7 \$\textbackslash sim\$ 65.9 percent better than the algorithms that only take the network topology into account.},
  keywords = {Bandwidth,erasure code,Java☀️,Maintenance engineering,Network topology,Reading🌟,Scheduling algorithms,Servers,storage,Task analysis,Traffic scheduling},
  file = {F\:\\Zotero文献数据\\storage\\2M2R6FNG\\Li et al_2018_Joint Scheduling and Source Selection for Background Traffic in Erasure-Coded.pdf;F\:\\Zotero文献数据\\storage\\KIBG6QZF\\8378267.html}
}
% == BibTeX quality report for liJointSchedulingSource2018:
% ? Title looks like it was stored in title-case in Zotero
% ? unused Library catalog ("IEEE Xplore")

@article{liMistEfficientDissemination2019,
  title = {Mist: {{Efficient Dissemination}} of {{Erasure-Coded Data}} in {{Data Centers}}},
  shorttitle = {Mist},
  author = {Li, J. and Li, B. and Li, B.},
  year = {2019},
  month = jul,
  journal = {IEEE Transactions on Emerging Topics in Computing},
  volume = {7},
  number = {3},
  pages = {468--480},
  issn = {2168-6750},
  doi = {10/gjrfjw},
  abstract = {Data centers store a massive amount of data in a large number of servers built by commodity hardware. To maintain data integrity against server failures, erasure codes have been extensively deployed in modern data centers to provide a higher level of failure tolerance with less storage overhead than replication. Yet, compared to replication, disseminating erasure-coded data from a source server into multiple servers will also take significantly more time. In this paper, we design and implement Mist, a new mechanism for disseminating erasure-coded data efficiently to multiple receiving servers (receivers) in data centers. Mist speeds up the dissemination process by building an efficient topology among the receivers with heterogeneous performance, so that coded data can be received from other receivers in a pipelined fashion, rather than directly from the source. Mist flexibly supports a wide range of erasure codes, without imposing constraints to the range of system parameters, and can be extended for specific erasure codes with better performance by taking advantage of the corresponding erasure code. We have implemented Mist in Python, and our experimental results in Amazon EC2 have demonstrated that the dissemination time can be reduced by up to 96.3 percent with different kinds of erasure codes.},
  keywords = {data dissemination,Distributed databases,distributed storage,Erasure code,local reconstruction code,Pipeline processing,Receivers,Reed-Solomon code,Reed-Solomon codes,regenerating code,Servers,Topology},
  annotation = {00002},
  file = {F\:\\Zotero文献数据\\storage\\GCWATA3E\\Li et al_2019_Mist.pdf;F\:\\Zotero文献数据\\storage\\DWHALKSN\\8259311.html}
}
% == BibTeX quality report for liMistEfficientDissemination2019:
% ? Title looks like it was stored in title-case in Zotero
% ? unused Library catalog ("IEEE Xplore")

@article{linBoostingFullNodeRepair,
  title = {Boosting {{Full-Node Repair}} in {{Erasure-Coded Storage}}},
  author = {Lin, Shiyao and Gong, Guowen and Shen, Zhirong and Lee, Patrick P C and Shu, Jiwu},
  pages = {15},
  abstract = {As a common choice for fault tolerance in today's storage systems, erasure coding is still hampered by the induced substantial traffic in repair. A variety of erasure codes and repair algorithms are designed in recent years to relieve the repair traffic, yet we unveil via careful analysis that they are still plagued by several limitations, which restrict or even negate the performance gains. We present RepairBoost, a scheduling framework that can assist existing linear erasure codes and repair algorithms to boost the full-node repair performance. RepairBoost builds on three design primitives: (i) repair abstraction, which employs a directed acyclic graph to characterize a single-chunk repair process; (ii) repair traffic balancing, which balances the upload and download repair traffic simultaneously; and (iii) transmission scheduling, which carefully dispatches the requested chunks to saturate the most unoccupied bandwidth. Extensive experiments on Amazon EC2 show that RepairBoost can accelerate the repair by 35.0-97.1\% for various erasure codes and repair algorithms.},
  langid = {english},
  keywords = {⛔ No DOI found,CUHK📕,可看🎈},
  file = {F\:\\Zotero文献数据\\storage\\3X2TUWWE\\Lin 等。 - Boosting Full-Node Repair in Erasure-Coded Storage.pdf}
}
% == BibTeX quality report for linBoostingFullNodeRepair:
% Missing required field 'journal'
% Missing required field 'year'
% ? Title looks like it was stored in title-case in Zotero
% ? unused Library catalog ("Zotero")

@phdthesis{linMianXiangDuoJieDianShiXiaoDeJiuShanMaJiShuJuXiuFuJiShuYanJiu2014,
  type = {{硕士}},
  title = {{面向多节点失效的纠删码及数据修复技术研究}},
  author = {林, 轩},
  year = {2014},
  abstract = {在分布式存储系统中,基于纠删码的容错机制相比于基于副本的容错机制能够极大地节省数据存储开销。然而,纠删码修复所产生的大量数据传输影响了系统性能,阻碍了纠删码在实际分布式存储系统中的广泛应用。纠删码的修复方式分为立即修复和延迟修复两种,延迟修复相比于立即修复能够节省系统资源,因此成为目前主流的修复方式。然而,延迟修复将导致多节点失效更为常见。现有的纠删码和修复策略主要针对于单节点失效修复,在多节点失效修复时数据传输量大、速度慢。为降低多节点数据传输量、加快修复速度,对面向多节点失效的纠删码以及数据修复技术进行了深入研究。取得的主要研究进展如下:首先,针对已有纠删码在多节点修复时存在数据传输量大的问题,本文提出了一种面向多节点失效的分组修复码GRC。GRC码利用分组思想将整个条带分成若干组并在组内计算出多个局部编码块,来减少多节点修复时的数据传输量。在计算局部编码块时,通过控制生成矩阵,使得各组中序号相同的局部编码块能够合成全局编码块,合成的全局编码块和已有全局编码块共同维持纠删码容错度。根据GRC码的编码特征,本文提出针对GRC码的基于多阶段选择策略的解码算法GMCD以减少解码过程的数据传输量,优化系统性能。实验结果表明,与已有的典型纠删码RS码相比,GRC码将修复时数据传输量降低50\%以上;与分组结构型纠删码BPC码相比,GRC码将修复时数据传输量降低15\%-25\%。其次,针对已有修复技术在多节点修复时速度慢的问题,本文提出了一种分组数据互换修复技术GDER。不同于传统集中式同时修复技术中将所有块发送到一个新生节点上进行解码,GDER将修复所用到的块平均分成两组,并各自发送到两个新生节点。两个新生节点分别计算得出中间数据,然后交换部分中间数据,使得新生节点本身计算得到的中间数据和从另一个新生节点接收得到的中间数据合成失效块。由于修复过程中两个节点并行地接收数据和进行解码计算,因此GDER的修复速度相比于传统集中式同时修复技术有近一倍的提高。此外,本文提出了一种以最小数据传输代价为目标的节点选择算法MDTNS以优化多节点修复性能。实验结果表明,与传统集中式同时修复技术相比,GDER在保持修复数据传输量较低的情况下,修复速度提高70\%以上。最后,基于上述研究成果,设计并实现了一个基于分组修复码的分布容错存储原型系统Group CR。Group CR基于开源的分布式容错存储系统HDFS-RAID设计实现,含有丰富的纠删码编码算法,包括已有的GRC码、BPC码、RS码和XOR码,也能较容易地扩展支持其他的编码算法。此外,Group CR支持分组数据互换修复技术GDER,也能较容易地扩展支持其他的修复技术。大量真实环境下的实验表明,在采用星型修复技术时,分组修复码相比于RS码在修复过程中传输的数据量减少50\%-60\%,相比于BPC码在修复过程中传输的数据量减少15\%-25\%;在采用RS码和GRC码时,分组数据互换修复技术GDER比传统集中式同时修复技术在修复速度上均提高70\%-80\%,进一步验证了理论分析和模拟实验的结果。},
  collaborator = {王, 意洁},
  langid = {chinese},
  school = {国防科学技术大学},
  keywords = {Erasure Codes,Lazy Repair,Multiple Failure Repair,分布式存储系统,多节点修复 Distributed Storage System,延迟修复,硕士🎓,纠删码},
  annotation = {4 citations(CNKI)[2022-2-18]},
  file = {F\:\\Zotero文献数据\\storage\\XKXCLKHM\\面向多节点失效的纠删码及数据修复技术研究_林轩.caj}
}
% == BibTeX quality report for linMianXiangDuoJieDianShiXiaoDeJiuShanMaJiShuJuXiuFuJiShuYanJiu2014:
% ? unused Library catalog ("CNKI")
% ? unused Url ("https://kns.cnki.net/KCMS/detail/detail.aspx?dbcode=CMFD&dbname=CMFD201701&filename=1016921805.nh&v=")

@article{liOpenECUnifiedConfigurable,
  title = {{{OpenEC}}: {{Toward Unified}} and {{Configurable Erasure Coding Management}} in {{Distributed Storage Systems}}},
  author = {Li, Xiaolu and Li, Runhui and Lee, Patrick P C and Hu, Yuchong},
  pages = {14},
  abstract = {Erasure coding becomes a practical redundancy technique for distributed storage systems to achieve fault tolerance with low storage overhead. Given its popularity, research studies have proposed theoretically proven erasure codes or efficient repair algorithms to make erasure coding more viable. However, integrating new erasure coding solutions into existing distributed storage systems is a challenging task and requires non-trivial re-engineering of the underlying storage workflows. We present OpenEC, a unified and configurable framework for readily deploying a variety of erasure coding solutions into existing distributed storage systems. OpenEC decouples erasure coding management from the storage workflows of distributed storage systems, and provides erasure coding designers with configurable controls of erasure coding operations through a directed-acyclic-graph-based programming abstraction. We prototype OpenEC on two versions of HDFS with limited code modifications. Experiments on a local cluster and Amazon EC2 show that OpenEC preserves both the operational performance and the properties of erasure coding solutions; OpenEC can also automatically optimize erasure coding operations to improve repair performance.},
  langid = {english},
  keywords = {CUHK📕,Reading🌟},
  annotation = {00000},
  file = {F\:\\Zotero文献数据\\storage\\P7DVD94C\\Li et al_OpenEC.pdf}
}
% == BibTeX quality report for liOpenECUnifiedConfigurable:
% Missing required field 'journal'
% Missing required field 'year'
% ? Title looks like it was stored in title-case in Zotero
% ? unused Library catalog ("Zotero")

@article{liOpenECUnifiedConfigurablea,
  title = {{{OpenEC}}: {{Toward Unified}} and {{Configurable Erasure Coding Management}} in {{Distributed Storage Systems}}},
  author = {Li, Xiaolu and Li, Runhui and Lee, Patrick P C and Hu, Yuchong},
  pages = {15},
  abstract = {Erasure coding becomes a practical redundancy technique for distributed storage systems to achieve fault tolerance with low storage overhead. Given its popularity, research studies have proposed theoretically proven erasure codes or efficient repair algorithms to make erasure coding more viable. However, integrating new erasure coding solutions into existing distributed storage systems is a challenging task and requires non-trivial re-engineering of the underlying storage workflows. We present OpenEC, a unified and configurable framework for readily deploying a variety of erasure coding solutions into existing distributed storage systems. OpenEC decouples erasure coding management from the storage workflows of distributed storage systems, and provides erasure coding designers with configurable controls of erasure coding operations through a directed-acyclic-graph-based programming abstraction. We prototype OpenEC on two versions of HDFS with limited code modifications. Experiments on a local cluster and Amazon EC2 show that OpenEC preserves both the operational performance and the properties of erasure coding solutions; OpenEC can also automatically optimize erasure coding operations to improve repair performance.},
  langid = {english},
  keywords = {⛔ No DOI found,可看🎈},
  file = {F\:\\Zotero文献数据\\storage\\6JEZTG5I\\Li 等。 - OpenEC Toward Uniﬁed and Conﬁgurable Erasure Codi.pdf}
}
% == BibTeX quality report for liOpenECUnifiedConfigurablea:
% Missing required field 'journal'
% Missing required field 'year'
% ? Title looks like it was stored in title-case in Zotero
% ? unused Library catalog ("Zotero")

@article{liQuZhongXinHuaCunChuXiaFenBuShiDiDaiKuanDuoJieDianXiuFuFangFa2020,
  title = {{去中心化存储下分布式低带宽多节点修复方法}},
  author = {李, 慧 and 李, 贵洋 and 周, 悦 and 江, 小玉 and 韩, 鸿宇},
  year = {2020},
  journal = {小型微型计算机系统},
  volume = {41},
  number = {07},
  pages = {1553--1558},
  issn = {1000-1220},
  abstract = {为扩展纠删码在区块链中的应用,研究了去中心化存储系统中的修复机制,发现系统中RS码存在多节点修复成本高、效率低的问题.针对这个问题,本文提出一种更契合去中心化网络环境下的多节点修复传输模型DSMR,充分利用RS码在修复多节点时的数据冗余性和计算冗余性.通过节点稳定性和网络跳数来选择节点、构造数据传输并行结构、分组修复计算和节点数据交互四个步骤,以最大化数据传输效率、较低带宽开销和较短修复时间完成了去中心下分布式低带宽多节点修复工作.理论及实验结果表明,在任意(n,k)参数下,分布式多节点修复传输机制在保持较低存储空间地同时进一步降低修复带宽、减少修复时间.},
  langid = {chinese},
  keywords = {data transmission,erasure codes,multi-node repair,network bandwidth,中文🌈,去中心化存储,多节点修复,数据传输,纠删码,网络带宽 decentralized storage},
  annotation = {{$<$}北大核心, CSCD{$>$}},
  file = {F\:\\Zotero文献数据\\storage\\UFTJFQIW\\李 et al_2020_去中心化存储下分布式低带宽多节点修复方法.pdf}
}
% == BibTeX quality report for liQuZhongXinHuaCunChuXiaFenBuShiDiDaiKuanDuoJieDianXiuFuFangFa2020:
% ? unused Library catalog ("CNKI")
% ? unused Url ("https://kns.cnki.net/KCMS/detail/detail.aspx?dbcode=CJFD&dbname=CJFDLAST2020&filename=XXWX202007037&v=")

@article{liRepairPipeliningErasureCoded,
  title = {Repair {{Pipelining}} for {{Erasure-Coded Storage}}},
  author = {Li, Runhui and Li, Xiaolu and Lee, Patrick P C and Huang, Qun},
  pages = {13},
  abstract = {We propose repair pipelining, a technique that speeds up the repair performance in general erasure-coded storage. By pipelining the repair of failed data in small-size units across storage nodes, repair pipelining reduces the repair time to approximately the same as the normal read time to the same amount of data in homogeneous environments. We further extend repair pipelining for heterogeneous environments. We implement a repair pipelining prototype called ECPipe and integrate it as a middleware system into two open-source distributed storage systems HDFS and QFS. Experiments on a local testbed and Amazon EC2 show that repair pipelining significantly improves the performance of both degraded reads and full-node recovery over existing repair techniques.},
  langid = {english},
  keywords = {CUHK📕,Reading🌟},
  annotation = {00000},
  file = {F\:\\Zotero文献数据\\storage\\CPCALUZJ\\Li et al_Repair Pipelining for Erasure-Coded Storage.pdf}
}
% == BibTeX quality report for liRepairPipeliningErasureCoded:
% Missing required field 'journal'
% Missing required field 'year'
% ? Title looks like it was stored in title-case in Zotero
% ? unused Library catalog ("Zotero")

@inproceedings{liS3JointScheduling2017,
  title = {S3: {{Joint Scheduling}} and {{Source Selection}} for {{Background Traffic}} in {{Erasure-Coded Storage}}},
  shorttitle = {S3},
  booktitle = {2017 {{IEEE}} 37th {{International Conference}} on {{Distributed Computing Systems}} ({{ICDCS}})},
  author = {Li, Shijing and Lan, Tian and Ra, Moo-Ryong and Panta, Rajesh},
  year = {2017},
  month = jun,
  pages = {2025--2030},
  publisher = {{IEEE}},
  address = {{Atlanta, GA, USA}},
  doi = {10.1109/ICDCS.2017.204},
  abstract = {Erasure-coded storage systems have gained considerable adoption recently since they can provide the same level of reliability with significantly lower storage overhead compared to replicated systems. However, background traffic of such systems \textendash{} e.g. repair, rebalance, backup and recovery traffic \textendash{} often has large volume and consumes significant network resources. Independently scheduling such tasks and selecting their sources can easily create interference among data flows, causing severe deadline violation. We show that the well-known heuristic scheduling algorithms fail to consider important constraints, thus resulting in unsatisfactory performance. In this paper, we claim that an optimal scheduling algorithm that aims to maximize the number of background tasks completed before deadlines must simultaneously consider deadline-aware scheduling, network topology, chunk placement, and time-varying resource availability. To solve this problem, we propose a novel algorithm, called Linear Programming for Selected Tasks (LPST) to maximize the number of successful tasks and improve overall utilization of the datacenter network. It jointly schedules tasks and selects their sources based on a notion of Remaining Time Flexibility, which measures the slackness of the starting time of a task. We evaluated the efficacy of our algorithm using extensive simulations. Our results show that, under certain scenarios, LPST can perform 7x{$\sim$}70x better than the heuristics which blindly treat the infrastructure as a collection of homogeneous resources, and 46.6\%{$\sim$}65.9\% better than the algorithms that take into account the network topology.},
  isbn = {978-1-5386-1792-2},
  langid = {english},
  keywords = {Aware♥️,可看🎈},
  file = {F\:\\Zotero文献数据\\storage\\CNWEM4NK\\Li et al_2017_S3.pdf}
}
% == BibTeX quality report for liS3JointScheduling2017:
% ? Unsure about the formatting of the booktitle
% ? Title looks like it was stored in title-case in Zotero
% ? unused Library catalog ("DOI.org (Crossref)")
% ? unused Url ("http://ieeexplore.ieee.org/document/7980145/")

@article{liuDesignEvaluationSimple2020,
  title = {Design and Evaluation of a Simple Data Interface for Efficient Data Transfer across Diverse Storage},
  author = {Liu, Zhengchun and Kettimuthu, Rajkumar and Chung, Joaquin and Ananthakrishnan, Rachana and Link, Michael and Foster, Ian},
  year = {2020},
  month = sep,
  journal = {arXiv:2009.03190 [cs]},
  eprint = {2009.03190},
  eprinttype = {arxiv},
  primaryclass = {cs},
  abstract = {Modern science and engineering computing environments often feature storage systems of different types, from parallel file systems in high-performance computing centers to object stores operated by cloud providers. To enable easy, reliable, secure, and performant data exchange among these different systems, we propose Connector, a pluggable data access architecture for diverse, distributed storage. By abstracting low-level storage system details, this abstraction permits a managed data transfer service (Globus in our case) to interact with a large and easily extended set of storage systems. Equally important, it supports third-party transfers: that is, direct data transfers from source to destination that are initiated by a third-party client but do not engage that third party in the data path. The abstraction also enables management of transfers for performance optimization, error handling, and end-to-end integrity. We present the Connector design, describe implementations for different storage services, evaluate tradeoffs inherent in managed vs.\textbackslash{} direct transfers, motivate recommended deployment options, and propose a performance model-based method that allows for easy characterization of performance in different contexts without exhaustive benchmarking.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Distributed; Parallel; and Cluster Computing},
  file = {F\:\\Zotero文献数据\\storage\\JKEQSACW\\Liu et al_2020_Design and evaluation of a simple data interface for efficient data transfer.pdf;F\:\\Zotero文献数据\\storage\\KR5YAMWC\\2009.html}
}
% == BibTeX quality report for liuDesignEvaluationSimple2020:
% ? Possibly abbreviated journal title arXiv:2009.03190 [cs]
% ? unused Url ("http://arxiv.org/abs/2009.03190")

@article{liuESetStoreErasureCodedStorage2020,
  title = {{{ESetStore}}: {{An Erasure-Coded Storage System With Fast Data Recovery}}},
  shorttitle = {{{ESetStore}}},
  author = {Liu, C. and Wang, Q. and Chu, X. and Leung, Y. and Liu, H.},
  year = {2020},
  month = sep,
  journal = {IEEE Transactions on Parallel and Distributed Systems},
  volume = {31},
  number = {9},
  pages = {2001--2016},
  issn = {1558-2183},
  doi = {10/ghn436},
  abstract = {Erasure codes have been used extensively in large-scale storage systems to reduce the storage overhead of triplication-based storage systems. One key performance issue introduced by erasure codes is the long time needed to recover from a single failure, which occurs constantly in large-scale storage systems. We present ESetStore, a prototype erasure-coded storage system that aims to achieve fast recovery from failures. ESetStore is novel in the following aspects. We proposed a data placement algorithm named ESet for our ESetStore that can aggregate adequate I/O resources from available storage servers to recover from each single failure. We designed and implemented efficient read and write operations on our erasure-coded storage system via effective use of available I/O and computation resources. We evaluated the performance of ESetStore with extensive experiments on a cluster with 50 storage servers. The evaluation results demonstrate that our recovery performance can obtain linear performance growth by harvesting available I/O resources. With our defined parameter recovery I/O parallelism under some mild conditions, we can achieve optimal recovery performance, in which ESet enables minimal recovery time. Rather than being an alternative to improve recovery performance, our work can be an enhancement for existing solutions, such as Partial-parallel-repair (PPR), to further improve recovery performance.},
  keywords = {Bandwidth,Containers,Distributed databases,Encoding,Erasure coded storage systems,ESet,ESetStore,Fast data recovery,Performance evaluation,Reading🌟,Reliability,Servers},
  file = {F\:\\Zotero文献数据\\storage\\QIVP6MYV\\Liu et al_2020_ESetStore.pdf;F\:\\Zotero文献数据\\storage\\7X28CD49\\9051846.html}
}
% == BibTeX quality report for liuESetStoreErasureCodedStorage2020:
% ? Title looks like it was stored in title-case in Zotero
% ? unused Library catalog ("IEEE Xplore")

@article{liuESetStoreErasureCodedStorage2020a,
  title = {{{ESetStore}}: {{An Erasure-Coded Storage System With Fast Data Recovery}}},
  shorttitle = {{{ESetStore}}},
  author = {Liu, Chengjian and Wang, Qiang and Chu, Xiaowen and Leung, Yiu-Wing and Liu, Hai},
  year = {2020},
  month = sep,
  journal = {IEEE Transactions on Parallel and Distributed Systems},
  volume = {31},
  number = {9},
  pages = {2001--2016},
  issn = {1045-9219, 1558-2183, 2161-9883},
  doi = {10.1109/TPDS.2020.2983411},
  abstract = {Erasure codes have been used extensively in large-scale storage systems to reduce the storage overhead of triplication-based storage systems. One key performance issue introduced by erasure codes is the long time needed to recover from a single failure, which occurs constantly in large-scale storage systems. We present ESetStore, a prototype erasure-coded storage system that aims to achieve fast recovery from failures. ESetStore is novel in the following aspects. We proposed a data placement algorithm named ESet for our ESetStore that can aggregate adequate I/O resources from available storage servers to recover from each single failure. We designed and implemented efficient read and write operations on our erasure-coded storage system via effective use of available I/O and computation resources. We evaluated the performance of ESetStore with extensive experiments on a cluster with 50 storage servers. The evaluation results demonstrate that our recovery performance can obtain linear performance growth by harvesting available I/O resources. With our defined parameter recovery I/O parallelism under some mild conditions, we can achieve optimal recovery performance, in which ESet enables minimal recovery time. Rather than being an alternative to improve recovery performance, our work can be an enhancement for existing solutions, such as Partial-parallel-repair (PPR), to further improve recovery performance.},
  langid = {english},
  keywords = {可看🎈},
  file = {F\:\\Zotero文献数据\\storage\\6HBPVFST\\Liu 等。 - 2020 - ESetStore An Erasure-Coded Storage System With Fa.pdf}
}
% == BibTeX quality report for liuESetStoreErasureCodedStorage2020a:
% ? Title looks like it was stored in title-case in Zotero
% ? unused Journal abbreviation ("IEEE Trans. Parallel Distrib. Syst.")
% ? unused Library catalog ("DOI.org (Crossref)")
% ? unused Url ("https://ieeexplore.ieee.org/document/9051846/")

@phdthesis{liuFenBuShiCunChuXiTongZhongShuJuKuaiSuXiuFuDeJiuShanMa2017,
  type = {{博士}},
  title = {{分布式存储系统中数据快速修复的纠删码}},
  author = {柳, 青},
  year = {2017},
  abstract = {为防止因设备故障和网络中断而导致的数据不可用,纠删码广泛地用于分布式存储系统中保证数据可靠性。传统的纠删码会遇到修复开销大的问题:修复过程所需要的数据量远大于失效数据量。大量的修复数据会消耗宝贵的磁盘I/O和网络带宽,并将系统长期暴露在一种不稳定的窗口期,使得任何额外故障将可能导致不可恢复的数据丢失,间接地降级了系统的可靠性。近期研究人员也提出了一些减少数据修复开销的纠删码,但它们或牺牲了最小存储开销等有益性质,或只能应用于某些特定的编码系数上。另外,纠删码在数据编码和数据修复时需要消耗大量的计算资源,如何减少计算开销也是纠删码领域的研究重点。本文对分布式存储系统上数据快速修复的纠删码从两个方面展开研究:构建具有灵活参数、减少修复开销的纠删码和减少数据编码和数据修复时的计算开销。本文主要贡献包括以下三点:提出一类新的再生码\textemdash GFR码。GFR码通过一个权衡参数实现分布式存储系统中存储开销和修复开销的权衡,使得其既可以达到理论最小存储开销、最小修复开销,也可以达到他们之间的平衡。GFR码还使用一种启发式算法寻找到修复单点失效数据的最小修复开销,并利用一个阈值控制了启发式算法中搜索空间和搜索时间的权衡。经实验分析,基于GFR码的分布式存储系统比基于RAID码的系统具有更高的可靠性。GFR码在实际系统中可以达到理论上最优或近似最优的修复开销,其数据编码性能和FMSR码相近。提出一种矩阵和数据块在有限域上的快速乘法算法－预排移位乘法(SSM)。预排移位乘法通过合理调度运算顺序,合并了在计算矩阵和数据块乘法时的相同计算,减少了纠删码在有限域上数据编码和数据修复时的计算开销。实验证明,预排移位乘法比传统算法具有更小的预测分支,预排移位乘法能提高RS编码速度和提.高GFR码的数据编码速度和数据修复速度。通过对GFR码修复性能分析,预排移位乘法对GFR码修复开销影响很小。提出了一类最小存储开销下最优修复开销的纠删码－Z码。Z码以置换矩阵为元矩阵,可以组合构造出具有最优修复开销的生成矩阵。Z码还利用矩阵的张量乘积,可迭代地构造出任意参数下的生成矩阵,并保持了其最优修复开销。另外,Z码是系统码,因此数据编码后原始数被保留。它们还具有更新开销低和计算开销小等优点。Z码的参数选择灵活,理论上可以实现任意高的存储效率和容错能力。GZ码以是Z码在有限域上的扩展,它具有MDS(Maximum Distance Separable)性质,且保持了和Z码相同的修复开销和系统性等性质。经实验分析,Z/GZ码和RS码有相近的编码速度和修复速度,Z/GZ码还具有最小的更新开销,Z/GZ码在数据修复时减少了 37.5\%以上的响应时间。GFR码和Z码都是减少修复开销的纠删码。前者是非系统码,编码后只有校验数据,能够减少存储系统中每个节点的修复开销;后者是系统码,编码后保留了原始数据,能够减少原始数据部分的修复开销。GFR还可以通过增加存储开销进一步减少修复开销,因此它更适合用于需要频繁的数据修复和修复开销大的分布式存储系统,而Z码的系统性、高编码性能和低更新开销使得其适合于高性能存储系统。预排移位乘法为基于有限域上纠删码的数据编码和数据修复提供了一种快速运算方法。这三个创新点都能够提高基于纠删码的分布式存储系统中数据修复性能,减少修复响应时间,并提高数据可靠性。},
  collaborator = {冯, 丹},
  langid = {chinese},
  school = {华中科技大学},
  keywords = {Data Repairing,Distributed Storage System,分布式存储系统,博士,数据修复 Erasure Codes,硕士🎓,纠删码},
  annotation = {2 citations(CNKI)[2022-2-18]},
  file = {F\:\\Zotero文献数据\\storage\\9T42MQ8L\\分布式存储系统中数据快速修复的纠删码_柳青.caj}
}
% == BibTeX quality report for liuFenBuShiCunChuXiTongZhongShuJuKuaiSuXiuFuDeJiuShanMa2017:
% ? unused Library catalog ("CNKI")
% ? unused Url ("https://kns.cnki.net/KCMS/detail/detail.aspx?dbcode=CDFD&dbname=CDFDLAST2018&filename=1017166763.nh&v=")

@article{liuOptimalCachingLow2020,
  title = {Optimal Caching for Low Latency in Distributed Coded Storage Systems},
  author = {Liu, Kaiyang and Peng, Jun and Wang, Jingrong and Pan, Jianping},
  year = {2020},
  month = dec,
  journal = {arXiv:2012.03005 [cs, math]},
  eprint = {2012.03005},
  eprinttype = {arxiv},
  primaryclass = {cs, math},
  abstract = {Erasure codes have been widely considered a promising solution to enhance data reliability at low storage costs. However, in modern geo-distributed storage systems, erasure codes may incur high data access latency as they require data retrieval from multiple remote storage nodes. This hinders the extensive application of erasure codes to data-intensive applications. This paper proposes novel caching schemes to achieve low latency in distributed coded storage systems. Experiments based on Amazon Simple Storage Service confirm the positive correlation between the latency and the physical distance of data retrieval. The average data access latency is used the performance metric to quantify the benefits of caching. Assuming that the future data popularity and network latency information is available, an offline caching scheme is proposed to find the optimal caching solution. Guided by the optimal scheme, an online caching scheme is proposed according to the measured data popularity and network latency information in real time. Experiment results demonstrate that the online scheme can approximate the optimal scheme well with dramatically reduced computation complexity.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Information Theory,Computer Science - Networking and Internet Architecture},
  file = {F\:\\Zotero文献数据\\storage\\KIGURQ5X\\Liu et al_2020_Optimal caching for low latency in distributed coded storage systems.pdf;F\:\\Zotero文献数据\\storage\\IMETEEXG\\2012.html}
}
% == BibTeX quality report for liuOptimalCachingLow2020:
% ? Possibly abbreviated journal title arXiv:2012.03005 [cs, math]
% ? unused Url ("http://arxiv.org/abs/2012.03005")

@inproceedings{liuRackAwarePipelineRepair2020,
  title = {A {{Rack-Aware Pipeline Repair Scheme}} for {{Erasure-Coded Distributed Storage Systems}}},
  booktitle = {49th {{International Conference}} on {{Parallel Processing}} - {{ICPP}}},
  author = {Liu, Tong and Alibhai, Shakeel and He, Xubin},
  year = {2020},
  month = aug,
  pages = {1--11},
  publisher = {{ACM}},
  address = {{Edmonton AB Canada}},
  doi = {10.1145/3404397.3404444},
  abstract = {Nowadays, modern industry data centers have employed erasure codes to provide reliability for large amounts of data at a low cost. Although erasure codes provide optimal storage efficiency, they suffer from high repair costs compared to traditional three-way replication: when a data miss occurs in a data center, erasure codes would require high disk usage and network bandwidth consumption across nodes and racks to repair the failed data. In this paper, we propose RPR, a rack-aware pipeline repair scheme for erasure-coded distributed storage systems. RPR for the first time investigates the insights of the racks, and explores the connection between the node level and rack level to help improve the repair performance when a single failure or multiple failures occur in a data center. The evaluation results on several common RS code configurations show that, for single-block failures, our RPR scheme reduces the total repair time by up to 81.5\% compared to the traditional RS code repair method and 50.2\% compared to the state-of-the-art CAR algorithm. For multi-block failures, RPR reduces the total repair time and cross-rack data transfer traffic by up to 64.5\% and 50\%, respectively, over the traditional repair.},
  isbn = {978-1-4503-8816-0},
  langid = {english},
  keywords = {Aware♥️,Reading🌟,可看🎈},
  file = {F\:\\Zotero文献数据\\storage\\DSE7VEV7\\Liu et al_2020_A Rack-Aware Pipeline Repair Scheme for Erasure-Coded Distributed Storage.pdf}
}
% == BibTeX quality report for liuRackAwarePipelineRepair2020:
% ? Unsure about the formatting of the booktitle
% ? Title looks like it was stored in title-case in Zotero
% ? unused Conference name ("ICPP '20: 49th International Conference on Parallel Processing")
% ? unused Library catalog ("DOI.org (Crossref)")
% ? unused Url ("https://dl.acm.org/doi/10.1145/3404397.3404444")

@article{liuWangLuoAnQuanPingGuYuFenXiMoXingYanJiu2018,
  title = {{网络安全评估与分析模型研究}},
  author = {刘, 文彦 and 霍, 树民 and 仝, 青 and 张, 淼 and 齐, 超},
  year = {2018},
  journal = {网络与信息安全学报},
  volume = {4},
  number = {04},
  pages = {1--11},
  issn = {2096-109X},
  abstract = {网络安全评估有助于清楚掌握其网络信息系统目前与未来的风险所在,并给出相应的安全建议和对策。网络安全评估与分析模型是其中重要的研究方向和内容,当前尚无对此进行全面总结和分析的综述文章。对常用的网络安全评估与分析模型进行综述,首先介绍了以攻击为中心的模型,如攻击树、攻击图、攻击链等;然后阐述以防御或攻防交互为中心的模型,如攻击面、网络传染病、Petri网、自动机等,对这些模型,分别介绍了其基本概念、适用领域、建模分析过程以及优势和不足,同时给出数个典型案例说明模型在网络防御技术评估分析中的应用。},
  langid = {chinese},
  keywords = {assessment and analysis,effectiveness,model,中文🌈,有效性,模型,网络与信息安全学报🌊,网络安全,评估与分析 network security},
  annotation = {9 citations(CNKI)[2021-07-19]},
  file = {F\:\\Zotero文献数据\\storage\\Q283TKGL\\刘 et al_2018_网络安全评估与分析模型研究.pdf}
}
% == BibTeX quality report for liuWangLuoAnQuanPingGuYuFenXiMoXingYanJiu2018:
% ? unused Library catalog ("CNKI")
% ? unused Url ("https://kns.cnki.net/KCMS/detail/detail.aspx?dbcode=CJFD&dbname=CJFDLAST2018&filename=WXAQ201804001&v=")

@article{liYiZhongMianXiangShuJuKeYongXingHeCunChuKeKaoXingDongTaiYaoQiuDeZiGuaYingJiuShanMaCunChuCeLueSheJi2021,
  title = {{一种面向数据可用性和存储可靠性动态要求的自适应纠删码存储策略设计}},
  author = {李, 子天 and 邢, 凯 and 龚, 海华},
  year = {2021},
  journal = {小型微型计算机系统},
  volume = {42},
  number = {2},
  pages = {308--314},
  issn = {1000-1220},
  abstract = {为了满足指数级增长的大数据存储需求,现代的分布式存储系统需要提供大容量的存储空间以及快速的存储服务.因此在主流的分布式存储系统中,均应用了纠删码技术以节约数据中心的磁盘成本,保证数据的可靠性,并且满足应用程序和客户端的快速存储需求.在实际应用中数据往往重要程度并不相同,对数据可用性要求不一,且不同磁盘的故障率和可靠性动态不一的特点,对于传统RAID存储方式包括基于纠删码的存储系统提出了新的挑战.本文提出了一种面向数据可用性和磁盘可靠性动态要求的灵活自适应纠删码存储设计On-demand ARECS(On-demand Availability and Reliability Oriented Adaptive Erasure Coded Storage System),根据存储后端数据可用性和磁盘可靠性的多个维度进行设计,综合确定纠删码编码策略和存储节点选择,从而减少存储冗余度和存储延迟,同时提高数据可用性和存储可靠性.我们在Tahoe-LAFS开源分布式文件系统中进行了实验,实验结果验证了我们的理论分析,在保证具有多样性要求的数据可用性和磁盘可靠性的前提下,明显减少了数据冗余度和存储延迟.},
  langid = {chinese},
  keywords = {⛔ No DOI found,data availability,disk reliability,erasure code,storage system,分布式文件系统,可看🎈,存储系统,数据可用性,磁盘可靠性 distributed file system,纠删码},
  annotation = {{$<$}北大核心, CSCD{$>$}},
  file = {F\:\\Zotero文献数据\\storage\\M6Z9AA42\\李 et al_2021_一种面向数据可用性和存储可靠性动态要求的自适应纠删码存储策略设计.pdf}
}
% == BibTeX quality report for liYiZhongMianXiangShuJuKeYongXingHeCunChuKeKaoXingDongTaiYaoQiuDeZiGuaYingJiuShanMaCunChuCeLueSheJi2021:
% ? unused Library catalog ("CNKI")
% ? unused Url ("https://kns.cnki.net/KCMS/detail/detail.aspx?dbcode=CJFD&dbname=CJFDLAST2021&filename=XXWX202102018&v=")

@article{lubyRepairRateLower2020,
  title = {Repair Rate Lower Bounds for Distributed Storage},
  author = {Luby, Michael},
  year = {2020},
  month = feb,
  journal = {arXiv:2002.07904 [cs, math]},
  eprint = {2002.07904},
  eprinttype = {arxiv},
  primaryclass = {cs, math},
  abstract = {One of the primary objectives of a distributed storage system is to reliably store a large amount \$dsize\$ of source data for a long duration using a large number \$N\$ of unreliable storage nodes, each with capacity \$nsize\$. The storage overhead \$\textbackslash beta\$ is the fraction of system capacity available beyond \$dsize\$, i.e., \$\textbackslash beta = 1- \textbackslash frac\{dsize\}\{N \textbackslash cdot nsize\}\$. Storage nodes fail randomly over time and are replaced with initially empty nodes, and thus data is erased from the system at an average rate \$erate = \textbackslash lambda \textbackslash cdot N \textbackslash cdot nsize\$, where \$1/\textbackslash lambda\$ is the average lifetime of a node before failure. To maintain recoverability of the source data, a repairer continually reads data over a network from nodes at some average rate \$rrate\$, and generates and writes data to nodes based on the read data. The main result is that, for any repairer, if the source data is recoverable at each point in time then it must be the case that \$rrate \textbackslash ge \textbackslash frac\{erate\}\{2 \textbackslash cdot \textbackslash beta\}\$ asymptotically as \$N\$ goes to infinity and beta goes to zero. This inequality provides a fundamental lower bound on the average rate that any repairer needs to read data from the system in order to maintain recoverability of the source data.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Distributed; Parallel; and Cluster Computing,Computer Science - Information Theory},
  file = {F\:\\Zotero文献数据\\storage\\TBRFXY9W\\Luby_2020_Repair rate lower bounds for distributed storage.pdf;F\:\\Zotero文献数据\\storage\\ET2XXLV4\\2002.html}
}
% == BibTeX quality report for lubyRepairRateLower2020:
% ? Possibly abbreviated journal title arXiv:2002.07904 [cs, math]
% ? unused Url ("http://arxiv.org/abs/2002.07904")

@article{maJiYuZhuChengFenFenXiHeKmeansJuLeiDePingXingZuoBiaoKeShiHuaJiShuYanJiu2017,
  title = {{基于主成分分析和K-means聚类的平行坐标可视化技术研究}},
  author = {马, 国峻 and 王, 水波 and 裴, 庆祺 and 詹, 阳},
  year = {2017},
  journal = {网络与信息安全学报},
  volume = {3},
  number = {08},
  pages = {22--31},
  issn = {2096-109X},
  abstract = {为了解决多维数据的维数过高、数据量过大带来的平行坐标可视化图形线条密集交叠以及数据规律特征不易获取的问题,提出基于主成分分析和K-means聚类的平行坐标(PCAKP,principal component analysis and k-means clustering parallel coordinate)可视化方法。该方法首先对多维数据采用主成分分析方法进行降维处理,其次对降维后的数据采用K-means聚类处理,最后对聚类得到的数据采用平行坐标可视化技术进行可视化展示。以统计局网站发布的数据为测试数据,对PCAKP可视化方法进行测试,与传统平行坐标可视化图形进行对比,验证了PCAKP可视化方法的实用性和有效性。},
  langid = {chinese},
  keywords = {K-means clustering,K-means聚类 data visualization,parallel coordinate visualization,principal component analysis,中文🌈,主成分分析,平行坐标可视化,数据可视化,网络与信息安全学报🌊},
  annotation = {10 citations(CNKI)[2021-07-19]},
  file = {F\:\\Zotero文献数据\\storage\\2DYHS2VV\\马 et al_2017_基于主成分分析和K-means聚类的平行坐标可视化技术研究.pdf}
}
% == BibTeX quality report for maJiYuZhuChengFenFenXiHeKmeansJuLeiDePingXingZuoBiaoKeShiHuaJiShuYanJiu2017:
% ? Title looks like it was stored in lower-case in Zotero
% ? unused Library catalog ("CNKI")
% ? unused Url ("https://kns.cnki.net/KCMS/detail/detail.aspx?dbcode=CJFD&dbname=CJFDLAST2017&filename=WXAQ201708003&v=")

@article{maturanaBandwidthCostCode2020,
  title = {Bandwidth {{Cost}} of {{Code Conversions}} in {{Distributed Storage}}: {{Fundamental Limits}} and {{Optimal Constructions}}},
  shorttitle = {Bandwidth {{Cost}} of {{Code Conversions}} in {{Distributed Storage}}},
  author = {Maturana, Francisco and Rashmi, K. V.},
  year = {2020},
  month = aug,
  journal = {arXiv:2008.12707 [cs, math]},
  eprint = {2008.12707},
  eprinttype = {arxiv},
  primaryclass = {cs, math},
  abstract = {Erasure codes have become an integral part of distributed storage systems as a tool for providing data reliability and durability under the constant threat of device failures. In such systems, an \$[n, k]\$ code over a finite field \$\textbackslash mathbb\{F\}\_q\$ encodes \$k\$ message symbols into \$n\$ codeword symbols from \$\textbackslash mathbb\{F\}\_q\$ which are then stored on \$n\$ different nodes in the system. Recent work has shown that significant savings in storage space can be obtained by tuning \$n\$ and \$k\$ to variations in device failure rates. Such a tuning necessitates code conversion: the process of converting already encoded data under an initial \$[n\^I, k\^I]\$ code to its equivalent under a final \$[n\^F, k\^F]\$ code. The default approach to conversion is to reencode data, which places significant burden on system resources. Convertible codes are a recently proposed class of codes for enabling resource-efficient conversions. Existing work on convertible codes has focused on minimizing access cost, i.e., the number of code symbols accessed during conversion. Bandwidth, which corresponds to the amount of data read and transferred, is another important resource to optimize. In this paper, we initiate the study on the fundamental limits on bandwidth used during code conversion and present constructions for bandwidth-optimal convertible codes. First, we model the code conversion problem using network information flow graphs with variable capacity edges. Second, focusing on MDS codes and an important parameter regime called the merge regime, we derive tight lower bounds on the bandwidth cost of conversion. The derived bounds show that bandwidth cost can be significantly reduced even in regimes where access cost cannot be reduced as compared to the default approach. Third, we present a new construction for MDS convertible codes which matches the proposed lower bound and is thus bandwidth-optimal during conversion.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Distributed; Parallel; and Cluster Computing,Computer Science - Information Theory,Computer Science - Networking and Internet Architecture},
  file = {F\:\\Zotero文献数据\\storage\\NPUKJAB4\\Maturana_Rashmi_2020_Bandwidth Cost of Code Conversions in Distributed Storage.pdf;F\:\\Zotero文献数据\\storage\\RBNCVI5V\\2008.html}
}
% == BibTeX quality report for maturanaBandwidthCostCode2020:
% ? Possibly abbreviated journal title arXiv:2008.12707 [cs, math]
% ? Title looks like it was stored in title-case in Zotero
% ? unused Url ("http://arxiv.org/abs/2008.12707")

@article{mengDynamicErasureCode,
  title = {A {{Dynamic Erasure Code Based}} on {{Block Code}}},
  author = {Meng, Lingling Zhang Yulong},
  pages = {5},
  abstract = {Aiming at the problem that the parameters of existing erasure codes are poorly dynamic in adjustment, this paper proposes a dynamic erasure code based on the idea of block codes, named DLRC (Dynamic Local Reconstruction Code). We encode the data blocks in group according to four parameters which proposed in DLRC. The dynamic balance of storage overhead, fault-tolerance ability, fault-tolerance rate, and reconstruction overhead is achieved by adjusting the values of parameters which can meet the different performance requirements of the distributed storage systems. The experiments show that DLRC achieves different proportions of four main performances mentioned above by adjusting the values of four parameters. In addition, we retain global parity blocks and put them in the calculation of local parity blocks which makes all coded blocks can be locally reconstructed within the group. In this case, DLRC ensures high fault tolerance ability and fault tolerance rate while reducing the overall reconstruction over-head.},
  langid = {english},
  keywords = {⛔ No DOI found,可看🎈},
  file = {F\:\\Zotero文献数据\\storage\\TDNHZ8WJ\\Meng - A Dynamic Erasure Code Based on Block Code.pdf}
}
% == BibTeX quality report for mengDynamicErasureCode:
% Missing required field 'journal'
% Missing required field 'year'
% ? Title looks like it was stored in title-case in Zotero
% ? unused Library catalog ("Zotero")

@inproceedings{mitraPartialparallelrepairPPRDistributed2016,
  title = {Partial-Parallel-Repair ({{PPR}}): A Distributed Technique for Repairing Erasure Coded Storage},
  shorttitle = {Partial-Parallel-Repair ({{PPR}})},
  booktitle = {Proceedings of the {{Eleventh European Conference}} on {{Computer Systems}} - {{EuroSys}} '16},
  author = {Mitra, Subrata and Panta, Rajesh and Ra, Moo-Ryong and Bagchi, Saurabh},
  year = {2016},
  pages = {1--16},
  publisher = {{ACM Press}},
  address = {{London, United Kingdom}},
  doi = {10.1145/2901318.2901328},
  abstract = {With the explosion of data in applications all around us, erasure coded storage has emerged as an attractive alternative to replication because even with significantly lower storage overhead, they provide better reliability against data loss. Reed-Solomon code is the most widely used erasure code because it provides maximum reliability for a given storage overhead and is flexible in the choice of coding parameters that determine the achievable reliability. However, reconstruction time for unavailable data becomes prohibitively long mainly because of network bottlenecks. Some proposed solutions either use additional storage or limit the coding parameters that can be used. In this paper, we propose a novel distributed reconstruction technique, called Partial Parallel Repair (PPR), which divides the reconstruction operation to small partial operations and schedules them on multiple nodes already involved in the data reconstruction. Then a distributed protocol progressively combines these partial results to reconstruct the unavailable data blocks and this technique reduces the network pressure. Theoretically, our technique can complete the network transfer in {$\lceil$}(log2(k + 1)){$\rceil$} time, compared to k time needed for a (k, m) Reed-Solomon code. Our experiments show that PPR reduces repair time and degraded read time significantly. Moreover, our technique is compatible with existing erasure codes and does not require any additional storage overhead. We demonstrate this by overlaying PPR on top of two prior schemes, Local Reconstruction Code and Rotated Reed-Solomon code, to gain additional savings in reconstruction time.},
  isbn = {978-1-4503-4240-7},
  langid = {english},
  keywords = {Reading🌟},
  file = {F\:\\Zotero文献数据\\storage\\AV973YPV\\Mitra et al_2016_Partial-parallel-repair (PPR).pdf}
}
% == BibTeX quality report for mitraPartialparallelrepairPPRDistributed2016:
% ? unused Conference name ("the Eleventh European Conference")
% ? unused Library catalog ("DOI.org (Crossref)")
% ? unused Url ("http://dl.acm.org/citation.cfm?doid=2901318.2901328")

@phdthesis{peiJiYuJiuShanMaDeFenBuShiRongCuoCunChuJiShuYanJiu2016,
  type = {{博士}},
  title = {{基于纠删码的分布式容错存储技术研究}},
  author = {裴, 晓强},
  year = {2016},
  abstract = {随着网络与信息技术的飞速发展,分布式存储系统在成本、性能、可扩展性以及存储容量等方面已取得了快速进步,但同时在容错性方面也面临着巨大的挑战:随着节点规模的不断扩大,分布式存储系统中节点出现失效的概率会大大增加,而节点失效导致的数据丢失会造成灾难性的后果。因此,如何设计高效、可靠的分布式容错存储技术是当前亟需解决的关键问题。相比于副本技术,基于纠删码的数据冗余技术能够在保证相同容错能力的基础上,极大地降低存储开销,成为了当前分布式存储领域研究的热点。基于纠删码的分布式容错存储技术面临的主要挑战在于:(1)现有的纠删码数据写入方法将数据分块、编码与传输等任务集中于同一节点,存在较为严重的瓶颈问题。随着数据量的不断增大,瓶颈问题更加突出。(2)节点规模的不断增加使得多点失效的概率明显增大,在多点修复过程中现有的纠删码数据修复方法修复效率较低,修复开销较大。(3)纠删码更新过程中涉及较多的数据传输与复杂的数据计算,现有的纠删码更新方法需要消耗较大的网络开销,导致了较低的更新效率。为此,本文围绕实现基于纠删码的高效低成本存储服务这一目标,分别针对基于纠删码的数据写入、数据修复和数据更新技术展开深入研究。针对已有的纠删码数据写入方法因单点瓶颈而导致写入效率较低的问题,本文研究提出了一种基于分组的分布式流水线数据写入方法D2CP。D2CP采用一种基于分组的分布式框架以维护源节点、数据节点与编码节点之间的邻居关系。通过一种基于一致性哈希的数据放置算法,D2CP将节点位置与数据存储位置进行哈希计算以提高数据放置效率。为了降低写入开销,D2CP采用一种基于分组的数据发送调度算法以动态调度源节点的数据发送。为了提高编码计算效率,D2CP采用一种基于协作的编码数据生成算法以协作方式组织编码节点之间的计算。基于HDFS-RAID平台的测试结果表明,与目前已有的纠删码数据写入方法相比,在多种不同参数设置情况下,D2CP的数据写入时间平均减少了26\%,网络开销平均降低了24.5\%,显著提升了纠删码数据写入效率并降低了网络开销。在多点失效场景中,集中式修复方法存在单点瓶颈的问题,而分布式修复方法存在修复开销大的问题。两种方法的修复效率随着数据量的增大而显著下降。为此,本文研究提出了一种基于协作的自适应数据修复方法DARS。DARS采用一种星型结构与树型结构结合的自适应数据修复模型以同时支持单点失效和多点失效的修复。通过一种带宽感知的节点选择算法,DARS选择具有更高可用带宽的节点以保证节点之间的高可用带宽。通过一种线型结构的数据传输算法,DARS有效组织提供者节点与中继节点之间的数据传输。通过一种基于中心节点的数据分发算法,DARS有效组织协调者节点与新生节点之间的数据交互,进而保证节点之间的数据传输效率。为了最小化网络代价,DARS通过条带内的懒惰修复算法自适应地调整失效数据的修复时机,并动态调整提供者节点的数目从而保证负载的均衡性。基于HDFS-RAID平台的测试结果表明,与目前已有的纠删码数据修复方法TSR和CORE相比,在多种不同参数设置情况下,DARS的数据修复时间平均减少了29\%和55\%,显著提升了纠删码数据修复效率。更新过程中复杂的数据传输与计算使得已有的纠删码单点更新方法效率随着数据规模的增长而显著下降。为此,本文研究提出了一种基于树型结构的单点数据更新方法TA-Update。TA-Update采用一种编码参数无关的更新树结构维护节点之间的连接关系,以支持不同参数的编码算法。通过一种机架感知的树型构建算法,TA-Update构建了一颗最优更新树,以保证节点之间数据传输的高效性。通过一种自顶向下的流水线数据处理算法,TA-Update将节点之间的数据传输流水线化并将更新计算任务分布在多个不同的节点中。TA-Update通过一种基于缓存的失效处理算法高效修复失效数据并恢复暂停的更新过程,以提高方法的适应性。基于HDFS-RAID平台的测试结果表明,与目前已有的纠删码数据单点更新方法相比,TA-Update在无节点失效情况下的更新时间平均减少了33\%,在单点失效情况下的更新时间平均减少了44\%,显著提升了纠删码单点更新效率。多点更新过程中,顺序更新的方式导致已有的更新方法更新开销较大,更新效率随着数据量的增大而显著下降。为此,本文研究提出了一种基于分组结构的多点更新方法Group-U。Group-U采用基于分组的更新框架以有效组织节点之间的邻居关系。通过一种负载感知的分组算法,Group-U依据更新负载自适应地为多个待更新节点选择合理的分组方式与分组大小。通过一种混合更新算法,Group-U依据时间间隔阈值有效组织多个更新节点的更新时机,从而保证数据节点的数据一致性和编码节点的更新效率。通过一种基于缓存的失效处理算法,Group-U有效处理更新过程中出现的节点失效并保证更新过程的顺利进行。基于HDFS-RAID平台的测试结果表明,与目前已有的纠删码数据多点更新方法相比,在多种不同参数设置情况下,Group-U的数据更新时间平均减少了44\%,更新开销平均降低了12\%,显著提升了纠删码多点更新效率。},
  collaborator = {王, 意洁},
  langid = {chinese},
  school = {国防科学技术大学},
  keywords = {Data Fault Tolerance,Data Insertion,Data Repair,Data Update,Erasure Coding,分布式存储,博士,数据修复,数据写入,数据容错,数据更新 Distributed Storage,硕士🎓,纠删码},
  annotation = {1 citations(CNKI)[2022-2-25]},
  file = {F\:\\Zotero文献数据\\storage\\5YRYSP5L\\基于纠删码的分布式容错存储技术研究_裴晓强.caj}
}
% == BibTeX quality report for peiJiYuJiuShanMaDeFenBuShiRongCuoCunChuJiShuYanJiu2016:
% ? unused Library catalog ("CNKI")
% ? unused Url ("https://kns.cnki.net/KCMS/detail/detail.aspx?dbcode=CDFD&dbname=CDFDLAST2019&filename=1018996863.nh&v=")

@article{peirisVAULTSharedDistributed2019,
  title = {{{VAULT}} - {{A Shared Distributed}} and {{Redundant Storage Solution}}},
  author = {Peiris, T. R.N.R. and Bandara, W. M.U.K.M.T. and Sachintha, K. V.A. and Senarathne, Amila and Ganegoda, B. A.},
  year = {2019},
  journal = {2019 International Conference on Advancements in Computing, ICAC 2019},
  pages = {458--463},
  doi = {10.1109/ICAC49085.2019.9103371},
  abstract = {An ideal distributed storage solution must have the ability to provide redundant, reliable, shared and secure access to user data without compromising the ability to scale and descend while maintaining performance. VAULT is an attempt to avert the negatives of the cloud in a local environment using a decentralized methodology. VAULT makes use of individual idle storage space on a network of peer-to-peer nodes which is then provided to an end user to store files in the pooled space. VAULT implements redundancy by the use of Reed-Solomon codes and maps file fragment locations using a blockchain as a distributed ledger. Fragment distribution is optimized using a machine learning approach where node characteristics are used to determine the reliability of each node. The aggregation of above features makes VAULT an ideal solution for corporate environments where consumer hardware and infrastructure is already allocated.},
  isbn = {9781728141701},
  keywords = {distributed-ledger,distributed-storage,Merkele-trees,peer-to-peer,Reed-Solomon},
  file = {F\:\\Zotero文献数据\\storage\\ZHYKT9XD\\Peiris et al_2019_VAULT - A Shared Distributed and Redundant Storage Solution.pdf}
}
% == BibTeX quality report for peirisVAULTSharedDistributed2019:
% ? Title looks like it was stored in title-case in Zotero

@article{pingYiZhongJiYuYunJiaGouDeShiKongDaShuJuCunChuMoShiYanJiu,
  title = {{一种基于云架构的时空大数据存储模式研究}},
  author = {平, 宗玮},
  journal = {大数据},
  pages = {1--12},
  issn = {2096-0271},
  abstract = {基于``山东省地理信息时空大数据中心''建设，面向海量的时空大数据存储需求，在分析地理信息资源管理与应用的特点后，本文研究并提出一种基于云架构的存储模式，通过对数据库进行应用层层级横向划分，并利用分布式存储技术，创建分布式矩阵，解决了海量数据存储情况下数据浏览效率低、并发性能差、可扩展性小的问题，为大数据中心的数据存储与应用提供了底层技术支撑。},
  langid = {chinese},
  keywords = {Big data,Cloud architecture,Data slicing,Distributed storage,Geographic information,中文🌈,云架构,分布式存储,地理信息,大数据,数据切片}
}
% == BibTeX quality report for pingYiZhongJiYuYunJiaGouDeShiKongDaShuJuCunChuMoShiYanJiu:
% Missing required field 'year'
% ? unused Library catalog ("CNKI")
% ? unused Url ("https://t.cnki.net/kcms/detail?v=DTzs9WqFju8WJdd5qUirDhfW2hHNjO1xbvPMRTn220fl8VOxH0skZ15lX5Q0dHmGxuE8fUNvU90gmJnTAW_VNhyeHP_ZZR1LkZXzvj3NsxxonZsg9JW3pQ==&uniplatform=NZKPT")

@article{plank,
  title = {T1: {{Erasure Codes}} for {{Storage Applications}}},
  author = {Plank, James S},
  pages = {74},
  langid = {english},
  file = {F\:\\Zotero文献数据\\storage\\6KRI8SC4\\Plank_T1.pdf;F\:\\Zotero文献数据\\storage\\7UGYTLWF\\1.png;F\:\\Zotero文献数据\\storage\\MLZMCXF8\\2.png}
}
% == BibTeX quality report for plank:
% Missing required field 'journal'
% Missing required field 'year'
% ? Title looks like it was stored in title-case in Zotero
% ? unused Library catalog ("Zotero")

@inproceedings{qiaoInnetworkAccelerationErasure2020,
  title = {Towards {{In-network Acceleration}} of {{Erasure Coding}}},
  booktitle = {Proceedings of the {{Symposium}} on {{SDN Research}}},
  author = {Qiao, Yi and Kong, Xiao and Zhang, Menghao and Zhou, Yu and Xu, Mingwei and Bi, Jun},
  year = {2020},
  month = mar,
  pages = {41--47},
  publisher = {{ACM}},
  address = {{San Jose CA USA}},
  doi = {10.1145/3373360.3380833},
  abstract = {In distributed storage systems, erasure coding (EC) is a crucial technology to enable high fault tolerance with lower storage overheads than data replication. EC can reconstruct missing data by downloading parity data from survived machines. However, downloading streams of EC multiplex the available network I/O on the receiving end, leading to a substantially low data reconstruction speed. In this paper, we present NetEC, a novel in-network accelerating system that fully offloads EC to programmable switching ASICs. NetEC prevents multiplexing network I/O through on-switch downloading stream aggregation, thus significantly improving reconstruction speed. NetEC addresses three key challenges: computation offloading of complex EC operations, rate synchronization of multiple downloading streams, and deep payload inspection/assembly. We implement NetEC on hardware programmable switches. Evaluation shows that compared to HDFS-EC, NetEC significantly improves reconstruction rate by 2.7x-9.0x and eliminates CPU overheads, with low switch memory usage.},
  isbn = {978-1-4503-7101-8},
  langid = {english},
  keywords = {可看🎈},
  file = {F\:\\Zotero文献数据\\storage\\DWAU23FE\\Qiao 等。 - 2020 - Towards In-network Acceleration of Erasure Coding.pdf}
}
% == BibTeX quality report for qiaoInnetworkAccelerationErasure2020:
% ? unused Conference name ("SOSR '20: Symposium on SDN Research")
% ? unused Library catalog ("DOI.org (Crossref)")
% ? unused Url ("https://dl.acm.org/doi/10.1145/3373360.3380833")

@inproceedings{qiuECFusionEfficientHybrid2020,
  title = {{{EC-Fusion}}: {{An Efficient Hybrid Erasure Coding Framework}} to {{Improve Both Application}} and {{Recovery Performance}} in {{Cloud Storage Systems}}},
  shorttitle = {{{EC-Fusion}}},
  booktitle = {2020 {{IEEE International Parallel}} and {{Distributed Processing Symposium}} ({{IPDPS}})},
  author = {Qiu, H. and Wu, C. and Li, J. and Guo, M. and Liu, T. and He, X. and Dong, Y. and Zhao, Y.},
  year = {2020},
  month = may,
  pages = {191--201},
  issn = {1530-2075},
  doi = {10/gjrd9x},
  abstract = {Nowadays erasure coding is one of the most significant techniques in cloud storage systems, which provides both quick parallel I/O processing and high capabilities of fault tolerance on massive data accesses. In these systems, triple disk failure tolerant arrays (3DFTs) is a typical configuration, which is supported by several classic erasure codes like Reed-Solomon (RS) codes, Local Reconstruction Codes (LRC), Minimum Storage Regeneration (MSR) codes, etc. For an online recovery process, the foreground application workloads and the background recovery workloads are handled simultaneously, which requires a comprehensive understanding on both two types of workload characteristics. Although several techniques have been proposed to accelerate the I/O requests of online recovery processes, they are typically unilateral due to the fact that the above two workloads are not combined together to achieve high cost-effective performance.To address this problem, we propose Erasure Codes Fusion (EC-Fusion), an efficient hybrid erasure coding framework in cloud storage systems. EC-Fusion is a combination of RS and MSR codes, which dynamically selects the appropriate code based on its properties. On one hand, for write-intensive application workloads or low risk on data loss in recovery workloads, EC-Fusion uses RS code to decrease the computational overhead and storage cost concurrently. On the other hand, for read-intensive or frequent reconstruction in workloads, MSR code is a proper choice. Therefore, a better overall application and recovery performance can be achieved in a cost-effective fashion. To demonstrate the effectiveness of EC-Fusion, several experiments are conducted in hadoop systems. The results show that, compared with the traditional hybrid erasure coding techniques, EC-Fusion accelerates the response time for application by up to 1.77\texttimes, and reduces the reconstruction time by up to 69.10\%.},
  keywords = {AdaptiveCode🌏,Cloud computing,Encoding,Erasure Coding,Heart,High Reliability,Microwave integrated circuits,Reading🌟,Reconstruction,Redundancy,Reed-Solomon codes,Storage Efficiency,Storage Fusion,可看🎈},
  annotation = {00001},
  file = {F\:\\Zotero文献数据\\storage\\GBK8MH62\\Qiu et al_2020_EC-Fusion.pdf;F\:\\Zotero文献数据\\storage\\4VQSHMXA\\9139819.html}
}
% == BibTeX quality report for qiuECFusionEfficientHybrid2020:
% ? Unsure about the formatting of the booktitle
% ? Title looks like it was stored in title-case in Zotero
% ? unused Library catalog ("IEEE Xplore")

@inproceedings{rashmi2013solution,
  title = {A Solution to the Network Challenges of Data Recovery in Erasure-Coded Distributed Storage Systems: {{A}} Study on the {{Facebook}} Warehouse Cluster},
  booktitle = {5th {{USENIX}} Workshop on Hot Topics in Storage and File Systems ({{HotStorage}} 13)},
  author = {Rashmi, Korlakai Vinayak and Shah, Nihar B and Gu, Dikang and Kuang, Hairong and Borthakur, Dhruba and Ramchandran, Kannan},
  year = {2013},
  keywords = {⛔ No DOI found}
}
% == BibTeX quality report for rashmi2013solution:
% ? Unsure about the formatting of the booktitle

@article{rashmiPiggybackingDesignFramework2013,
  title = {A Piggybacking Design Framework for Read-and Download-Efficient Distributed Storage Codes},
  author = {Rashmi, K. V. and Shah, Nihar B. and Ramchandran, Kannan},
  year = {2013},
  journal = {IEEE International Symposium on Information Theory - Proceedings},
  volume = {63},
  number = {9},
  pages = {331--335},
  issn = {21578095},
  doi = {10.1109/ISIT.2013.6620242},
  abstract = {We present a new piggybacking framework for designing distributed storage codes that are efficient in the amount of data read and downloaded during node-repair. We illustrate the power of this framework by constructing explicit codes that attain the smallest amount of data to be read and downloaded for repair among all existing solutions for three important settings: (a) codes meeting the constraints of being maximum distance separable (MDS), high-rate, and having a small number of substripes, (b) binary MDS codes for all parameters where binary MDS codes exist, and (c) MDS codes with the smallest repair-locality. In addition, we show how to use this framework to enable efficient repair of parity nodes in existing codes that are constructed to address the repair of only the systematic nodes. The basic idea behind this framework is to take multiple stripes of existing codes and add carefully designed functions of the data of one stripe to other stripes. Typical savings in the amount of data read and downloaded during repair are 25\% to 50\% depending on the choice of the system parameters. \textcopyright{} 2013 IEEE.},
  isbn = {9781479904464},
  keywords = {bandwidth and I/O,code-design framework,Distributed storage,erasure codes,repair},
  annotation = {\_eprint: 1302.5872},
  file = {F\:\\Zotero文献数据\\storage\\HWW8BQ2E\\Rashmi et al_2013_A piggybacking design framework for read-and download-efficient distributed.pdf}
}

@article{rashmiPiggybackingDesignFramework2017,
  title = {A {{Piggybacking Design Framework}} for {{Read-and Download-Efficient Distributed Storage Codes}}},
  author = {Rashmi, K. V. and Shah, Nihar B. and Ramchandran, Kannan},
  year = {2017},
  journal = {IEEE Transactions on Information Theory},
  volume = {63},
  number = {9},
  pages = {5802--5820},
  issn = {00189448},
  doi = {10.1109/TIT.2017.2715043},
  abstract = {Erasure codes are being extensively deployed in distributed storage systems instead of replication to achieve fault tolerance in a storage efficient manner. While traditional erasure codes are storage efficient, they can result in a significant increase in the amount of data access and downloaded during rebuilding of failed or otherwise unavailable nodes. In this paper, we present a new framework, which we call piggybacking, for constructing distributed storage codes that are efficient in the amount of data read and downloaded during rebuilding, while meeting requirements arising out of system considerations in data centers - maximum-distance-separability (MDS), high-rate, and a small number of so-called substripes. Under this setting, to the best of our knowledge, piggyback codes achieve the minimum average amount of data access and downloaded during rebuilding among all existing explicit solutions. The piggybacking framework also offers a rich design space for constructing codes for a variety of other settings. In particular, we construct codes that require minimum amount of data access and downloaded for rebuilding among all existing solutions for: 1) binary MDS array codes with more than two parities and 2) MDS codes with the smallest locality during rebuilding. In addition, we show how piggybacking can be employed to enable efficient repair of parity nodes in codes that address the rebuilding of only systematic nodes. The basic idea behind the piggybacking framework is to take multiple instances of existing codes and add carefully designed functions of the data from one instance to the others. This framework provides 25\% to 50\% savings in the average amount of data access and downloaded during rebuilding depending on the choice of the code parameters.},
  keywords = {bandwidth and I/O,code-design framework,Distributed storage,erasure codes,repair},
  annotation = {\_eprint: 1302.5872},
  file = {F\:\\Zotero文献数据\\storage\\GASFNS8S\\Rashmi et al_2017_A Piggybacking Design Framework for Read-and Download-Efficient Distributed.pdf}
}
% == BibTeX quality report for rashmiPiggybackingDesignFramework2017:
% ? Title looks like it was stored in title-case in Zotero

@article{shenClusterAwareScatteredRepair2020,
  title = {Cluster-{{Aware Scattered Repair}} in {{Erasure-Coded Storage}}: {{Design}} and {{Analysis}}},
  shorttitle = {Cluster-{{Aware Scattered Repair}} in {{Erasure-Coded Storage}}},
  author = {Shen, Z. and Shu, J. and Huang, Z. and Fu, Y.},
  year = {2020},
  journal = {IEEE Transactions on Computers},
  pages = {1--1},
  issn = {1557-9956},
  doi = {10.1109/TC.2020.3028353},
  abstract = {Erasure coding is a storage-efficient means to guarantee data reliability in today's commodity storage systems, yet its repair performance is seriously hindered by the substantial repair traffic. Repair in clustered storage systems is even complicated because of the scarcity of the cross-cluster bandwidth. We present ClusterSR, a cluster-aware scattered repair approach. ClusterSR minimizes the cross-cluster repair traffic by carefully choosing the clusters for reading and repairing chunks. It further balances the cross-cluster repair traffic by scheduling the repair of multiple chunks. Large-scale simulation and Alibaba Cloud ECS experiments show that ClusterSR can reduce 8.6-52.7\% of the cross-cluster repair traffic and improve 14.4-68.8\% of the repair throughput.},
  keywords = {Aware♥️,Bandwidth,Computer architecture,Cross-Cluster Repair Traffic,Data centers,Encoding,Fault tolerance,Fault tolerant systems,Full Duplex Transmission,Load Balancing,Maintenance engineering,Reading🌟,Scattered Repair,可看🎈},
  file = {F\:\\Zotero文献数据\\storage\\C35D5BBG\\Shen et al_2020_Cluster-Aware Scattered Repair in Erasure-Coded Storage.pdf;F\:\\Zotero文献数据\\storage\\ARRECVFE\\9210857.html;F\:\\Zotero文献数据\\storage\\HPQUZFRH\\9210857.html}
}
% == BibTeX quality report for shenClusterAwareScatteredRepair2020:
% ? Title looks like it was stored in title-case in Zotero
% ? unused Library catalog ("IEEE Xplore")

@inproceedings{shenFastPredictiveRepair2019,
  title = {Fast {{Predictive Repair}} in {{Erasure-Coded Storage}}},
  booktitle = {2019 49th {{Annual IEEE}}/{{IFIP International Conference}} on {{Dependable Systems}} and {{Networks}} ({{DSN}})},
  author = {Shen, Zhirong and Li, Xiaolu and Lee, Patrick P. C.},
  year = {2019},
  month = jun,
  pages = {556--567},
  publisher = {{IEEE}},
  address = {{Portland, OR, USA}},
  doi = {10/gj3s7x},
  abstract = {Erasure coding offers a storage-efficient redundancy mechanism for maintaining data availability guarantees in largescale storage clusters, yet it also incurs high performance overhead in failure repair. Recent developments in accurate disk failure prediction allow soon-to-fail (STF) nodes to be repaired in advance, thereby opening new opportunities for accelerating failure repair in erasure-coded storage. To this end, we present a fast predictive repair solution called FastPR, which carefully couples two repair methods, namely migration (i.e., relocating the chunks of an STF node) and reconstruction (i.e., decoding the chunks of an STF node through erasure coding), so as to fully parallelize the repair operation across the storage cluster. FastPR solves a bipartite maximum matching problem and schedules both migration and reconstruction in a parallel fashion. We show that FastPR significantly reduces the repair time over the baseline repair approaches via mathematical analysis, large-scale simulation, and Amazon EC2 experiments.},
  isbn = {978-1-72810-057-9},
  langid = {english},
  keywords = {CUHK📕,Reading🌟,可看🎈},
  file = {F\:\\Zotero文献数据\\storage\\LXWCHIJT\\Shen et al_2019_Fast Predictive Repair in Erasure-Coded Storage.pdf}
}
% == BibTeX quality report for shenFastPredictiveRepair2019:
% ? Unsure about the formatting of the booktitle
% ? Title looks like it was stored in title-case in Zotero
% ? unused Library catalog ("DOI.org (Crossref)")
% ? unused Url ("https://ieeexplore.ieee.org/document/8809511/")

@article{shiHighavailabilityDataBackup,
  title = {A {{High-availability Data Backup Strategy}} for {{IPFS}}},
  author = {Shi, Mr LinFei and Luo, Hong and Yang, XueMei and Sun, Mrs Yan},
  pages = {2},
  doi = {10/ghm88j},
  abstract = {The InterPlanetary File System (IPFS) is a peer-topeer distributed file system. It can greatly reduce the cost of data storage and improve the performance of data download. Currently, the IPFS-based distributed storage systems mostly uses the centralized backup mechanism. Although it can provide high data availability, centralized nodes will be single fault peer and become the bottleneck of system performance. This paper proposes a high-availability data backup strategy based on QoS and interest of IPFS nodes. Compared with the existing methods, the experimental results demonstrate that our proposed strategy is more effective and practical.},
  langid = {english},
  file = {F\:\\Mendeley论文\\2019 IEEE International Conference on Consumer Electronics - Taiwan, ICCE-TW 2019\\Shi et al\\2019 - Shi et al. - A High-availability Data Backup Strategy for IPFS.pdf}
}
% == BibTeX quality report for shiHighavailabilityDataBackup:
% Missing required field 'journal'
% Missing required field 'year'
% ? unused Library catalog ("Zotero")

@inproceedings{shiUMRECUnifiedMultiRail2019,
  title = {{{UMR-EC}}: {{A Unified}} and {{Multi-Rail Erasure Coding Library}} for {{High-Performance Distributed Storage Systems}}},
  shorttitle = {{{UMR-EC}}},
  booktitle = {Proceedings of the 28th {{International Symposium}} on {{High-Performance Parallel}} and {{Distributed Computing}}},
  author = {Shi, Haiyang and Lu, Xiaoyi and Shankar, Dipti and Panda, Dhabaleswar K.},
  year = {2019},
  month = jun,
  pages = {219--230},
  publisher = {{ACM}},
  address = {{Phoenix AZ USA}},
  doi = {10.1145/3307681.3325406},
  abstract = {Distributed storage systems typically need data to be stored redundantly to guarantee data durability and reliability. While the conventional approach towards this objective is to store multiple replicas, today's unprecedented data growth rates encourage modern distributed storage systems to employ Erasure Coding (EC) techniques, which can achieve better storage efficiency. Various hardware-based EC schemes have been proposed in the community to leverage the advanced compute capabilities on modern data center and cloud environments. Currently, there is no unified and easy way for distributed storage systems to fully exploit multiple devices such as CPUs, GPUs, and network devices (i.e., multi-rail support) to perform EC operations in parallel; thus, leading to the under-utilization of the available compute power. In this paper, we first introduce an analytical model to analyze the design scope of efficient EC schemes in distributed storage systems. Guided by the performance model, we propose UMR-EC, a Unified and Multi-Rail Erasure Coding library that can fully exploit heterogeneous EC coders. Our proposed interface is complemented by asynchronous semantics with optimized metadata-free scheme and EC rate-aware task scheduling that can enable a highly-efficient I/O pipeline. To show the benefits and effectiveness of UMR-EC, we re-design HDFS 3.x write/read pipelines based on the guidelines observed in the proposed performance model. Our performance evaluations show that our proposed designs can outperform the write performance of replication schemes and the default HDFS EC coder by 3.7x - 6.1x and 2.4x - 3.3x, respectively, and can improve the performance of read with failure recoveries up to 5.1x compared with the default HDFS EC coder. Compared with the fastest available CPU coder (i.e., ISA-L), our proposed designs have an improvement of up to 66.0\% and 19.4\% for write and read with failure recoveries, respectively.},
  isbn = {978-1-4503-6670-0},
  langid = {english},
  keywords = {Aware♥️,可看🎈},
  file = {F\:\\Zotero文献数据\\storage\\THF9TFMM\\Shi 等。 - 2019 - UMR-EC A Unified and Multi-Rail Erasure Coding Li.pdf}
}
% == BibTeX quality report for shiUMRECUnifiedMultiRail2019:
% ? Title looks like it was stored in title-case in Zotero
% ? unused Conference name ("HPDC '19: The 28th International Symposium on High-Performance Parallel and Distributed Computing")
% ? unused Library catalog ("DOI.org (Crossref)")
% ? unused Url ("https://dl.acm.org/doi/10.1145/3307681.3325406")

@inproceedings{shuaiLatencyComparisonReplication2018,
  title = {Latency {{Comparison}} of {{Replication}} and {{Coding}} for {{Data Access}} under {{Random Scheduling}}},
  booktitle = {2018 {{IEEE International Conference}} on {{Communications}} ({{ICC}})},
  author = {Shuai, Qiqi and Li, Victor O. K. and Lu, Zhiyi and Cao, Miaomiao},
  year = {2018},
  month = may,
  pages = {1--6},
  publisher = {{IEEE}},
  address = {{Kansas City, MO}},
  doi = {10.1109/ICC.2018.8422492},
  abstract = {Replication and coding are two popular approaches to combat failures in large-scale distributed storage systems. Access latency in such systems greatly impacts user experience. Compared with redundant scheduling, random scheduling can reduce the system load, resulting in lower latency, especially when the request arrival rate is high. Besides, random scheduling can achieve near optimal load balancing at a reduced communication cost. A latency comparison of replication and coding is of great importance. Although it has been much argued that coding can achieve lower latency than replication, the latency comparison under random scheduling is still lacking. In this work, based on random scheduling, we analyze the latency of replication and coding and find that, when each request desires all data in a codeword, they have the same average latency. Additionally, we study a general case that users only request a subset of the erasure-coded content, and propose flexible random scheduling for coding, which can lower latency and realize load balancing. Our analysis demonstrates that, in this case, replication achieves lower latency when the system load is low and suffers higher latency when the system load becomes high. With real service time traces from Amazon S3, we conduct trace-driven simulations to validate our analysis.},
  isbn = {978-1-5386-3180-5},
  langid = {english},
  file = {F\:\\Zotero文献数据\\storage\\LFLSB64U\\Shuai et al_2018_Latency Comparison of Replication and Coding for Data Access under Random.pdf}
}
% == BibTeX quality report for shuaiLatencyComparisonReplication2018:
% ? Unsure about the formatting of the booktitle
% ? Title looks like it was stored in title-case in Zotero
% ? unused Conference name ("2018 IEEE International Conference on Communications (ICC 2018)")
% ? unused Library catalog ("DOI.org (Crossref)")
% ? unused Url ("https://ieeexplore.ieee.org/document/8422492/")

@inproceedings{shuBinaryReedSolomonCoding2018,
  title = {Binary {{Reed-Solomon Coding Based Distributed Storage Scheme}} in {{Information-Centric Fog Networks}}},
  booktitle = {2018 {{IEEE}} 23rd {{International Workshop}} on {{Computer Aided Modeling}} and {{Design}} of {{Communication Links}} and {{Networks}} ({{CAMAD}})},
  author = {Shu, Ye and Dong, Mianxiong and Ota, Kaoru and Wu, Jun and Liao, Siyi},
  year = {2018},
  month = sep,
  pages = {1--5},
  publisher = {{IEEE}},
  address = {{Barcelona}},
  doi = {10.1109/CAMAD.2018.8514998},
  abstract = {Fog computing is an emerging architecture for processing, storing, and controlling the data at the edge of the networks, which is becoming a popular technology for Internet of Things (IoT). As a next-generation networking architecture, Information-Centric Network (ICN) has been introduced into networked fogs to establish efficient data exchange based on name, caching, content features, etc., which gives the IoT an opportunity to store the huge geo-distributed data at the edge of the networks and be less dependent on the Cloud, thus fulfilling the delay-sensitive needs of the end-users. Nevertheless, efficient distributed storage is a must for information-centric fog networks, because of the huge content exchange and geodistributed data. To address this, this paper proposes an efficient storage scheme by integrating Binary Reed-Solomon erasure code with ICN mechanism in fog networks. Specifically, the data are encoded into named data blocks and are distributed as well as stored into distributed fog nodes. The fog network performs information-centered with horizontal fog-to-fog communications to retrieve the data blocks efficiently. Moreover, the data is then recovered even with some of the data blocks missing, thus ensuring the reliability of storage at distributed fogs. Simulation results show the efficiency and advantages of the proposed distributed storage scheme.},
  isbn = {978-1-5386-6151-2},
  langid = {english},
  file = {F\:\\Zotero文献数据\\storage\\VECKN4EA\\Shu et al_2018_Binary Reed-Solomon Coding Based Distributed Storage Scheme in.pdf}
}
% == BibTeX quality report for shuBinaryReedSolomonCoding2018:
% ? Unsure about the formatting of the booktitle
% ? Title looks like it was stored in title-case in Zotero
% ? unused Library catalog ("DOI.org (Crossref)")
% ? unused Url ("https://ieeexplore.ieee.org/document/8514998/")

@article{sikora2007disk,
  title = {Disk Failures in the Real World: {{What}} Does an {{MTTF}} of 1,000,000 Hours Mean to You?},
  author = {Sikora, Jakub},
  year = {2007},
  publisher = {{Citeseer}},
  keywords = {⛔ No DOI found}
}
% == BibTeX quality report for sikora2007disk:
% Missing required field 'journal'

@article{siposNetworkAwareFeasibleRepairs2018,
  title = {Network-{{Aware Feasible Repairs}} for {{Erasure-Coded Storage}}},
  author = {Sipos, Marton and Gahm, Josh and Venkat, Narayan and Oran, Dave},
  year = {2018},
  month = jun,
  journal = {IEEE/ACM Transactions on Networking},
  volume = {26},
  number = {3},
  pages = {1404--1417},
  issn = {1063-6692, 1558-2566},
  doi = {10.1109/TNET.2018.2830800},
  abstract = {A significant amount of research on using erasure coding for distributed storage has focused on reducing the amount of data that needs to be transferred to replace failed nodes. This continues to be an active topic as the introduction of faster storage devices looks to put an even greater strain on the network. However, with a few notable exceptions, most published work assumes a flat, static network topology between the nodes of the system. We propose a general framework to find the lowest cost feasible repairs in a more realistic, heterogeneous and dynamic network, and examine how the number of repair strategies to consider can be reduced for three distinct erasure codes. We devote a significant part of the paper to determining the set of feasible repairs for random linear network coding (RLNC) and describe a system of efficient checks using techniques from the arsenal of dynamic programming. Our solution involves decomposing the problem into smaller steps, memorizing, and then reusing intermediate results. All computationally intensive operations are performed prior to the failure of a node to ensure that the repair can start with minimal delay, based on up-todate network information. We show that all three codes benefit from being network aware and find that the extra computations required for RLNC can be reduced to a viable level for a wide range of parameter values.},
  langid = {english},
  keywords = {Aware♥️,可看🎈},
  file = {F\:\\Zotero文献数据\\storage\\UNN7Z3PR\\Sipos 等。 - 2018 - Network-Aware Feasible Repairs for Erasure-Coded S.pdf}
}
% == BibTeX quality report for siposNetworkAwareFeasibleRepairs2018:
% ? Title looks like it was stored in title-case in Zotero
% ? unused Journal abbreviation ("IEEE/ACM Trans. Networking")
% ? unused Library catalog ("DOI.org (Crossref)")
% ? unused Url ("https://ieeexplore.ieee.org/document/8370785/")

@article{sunDistributedStorageCodes2020,
  title = {Distributed {{Storage Codes Based}} on {{Double-layered Piggybacking Framework}}},
  author = {Sun, Rong and Li, Xin and Zhang, Lu and Liu, Jingwei},
  year = {2020},
  journal = {IEEE Access},
  pages = {1--1},
  doi = {10.1109/access.2020.3002824},
  file = {F\:\\Zotero文献数据\\storage\\A9QJ6GEA\\Sun et al_2020_Distributed Storage Codes Based on Double-layered Piggybacking Framework.pdf}
}
% == BibTeX quality report for sunDistributedStorageCodes2020:
% ? unused Url ("https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9118897")

@phdthesis{sunJiYuQuKuaiLianDeFenBuShiRongYuGongXiangCunChuXiTongYinSiBaoHuSuanFaYanJiu2020,
  type = {{硕士}},
  title = {{基于区块链的分布式冗余共享存储系统隐私保护算法研究}},
  author = {孙, 世璞},
  year = {2020},
  abstract = {随着信息技术和移动通信技术的普及,用户数据规模急剧膨胀,为解决用户的海量数据存储需求,云存储系统已成为现代信息社会的基础服务设施。中心化的云存储系统依赖中心化的服务器为用户提供文件存储服务,存在单点故障的问题,容易造成用户数据不可用,并威胁用户隐私安全。基于区块链的分布式共享存储系统采用去中心化的架构,因此不存在单点故障的隐患,另外,区块链的不可篡改、透明性等特征,能有效提高系统安全性、降低用户使用成本。然而,相比传统集中式的存储系统,基于区块链的分布式共享存储系统在带来诸多优势的同时,也面临着两大局限性。首先,在数据可用性方面,基于区块链的分布式共享存储系统采用基于纠删码的数据冗余方案,因此在数据恢复过程中会带来巨大的网络和计算开销;其次,在用户隐私方面,区块链数据公开透明的特性使得任何人都可以获取到区块链上的数据,威胁用户的隐私。针对以上两大问题,以及现有相关研究工作的不足,本文提出一种基于区块链的分布式共享冗余存储系统的隐私保护方案,为用户提供安全可靠的文件存储的前提下,提高冗余存储效率,并能保护用户数据隐私。本文的主要工作如下:（1）提出基于区块链的分布式共享存储系统冗余存储方案。现有的基于纠删码的数据冗余方案在数据分块过程中,通过将原始文件分割成大小相等的数据条,按照在文件中的位置将数据条分配到同一个数据块中,因此在读取失效数据块过程中,存在巨大的网络和计算开销。针对此问题,本文提出一种基于离散数据分块的文件冗余存储方案。方案将原始文件分割成大小相等的数据条,并设计映射规则将数据条进行分组完成分块过程。所提方案通过一次解码计算可以得到若干地址连续的数据条,在读取失效数据块过程中,有效降低了系统开销并提高了效率。（2）提出基于区块链的分布式共享存储系统隐私保护方案。在当前基于区块链的分布式共享存储系统中,区块链上的数据都是公开透明的,任何人都可以获取链上的数据,因此会造成用户隐私数据的泄露。本文结合隐匿传输方案和非交互式零知识证明协议设计一种隐私保护方案。通过使用隐匿传输,用户可以使用区块链交易传输数据,并在传输过程中隐藏接收方地址和交易内容。通过使用非交互式零知识证明协议实现以太坊智能合约中数据的隐藏,只有数据所有者可以查看用户数据明文,其他用户可以验证数据的有效性,而无法获取具体地数据内容,也无法知道数据所有者的信息。理论分析和实验分析表明,所提隐私保护方案是安全的、可行的。（3）设计并实现基于区块链的分布式共享存储系统。系统使用Python进行开发,基于web3.py函数库,使用以太坊、分布式存储系统IPFS实现所提冗余存储和隐私保护方案。系统采用模块化设计,包括前端模块、智能合约模块、数据存储模块。最后,对原型系统的功能进行展示。},
  collaborator = {王, 良民},
  langid = {chinese},
  school = {江苏大学},
  keywords = {Blockchain,Data Redundancy,Erasure Code,Privacy Protection,Shared Storage,中文🌈,共享存储,区块链,数据冗余,硕士🎓,纠删码,隐私保护},
  file = {F\:\\Zotero文献数据\\storage\\ZKFMRHJM\\基于区块链的分布式冗余共享存储系统隐私保护算法研究_孙世璞.caj}
}
% == BibTeX quality report for sunJiYuQuKuaiLianDeFenBuShiRongYuGongXiangCunChuXiTongYinSiBaoHuSuanFaYanJiu2020:
% ? unused Library catalog ("CNKI")
% ? unused Url ("https://kns.cnki.net/kcms/detail/detail.aspx?dbcode=CMFD&dbname=CMFD202101&filename=1020973828.nh&v=kT9yZvW41KMR0bGMuBHK6htEMraSz36FTIk0In4UVrBhi3s738X43tp6fjwPFesq")

@inproceedings{tangMICSMinglingChained2015,
  title = {{{MICS}}: {{Mingling Chained Storage Combining Replication}} and {{Erasure Coding}}},
  shorttitle = {{{MICS}}},
  booktitle = {2015 {{IEEE}} 34th {{Symposium}} on {{Reliable Distributed Systems}} ({{SRDS}})},
  author = {Tang, Yan and Yin, Jianwei and Lo, Wei and Li, Ying and Deng, Shuiguang and Dong, Kexiong and Pu, Calton},
  year = {2015},
  month = sep,
  pages = {192--201},
  publisher = {{IEEE}},
  address = {{Montreal, QC, Canada}},
  doi = {10/gj27wf},
  isbn = {978-1-4673-9302-7},
  keywords = {AdaptiveCode🌏,Reading🌟},
  annotation = {00000},
  file = {F\:\\Zotero文献数据\\storage\\TM97WQ46\\Tang et al_2015_MICS.pdf}
}
% == BibTeX quality report for tangMICSMinglingChained2015:
% ? Unsure about the formatting of the booktitle
% ? Title looks like it was stored in title-case in Zotero
% ? unused Library catalog ("DOI.org (Crossref)")
% ? unused Url ("http://ieeexplore.ieee.org/document/7371583/")

@inproceedings{taoOptimalCodeRegeneration2018,
  title = {Optimal {{Code Regeneration}} with {{Background Traffic Awareness}} in {{Distributed Storage}}},
  booktitle = {2018 {{International Conference}} on {{Computing}}, {{Networking}} and {{Communications}} ({{ICNC}})},
  author = {Tao, Yangyang and Yu, Shucheng and Yoshigoe, Kenji and Zhou, Junxiu},
  year = {2018},
  month = mar,
  pages = {48--52},
  publisher = {{IEEE}},
  address = {{Maui, HI}},
  doi = {10.1109/ICCNC.2018.8390329},
  abstract = {In cloud storage systems a certain degree of data redundancy is important for data availability. Timely regeneration of corrupted or lost data shares is desired to meet the MTTR (mean time to recovery) reliability requirements as usually defined in Service Level Agreements (SLA). Current data regeneration techniques usually assume uniform and/or unlimited network capacity while ignoring the impacts of background traffics and cloud network architecture in practice. This paper proposes a more realistic regeneration strategy by taking these impacts into consideration. Specifically, our approach first extracts an information flow graph from BCube network architecture based on which the real-time network status is predicted using a Markov Chain model. The optimal code regeneration strategy is then formulated as a linear programming (LP) problem which minimizes the sub-flow rate on bottleneck links subject to the constraint of real-time network dynamics. Finally, a distributed multi-commodity flow dynamic routing (MFDR) approximation algorithm is proposed to solve the code regeneration LP. Simulation results indicate that the proposed distributed algorithm on average saves 16.5\% data regeneration time of RCTREE and 45.3\% of HDFS.},
  isbn = {978-1-5386-3652-7},
  langid = {english},
  file = {F\:\\Zotero文献数据\\storage\\97ZGMKZ5\\Tao et al_2018_Optimal Code Regeneration with Background Traffic Awareness in Distributed.pdf}
}
% == BibTeX quality report for taoOptimalCodeRegeneration2018:
% ? Unsure about the formatting of the booktitle
% ? Title looks like it was stored in title-case in Zotero
% ? unused Library catalog ("DOI.org (Crossref)")
% ? unused Url ("https://ieeexplore.ieee.org/document/8390329/")

@inproceedings{wangAdaptiveErasureCodedStorage2020,
  title = {An {{Adaptive Erasure-Coded Storage Scheme}} with an {{Efficient Code-Switching Algorithm}}},
  booktitle = {49th {{International Conference}} on {{Parallel Processing}} - {{ICPP}}},
  author = {Wang, Zizhong and Wang, Haixia and Shao, Airan and Wang, Dongsheng},
  year = {2020},
  month = aug,
  pages = {1--11},
  publisher = {{ACM}},
  address = {{Edmonton AB Canada}},
  doi = {10.1145/3404397.3404420},
  abstract = {Many distributed storage systems use erasure codes rather than replication for higher reliability at significantly lower storage costs. However, using traditional erasure codes increases consumption of network traffic and disk I/O tremendously when systems recover data, resulting in high latency of degraded reads. In order to mitigate this problem, we present an adaptive storage scheme based on data access skew, a fact that most data accesses are applied in a small fraction of data. In this scheme, we use both a Local Reconstruction Code (LRC) to store frequently accessed data, and a Hitchhiker (HH) code to store infrequently accessed data. Besides, an efficient switching algorithm between LRC and HH code with low network and computation costs is provided. The whole system will benefit from low degraded read latency while keeping a low storage overhead, and code-switching will not become a bottleneck. Experimental evaluation shows that this adaptive storage scheme's performance was in line with expectations.},
  isbn = {978-1-4503-8816-0},
  langid = {english},
  keywords = {Readed🌟,可看🎈},
  file = {F\:\\Zotero文献数据\\storage\\MQKSNFJE\\Wang et al_2020_An Adaptive Erasure-Coded Storage Scheme with an Efficient Code-Switching.pdf;F\:\\Zotero文献数据\\storage\\VRCANYIL\\Wang et al_2020_An Adaptive Erasure-Coded Storage Scheme with an Efficient Code-Switching.pdf}
}
% == BibTeX quality report for wangAdaptiveErasureCodedStorage2020:
% ? Unsure about the formatting of the booktitle
% ? Title looks like it was stored in title-case in Zotero
% ? unused Conference name ("ICPP '20: 49th International Conference on Parallel Processing")
% ? unused Library catalog ("DOI.org (Crossref)")
% ? unused Url ("https://dl.acm.org/doi/10.1145/3404397.3404420")

@article{wangKaoLuBaiZhanTingShuXingDeSDNAnQuanKongZhiQiDuoMuBiaoYouHuaBuShuFangAn2021,
  title = {{考虑拜占庭属性的SDN安全控制器多目标优化部署方案}},
  author = {王, 涛 and 陈, 鸿昶},
  year = {2021},
  journal = {网络与信息安全学报},
  volume = {7},
  number = {03},
  pages = {72--84},
  issn = {2096-109X},
  abstract = {通过赋予软件定义网络分布式控制平面拜占庭属性可以有效提高其安全性。在实现拜占庭属性过程中,控制器部署的数量、位置,以及交换机与控制器之间的连接关系会直接影响全局网络关键性能指标。为此,提出了一种考虑拜占庭属性的SDN安全控制器多目标优化部署方案。首先,构建了综合考量交互时延、同步时延、负载差异程度和控制器部署数量等优化指标的拜占庭控制器部署问题(MOSBCPP)模型;然后,针对该模型个性化设计了包括控制器部署策略初始化函数、变异函数,快速非支配排序函数及精英策略选择函数等在内的NASG-II求解算法。相关仿真结果表明,该部署方案能够在有效降低交互时延、同步时延、负载差异程度和控制器部署数量等性能指标的同时提高控制平面安全性。},
  langid = {chinese},
  keywords = {Byzantine attributes,controller placement,distributed control plane,multi-objective optimization,中文🌈,分布式控制平面,多目标优化 software defined network security,拜占庭属性,控制器部署,软件定义网络安全},
  file = {F\:\\Zotero文献数据\\storage\\96HS4EL6\\王_陈_2021_考虑拜占庭属性的SDN安全控制器多目标优化部署方案.pdf}
}
% == BibTeX quality report for wangKaoLuBaiZhanTingShuXingDeSDNAnQuanKongZhiQiDuoMuBiaoYouHuaBuShuFangAn2021:
% ? unused Library catalog ("CNKI")
% ? unused Url ("https://kns.cnki.net/KCMS/detail/detail.aspx?dbcode=CJFD&dbname=CJFDLAST2021&filename=WXAQ202103006&v=")

@article{wangRepairableFountainCoded2019,
  title = {Repairable {{Fountain Coded Storage Systems}} for {{Multi-tier Mobile Edge Caching Networks}}},
  author = {Wang, Ye and Gu, Shushi and Zhao, Lian and Zhang, Ning and Xiang, Wei and Zhang, Qinyu},
  year = {2019},
  journal = {IEEE Transactions on Network Science and Engineering},
  pages = {1--1},
  issn = {2327-4697, 2334-329X},
  doi = {10.1109/TNSE.2019.2932727},
  abstract = {Mobile edge caching (MEC) is an emerging paradigm where cloud services are extended to base stations (BSs) and devices to support a variety of applications and services in the Internet of Things (IoT). It expects to exploit storage resources deployed at different BSs and idle resources of end devices to efficiently cache and deliver contents. However, frequent mobility of devices with cached data can lead to data loss. Therefore, it becomes an important yet very challenging issue to cache the massive data with high data fault-tolerance and low cost. In this paper, we consider a multi-tier MEC network, where cloud-BS, edge-BSs and mobile devices collaboratively store and deliver contents to users. In addition, a framework based on repairable fountain codes (RFCs) with unequal repair locality (URL) for data caching, repairing and downloading, termed URL-RFC, is proposed to achieve efficient data caching in multi-tier heterogeneous MEC networks. Furthermore, a theoretical analysis and simulation results are provided to analyze and compare the energy costs of URL-RFC and existing solutions. It is demonstrated that the proposed URL-RFC scheme outperforms other redundant fault-tolerant schemes, which validates the potential value and feasibility of URL-RFC enabled storage in multi-tier MEC networks.},
  langid = {english},
  file = {F\:\\Zotero文献数据\\storage\\ZJP9WRN2\\Wang et al_2019_Repairable Fountain Coded Storage Systems for Multi-tier Mobile Edge Caching.pdf}
}
% == BibTeX quality report for wangRepairableFountainCoded2019:
% ? unused Journal abbreviation ("IEEE Trans. Netw. Sci. Eng.")
% ? unused Library catalog ("DOI.org (Crossref)")
% ? unused Url ("https://ieeexplore.ieee.org/document/8786259/")

@article{wangSymmetricPrivateInformation2019,
  title = {Symmetric {{Private Information Retrieval}} from {{MDS Coded Distributed Storage With Non-Colluding}} and {{Colluding Servers}}},
  author = {Wang, Qiwen and Skoglund, Mikael},
  year = {2019},
  month = aug,
  journal = {IEEE Transactions on Information Theory},
  volume = {65},
  number = {8},
  pages = {5160--5175},
  issn = {0018-9448, 1557-9654},
  doi = {10.1109/TIT.2019.2903206},
  file = {F\:\\Zotero文献数据\\storage\\II3WZB9V\\Wang_Skoglund_2019_Symmetric Private Information Retrieval from MDS Coded Distributed Storage With.pdf}
}
% == BibTeX quality report for wangSymmetricPrivateInformation2019:
% ? Title looks like it was stored in title-case in Zotero
% ? unused Journal abbreviation ("IEEE Trans. Inform. Theory")
% ? unused Library catalog ("DOI.org (Crossref)")
% ? unused Url ("https://ieeexplore.ieee.org/document/8660467/")

@article{wangYiZhongHunHeJuBuHuiFuMaJiHitchhikerMaDeCunChuCeLue2020,
  title = {{一种混合局部恢复码及Hitchhiker码的存储策略}},
  author = {王, 梓仲 and 王, 海霞 and 邵, 艾然 and 汪, 东升},
  year = {2020},
  journal = {计算机学报},
  volume = {43},
  number = {04},
  pages = {618--630},
  issn = {0254-4164},
  abstract = {我们正处于一个大数据的时代.如今一个分布式存储系统需要存放PB数量级数据的情况越来越常见.这些系统一般由普通商用组件构成,其出错率相对较高.由此,分布式存储系统需要保证数据的可靠性和可用性.多副本和纠删码是现在最为常用的技术.相比多副本技术,采用纠删码能在同等容错能力下大幅降低存储开销.然而,在进行数据恢复时,使用传统的纠删码(如Reed-Solomon码)会导致系统中产生大量的网络带宽消耗及磁盘读写操作,进而导致退化读延迟过高.注意到在系统中数据的访问频率呈Zipf分布,大多数数据访问只涉及到少量数据,而绝大多数数据的被访频率很低.根据这种数据访问的偏斜性,本文提出如下存储策略以解决采用纠删码的系统退化读延迟过高的问题:对被访频率高的热数据采用低恢复延迟的纠删码(如局部恢复码Local Reconstruction Code,LRC)进行编码,而对被访频率低的冷数据采用保证最小存储开销的纠删码(如Hitchhiker码)进行编码.由于热数据占据了绝大多数的数据访问,因此绝大多数的退化读也将应用在这些热数据上,这样这一策略就能在整个系统的角度获取低恢复开销的优势.同时,冷数据占据了系统绝大多数的数据量,且冷数据由保证最小存储开销的编码进行存储,因此这一策略的存储开销会很低.然而,对于混合存储策略而言,热数据可能会变冷,而冷数据也可能会变热,因此它需要配置一种编码切换过程.一个不恰当的编码切换过程会引起巨大的数据传输量,这是难以让人接受的.为了避免这一缺陷,本文提出了一种LRC和Hitchhiker码之间的高效切换算法.这一算法可以避免上述策略在部署时因冷热数据的转换出现系统瓶颈.在精心选取了两种编码并提出它们之间的高效切换算法后,本文提出的混合存储策略避免了现阶段其余混合存储策略的主要缺点.通过实验验证,此存储策略相较传统的ReedSolomon码在退化读延迟方面降低了55. 8\%.在编码切换方面,切换延迟能分别降低为重新编码算法用时的13. 4\%及33. 1\%,且当数据从LRC切换为Hitchhiker码时(更为频繁出现的情况)的数据传输量能降至10\%.},
  langid = {chinese},
  keywords = {AdaptiveCode🌏,code switch,degraded read,fault tolerance,Reading🌟,storage,中文🌈,可看🎈,存储 erasure code,容错,纠删码,编码切换,退化读},
  annotation = {{$<$}北大核心, EI, CSCD{$>$}},
  file = {F\:\\Zotero文献数据\\storage\\KTTXRPZY\\王 et al_2020_一种混合局部恢复码及Hitchhiker码的存储策略.pdf}
}
% == BibTeX quality report for wangYiZhongHunHeJuBuHuiFuMaJiHitchhikerMaDeCunChuCeLue2020:
% ? unused Library catalog ("CNKI")
% ? unused Url ("https://kns.cnki.net/KCMS/detail/detail.aspx?dbcode=CJFD&dbname=CJFDLAST2020&filename=JSJX202004003&v=")

@article{weiNewAdaptiveCoding2018,
  title = {A {{New Adaptive Coding Selection Method}} for {{Distributed Storage Systems}}},
  author = {Wei, Bing and Xiao, Li Min and Wei, Wei and Song, Yao and Zhou, Bing Yu},
  year = {2018},
  journal = {IEEE Access},
  volume = {6},
  number = {c},
  pages = {13350--13357},
  issn = {21693536},
  doi = {10.1109/ACCESS.2018.2801265},
  abstract = {Erasure codes, such as Reed-Solomon (RS) codes and local reconstruction codes (LRCs), are being increasingly adopted in distributed storage systems since they offer lower redundancy than data replication. While these codes significantly save storage space, they can incur large I/O overhead and network traffic in reconstructing unavailable data. Most existing storage systems use replication for hot data and an erasure code for warm and cold data, thereby achieving a good tradeoff between storage overhead and recovery performance. However, these storage systems do not take the access characteristics of data into account and tend to use only an erasure code, which hinders the possibility of reducing storage overhead and recovery cost. In this paper, we propose a new adaptive coding selection method that instead uses multiple LRCs for warm data. The LRCs are selected based on the access characteristics of the data. Each time a file is accessed, we assume that each of the involved data blocks is unavailable, in turn. It is necessary to calculate the I/O cost to recover unavailable blocks for different LRCs. The sum of the I/O costs for each LRC is calculated, and the LRC with the minimal I/O cost is selected for warm data. For cold data, we use an RS code that is optimized for storage overhead to reduce the storage burden. Our method is implemented on the top of the Hadoop distributed file system. Evaluations show that it reduces the storage overhead by up to 5\% and the reconstruction traffic by up to 22\%.},
  keywords = {access characteristics,AdaptiveCode🌏,Erasure codes,Reading🌟,reconstruction cost,storage overhead},
  file = {F\:\\Zotero文献数据\\storage\\6HFI6YSN\\Wei et al_2018_A New Adaptive Coding Selection Method for Distributed Storage Systems.pdf}
}
% == BibTeX quality report for weiNewAdaptiveCoding2018:
% ? Title looks like it was stored in title-case in Zotero

@article{weiNewAdaptiveCoding2018a,
  title = {A {{New Adaptive Coding Selection Method}} for {{Distributed Storage Systems}}},
  author = {Wei, Bing and Xiao, Li-Min and Wei, Wei and Song, Yao and Zhou, Bing-Yu},
  year = {2018},
  journal = {IEEE Access},
  volume = {6},
  pages = {13350--13357},
  issn = {2169-3536},
  doi = {10/gjxkhw},
  keywords = {AdaptiveCode🌏,Reading🌟,可看🎈},
  file = {F\:\\Zotero文献数据\\storage\\XXDGVRST\\Wei et al_2018_A New Adaptive Coding Selection Method for Distributed Storage Systems.pdf}
}
% == BibTeX quality report for weiNewAdaptiveCoding2018a:
% ? Title looks like it was stored in title-case in Zotero
% ? unused Library catalog ("DOI.org (Crossref)")
% ? unused Url ("https://ieeexplore.ieee.org/document/8279436/")

@article{wenJiYuShenDuXueXiDeDaNaoXingBieChaiYiFenXi2021,
  title = {{基于深度学习的大脑性别差异分析}},
  author = {温, 景熙 and 于, 胡飞 and 辛, 江 and 唐, 艳},
  year = {2021},
  journal = {大数据},
  volume = {7},
  number = {04},
  pages = {130--140},
  issn = {2096-0271},
  abstract = {深度学习被广泛应用于大脑的相关研究中。通过构建深度学习模型对弥散张量成像数据的各向异性分数进行了性别分类,并通过深度学习特征可视化方法提取了不同性别的重要特征,最后对可视化结果进行了基于体素的分析。结果显示,提出的模型能够准确预测性别,并且达到了96.2\%的分类准确率。在可视化的结果中,发现男女大脑之间存在明显差异,其中存在差异的脑区主要表现在胼胝体、顶叶下叶和基底神经节等,这些脑区揭示了男女之间的大脑差异可能与运动能力、数学运算、身体形象感知和情绪控制等方面的能力相关。},
  langid = {chinese},
  keywords = {deep learning,diffusion tensor imaging,feature visualization,gender classification,中文🌈,弥散张量成像,性别分类,深度学习,特征可视化},
  file = {F\:\\Zotero文献数据\\storage\\2VDBBTUA\\温 et al_2021_基于深度学习的大脑性别差异分析.pdf}
}
% == BibTeX quality report for wenJiYuShenDuXueXiDeDaNaoXingBieChaiYiFenXi2021:
% ? unused Library catalog ("CNKI")
% ? unused Url ("https://t.cnki.net/kcms/detail?v=2RSegAH8zSpqrJcVZN72pSGWcq4lCVu8nPxTR3G4HnfDUoGeCAoBPLiC-fdQy1KR0kjVUsvA9BZfqVetwoQO89UWwzS8H11bfsZq8gjWYOxJza9Bl234QIx9936CyMul&uniplatform=NZKPT")

@inproceedings{wuOptimalRepairScalingTradeoff2020,
  title = {On the {{Optimal Repair-Scaling Trade-off}} in {{Locally Repairable Codes}}},
  booktitle = {{{IEEE INFOCOM}} 2020 - {{IEEE Conference}} on {{Computer Communications}}},
  author = {Wu, Si and Shen, Zhirong and Lee, Patrick P. C.},
  year = {2020},
  month = jul,
  pages = {2155--2164},
  publisher = {{IEEE}},
  address = {{Toronto, ON, Canada}},
  doi = {10/ghkk6f},
  isbn = {978-1-72816-412-0},
  keywords = {CUHK📕,Reading🌟,可看🎈},
  annotation = {00000},
  file = {F\:\\Zotero文献数据\\storage\\FQCPQSHP\\Wu et al_2020_On the Optimal Repair-Scaling Trade-off in Locally Repairable Codes.pdf;F\:\\Zotero文献数据\\storage\\4WL5A5PJ\\lrctradeoff.html}
}
% == BibTeX quality report for wuOptimalRepairScalingTradeoff2020:
% ? Unsure about the formatting of the booktitle
% ? Title looks like it was stored in title-case in Zotero
% ? unused Library catalog ("DOI.org (Crossref)")
% ? unused Url ("https://ieeexplore.ieee.org/document/9155417/")

@article{xiaTaleTwoErasure,
  title = {A {{Tale}} of {{Two Erasure Codes}} in {{HDFS}}},
  author = {Xia, Mingyuan and Saxena, Mohit and Blaum, Mario and Pease, David A},
  pages = {15},
  abstract = {Distributed storage systems are increasingly transitioning to the use of erasure codes since they offer higher reliability at significantly lower storage costs than data replication. However, these codes tradeoff recovery performance as they require multiple disk reads and network transfers for reconstructing an unavailable data block. As a result, most existing systems use an erasure code either optimized for storage overhead or recovery performance. In this paper, we present HACFS, a new erasure-coded storage system that instead uses two different erasure codes and dynamically adapts to workload changes. It uses a fast code to optimize for recovery performance and a compact code to reduce the storage overhead. A novel conversion mechanism is used to efficiently upcode and downcode data blocks between fast and compact codes. We show that HACFS design techniques are generic and successfully apply it to two different code families: Product and LRC codes.},
  langid = {english},
  keywords = {AdaptiveCode🌏,Reading🌟,可看🎈},
  annotation = {00000},
  file = {F\:\\Zotero文献数据\\storage\\PR8ZJ7PU\\Xia et al_A Tale of Two Erasure Codes in HDFS.pdf}
}
% == BibTeX quality report for xiaTaleTwoErasure:
% Missing required field 'journal'
% Missing required field 'year'
% ? Title looks like it was stored in title-case in Zotero
% ? unused Library catalog ("Zotero")

@inproceedings{xieAZCodeEfficientAvailability2019,
  title = {{{AZ-Code}}: {{An Efficient Availability Zone Level Erasure Code}} to {{Provide High Fault Tolerance}} in {{Cloud Storage Systems}}},
  shorttitle = {{{AZ-Code}}},
  booktitle = {2019 35th {{Symposium}} on {{Mass Storage Systems}} and {{Technologies}} ({{MSST}})},
  author = {Xie, Xin and Wu, Chentao and Gu, Junqing and Qiu, Han and Li, Jie and Guo, Minyi and He, Xubin and Dong, Yuanyuan and Zhao, Yafei},
  year = {2019},
  month = may,
  pages = {230--243},
  publisher = {{IEEE}},
  address = {{Santa Clara, CA, USA}},
  doi = {10.1109/MSST.2019.00004},
  abstract = {As data in modern cloud storage system grows dramatically, it's a common method to partition data and store them in different Availability Zones (AZs). Multiple AZs not only provide high fault tolerance (e.g., rack level tolerance or disaster tolerance), but also reduce the network latency. Replication and Erasure Codes (EC) are typical data redundancy methods to provide high reliability for storage systems. Compared with the replication approach, erasure codes can achieve much lower monetary cost with the same fault-tolerance capability. However, the recovery cost of EC is extremely high in multiple AZ environment, especially because of its high bandwidth consumption in data centers. LRC is a widely used EC to reduce the recovery cost, but the storage efficiency is sacrificed. MSR code is designed to decrease the recovery cost with high storage efficiency, but its computation is too complex.},
  isbn = {978-1-72813-920-3},
  langid = {english},
  keywords = {可看🎈},
  file = {F\:\\Zotero文献数据\\storage\\MUJ7YRAA\\Xie 等。 - 2019 - AZ-Code An Efficient Availability Zone Level Eras.pdf}
}
% == BibTeX quality report for xieAZCodeEfficientAvailability2019:
% ? Unsure about the formatting of the booktitle
% ? Title looks like it was stored in title-case in Zotero
% ? unused Library catalog ("DOI.org (Crossref)")
% ? unused Url ("https://ieeexplore.ieee.org/document/8890228/")

@article{xuDeterministicDataDistribution2020,
  title = {Deterministic {{Data Distribution}} for {{Efficient Recovery}} in {{Erasure-Coded Storage Systems}}},
  author = {Xu, L. and Lyu, M. and Li, Z. and Li, Y. and Xu, Y.},
  year = {2020},
  month = oct,
  journal = {IEEE Transactions on Parallel and Distributed Systems},
  volume = {31},
  number = {10},
  pages = {2248--2262},
  issn = {1558-2183},
  doi = {10.1109/TPDS.2020.2987837},
  abstract = {Due to individual unreliable commodity components, failures are common in large-scale distributed storage systems. Erasure codes are widely deployed in practical storage systems to provide fault tolerance with low storage overhead. However, random data distribution (RDD), commonly used in erasure-coded storage systems, induces heavy cross-rack traffic, load imbalance, and random access, which adversely affects failure recovery. In this article, with orthogonal arrays, we define a Deterministic Data Distribution (D3) to uniformly distribute data/parity blocks among nodes, and propose an efficient failure recovery approach based on D3, which minimizes the cross-rack repair traffic against a single node failure. Thanks to the uniformity of D3, the proposed recovery approach balances the repair traffic not only among nodes within a rack but also among racks. We implement D3 over Reed-Solomon codes and Locally Repairable Codes in Hadoop Distributed File System (HDFS) with a cluster of 28 machines. Compared with RDD, our experiments show that D3 significantly speeds up the failure recovery up to 2.49 times for RS codes and 1.38 times for LRCs. Moreover, D3 supports front-end applications better than RDD in both of normal and recovery states.},
  keywords = {Arrays,Bandwidth,cross-rack repair traffic,cross-rack traffic,deterministic data distribution,distributed databases,Distributed storage system,erasure codes,erasure coding,erasure-coded storage systems,failure recovery approach,Fault tolerance,fault tolerant computing,Fault tolerant systems,file organisation,Hadoop distributed file system,large-scale distributed storage systems,Layout,load balance,locally repairable codes,Maintenance engineering,network operating systems,orthogonal array,parallel processing,random data distribution,RDD,Reading🌟,Reed-Solomon codes,storage management,storage overhead,system recovery,telecommunication network reliability,telecommunication traffic,traffic,可看🎈},
  file = {F\:\\Zotero文献数据\\storage\\H5S32ZH6\\Xu et al_2020_Deterministic Data Distribution for Efficient Recovery in Erasure-Coded Storage.pdf;F\:\\Zotero文献数据\\storage\\HRAFXJVX\\Xu et al_2020_Deterministic Data Distribution for Efficient Recovery in Erasure-Coded Storage.pdf;F\:\\Zotero文献数据\\storage\\KACDSHH7\\9069296.html;F\:\\Zotero文献数据\\storage\\XDH8MXHD\\9069296.html}
}
% == BibTeX quality report for xuDeterministicDataDistribution2020:
% ? Title looks like it was stored in title-case in Zotero
% ? unused Library catalog ("IEEE Xplore")

@phdthesis{xuFenBuShiCunChuXiTongZhongJiuShanMaDeShuJuXiuFuJiShuYanJiu2013,
  type = {{硕士}},
  title = {{分布式存储系统中纠删码的数据修复技术研究}},
  author = {许, 方亮},
  year = {2013},
  abstract = {在``大数据''时代背景下,信息技术产业已从以计算为核心的时代进入到了以存储为核心的时代,数据海量化成为了一种趋势。构建于普通服务器集群之上的分布式存储系统,因其成本低廉和扩展性高等优点被广泛应用于海量数据的存储。但是分布式存储系统节点规模庞大且单个节点可靠性不高,致使系统发生节点失效的概率大为提高。为了保证数据可靠性,系统必须采用一定的数据容错技术。纠删码作为一种可靠性高且存储空间消耗少的容错技术,对提高分布式存储系统的数据可靠性并降低其经济成本具有重大意义。但是纠删码数据修复网络负载高、数据修复速度低等问题严重阻碍了其在分布式存储系统中的广泛应用。针对以上问题,本文对纠删码的低网络负载数据修复技术和快速数据修复技术进行了深入研究,主要研究内容与贡献如下:数据修复网络负载的传统度量指标是传输的数据量,这一指标忽略了数据传输距离的不同,不能精确衡量修复过程中数据传输对网络性能产生的影响。针对此问题,本文提出了基于网络拓扑的网络负载度量指标:网络代价。网络代价将数据传输的网络负载定义为数据传输量与传输距离的乘积,更精确地描述了数据传输所占用的网络资源,从而更好地刻画了数据传输对网络性能造成的影响。实验结果表明,网络代价能够比数据传输量更加精确地反映数据传输对网络性能造成的影响,是更好的网络负载度量指标。针对纠删码数据修复网络代价过高的不足,本文提出了一种基于网络拓扑的树型数据修复技术NTree。NTree根据网络拓扑将参与修复的节点组织成总网络距离最小的树型修复结构(修复树),以最小化修复时数据的传输距离,从而使修复的网络代价达到最低。在此基础上,提出了提供节点组合的选择算法OpTree。OpTree能够在从所有可用节点中快速选取最优提供节点组合的同时构建出最优的修复树,进一步降低NTree的网络代价。大量的模拟实验结果表明,NTree相比于现有的星型修复方法,可将纠删码数据修复的网络代价降低20\%-45\%。针对纠删码数据修复速度慢导致退化读性能差的问题,提出了一种基于网络拓扑的线型数据修复技术NLine。对NTree修复过程的深入分析表明,修复速度与修复树的最大入度成反比。NLine根据网络拓扑将参与修复的节点组织成最大入度为1的线型修复结构(修复路径),从而达到了最快的修复速度。同时,为了尽量降低NLine的网络代价,提出了近似最优的修复路径规划算法OpLine。大量模拟实验结果表明,NLine能够以接近于NTree网络代价获得至少比星型修复方法高400\%,比NTree高100\%的修复速度。基于上述理论研究成果,设计实现了一个纠删码数据修复原型系统ECRepair。ECRepair完全遵循机制与策略分离的设计原则,不仅支持基于网络拓扑的树型数据修复技术NTree和基于网络拓扑的线型数据修复技术NLine,也可以方便地添加对其它树型修复技术的支持,并且适用于任何线性纠删码。大量真实环境下的实验结果表明,在星型修复方法、基于网络拓扑的树型数据修复技术NTree和基于网络拓扑的线型数据修复技术NLine中,NTree具有最低的网络代价和最高的并行修复速度,NLine具有最快的串行修复速度和最高的退化读性能,进一步验证了理论分析和模拟实验的结果。},
  collaborator = {王, 意洁},
  langid = {chinese},
  school = {国防科学技术大学},
  keywords = {Data Repair,Erasure Codes,中文🌈,分布式存储,数据修复 Distributed Storage,硕士🎓,纠删码},
  annotation = {4 citations(CNKI)[2021-04-21]},
  file = {F\:\\Zotero文献数据\\storage\\MJDCT7PG\\分布式存储系统中纠删码的数据修复技术研究_许方亮.caj}
}
% == BibTeX quality report for xuFenBuShiCunChuXiTongZhongJiuShanMaDeShuJuXiuFuJiShuYanJiu2013:
% ? unused Library catalog ("CNKI")
% ? unused Url ("https://kns.cnki.net/KCMS/detail/detail.aspx?dbcode=CMFD&dbname=CMFD201601&filename=1015958262.nh&v=")

@inproceedings{xuPDLDataLayout2020,
  title = {{{PDL}}: {{A Data Layout}} towards {{Fast Failure Recovery}} for {{Erasure-coded Distributed Storage Systems}}},
  shorttitle = {{{PDL}}},
  booktitle = {{{IEEE INFOCOM}} 2020 - {{IEEE Conference}} on {{Computer Communications}}},
  author = {Xu, L. and Lv, M. and Li, Z. and Li, C. and Xu, Y.},
  year = {2020},
  month = jul,
  pages = {736--745},
  issn = {2641-9874},
  doi = {10.1109/INFOCOM41043.2020.9155350},
  abstract = {Erasure coding becomes increasingly popular in distributed storage systems (DSSes) for providing high reliability with low storage overhead. However, traditional random data placement causes massive cross-rack traffic and severely unbalanced load during failure recovery, degrading the recovery performance significantly. In addition, various erasure coding policies coexisting in a DSS exacerbates the above problem. In this paper, we propose PDL, a PBD-based Data Layout, to optimize failure recovery performance in DSSes. PDL is constructed based on Pairwise Balanced Design, a combinatorial design scheme with uniform mathematical properties, and thus presents a uniform data layout. Then we propose rPDL, a failure recovery scheme based on PDL. rPDL reduces cross-rack traffic effectively and provides nearly balanced cross-rack traffic distribution by uniformly choosing replacement nodes and retrieving determined available blocks to recover the lost blocks. We implemented PDL and rPDL in Hadoop 3.1.1. Compared with existing data layout of HDFS, experimental results show that rPDL reduces degraded read latency by an average of 62.83\%, delivers 6.27\texttimes{} data recovery throughput, and provides evidently better support for front-end applications.},
  keywords = {6.27× data recovery throughput,Bandwidth,combinatorial design scheme,combinatorial mathematics,computer networks,cross-rack traffic distribution,data handling,Decoding,distributed processing,DSS,DSSes,Encoding,erasure coding policies,erasure-coded distributed storage systems,existing data layout,failure recovery performance,failure recovery scheme,fast failure recovery,Fault tolerance,Fault tolerant systems,file organisation,high reliability,Layout,low storage overhead,massive cross-rack traffic,optimisation,Pairwise Balanced Design,parallel processing,PBD-based Data Layout,PDL,rPDL,severely unbalanced load,software fault tolerance,storage management,Switches,telecommunication network reliability,telecommunication traffic,traditional random data placement,uniform data layout,uniform mathematical properties},
  file = {F\:\\Zotero文献数据\\storage\\2AWGIGF7\\Xu et al_2020_PDL.pdf;F\:\\Zotero文献数据\\storage\\3SRW5TUS\\Xu et al_2020_PDL.pdf;F\:\\Zotero文献数据\\storage\\49XWZRPT\\9155350.html;F\:\\Zotero文献数据\\storage\\7289BVP2\\9155350.html}
}
% == BibTeX quality report for xuPDLDataLayout2020:
% ? Unsure about the formatting of the booktitle
% ? unused Library catalog ("IEEE Xplore")

@article{xuSelectiveECSelectiveReconstruction,
  title = {{{SelectiveEC}}: {{Selective Reconstruction}} in {{Erasure-coded Storage Systems}}},
  author = {Xu, Liangliang and Lyu, Min and Li, Qiliang and Xie, Lingjiang and Xu, Yinlong},
  pages = {7},
  abstract = {Erasure coding has been a commonly used approach to provide high reliability with low storage cost. But the skewed load in a recovery batch severely slows down the failure recovery process in storage systems. To this end, we propose a balanced scheduling module, SelectiveEC, which schedules reconstruction tasks out of order by dynamically selecting some stripes to be reconstructed into a batch and selecting source nodes and replacement nodes for each reconstruction task. So it achieves balanced network recovery traffic, computing resources and disk I/Os against single node failure in erasure-coded storage systems. Compared with conventional random reconstruction, SelectiveEC increases the parallelism of recovery process up to 106\% and averagely bigger than 97\% in our simulation. Therefore, SelectiveEC not only speeds up recovery process, but also reduces the interference of failure recovery on the front-end applications.},
  langid = {english},
  keywords = {Reading🌟,可看🎈},
  annotation = {00000},
  file = {F\:\\Zotero文献数据\\storage\\7M2PUFQ9\\Xu et al_SelectiveEC.pdf}
}
% == BibTeX quality report for xuSelectiveECSelectiveReconstruction:
% Missing required field 'journal'
% Missing required field 'year'
% ? unused Library catalog ("Zotero")

@article{xuYiZhongJiYuJiuShanMaDeDuoJieDianShiXiaoXiuFuSuanFa2021,
  title = {{一种基于纠删码的多节点失效修复算法}},
  author = {徐, 家冰 and 朱, 浩辰 and 杨, 丽},
  year = {2021},
  journal = {计算机与现代化},
  number = {3},
  pages = {18--23},
  issn = {1006-2475},
  abstract = {纠删码作为分布式系统中重要的数据容错技术,在失效数据的修复领域有着广泛应用。但现有的纠删码算法大多针对单节点修复,修复成本较高,且未考虑新生节点间的信息传递,给多失效节点的修复带来不便。基于此,提出一种基于纠删码的多节点失效修复算法,该算法在新生节点中利用节点选择策略选取中心节点为根节点,并依据链路带宽分别与供应节点和剩余新生节点构建最大修复树,从而降低数据修复时长。实验结果表明,与现有的BHS和SSR串行修复等方法相比,该算法能有效提高多失效节点的修复效率,验证了算法的有效性。},
  langid = {chinese},
  keywords = {⛔ No DOI found,center node,link bandwidth,maximum repair tree,multi-node failure,中心节点,最大修复树 correction code,可看🎈,多节点失效,纠删码,链路带宽},
  file = {F\:\\Zotero文献数据\\storage\\YC474G88\\徐 et al_2021_一种基于纠删码的多节点失效修复算法.pdf}
}
% == BibTeX quality report for xuYiZhongJiYuJiuShanMaDeDuoJieDianShiXiaoXiuFuSuanFa2021:
% ? unused Library catalog ("CNKI")
% ? unused Url ("https://kns.cnki.net/KCMS/detail/detail.aspx?dbcode=CJFD&dbname=CJFDLAST2021&filename=JYXH202103004&v=")

@phdthesis{xuYunCunChuZhongJiYuJiuShanMaDeShuJuRongCuoJiShuYanJiu2019,
  type = {{博士}},
  title = {{云存储中基于纠删码的数据容错技术研究}},
  author = {许, 方亮},
  year = {2019},
  abstract = {构建于大量节点之上云存储方便易用、成本低廉且可弹性扩展,被广泛用来保存人们快速产生的海量数据。根据节点分布,云存储可分为单中心云存储、跨中心云存储和P2P云存储三类。前二者通过运营包含大量服务器的一个或多个数据中心来提供服务;P2P云存储则通过大量租用个人闲置的存储空间和网络带宽来提供服务。对于任何一类云存储,采用容错技术以保证数据不因节点失效而丢失都至关重要。基于纠删码的容错技术容错能力更强且存储效率更高,近年来广泛替代了传统基于副本的容错技术。然而,由于基于纠删码的容错技术更为复杂,其在云存储中面临着以下问题:(1)数据编码包括数据分块、数据运算和数据分发等操作,已有的编码方法或者消耗了过多的I/O资源或者具有低下的数据读写速度;(2)数据修复时每修复一个失效块都需要传输多个块并进行复杂的运算,已有的数据修复方法不能有效降低数据传输开销并提高数据修复效率。近年来,跨中心云存储和P2P云存储的兴起使这些问题变得更加突出。本文针对这些技术难题,综合考虑各类云存储的特点,对纠删码容错技术中的数据编码问题和数据修复问题展开深入研究,主要贡献如下:已有的数据编码方法或因需要进行容错技术转换而产生过多的网络传输和磁盘读写,或因使用离散分块方式而严重降低了数据读写速度,尤其不适用于跨中心云存储。针对此问题,本文面向单中心云存储和跨中心云存储研究提出了一种基于流水线的分布式渐进编码方法PDCE。PDCE采用连续分块,以流水线的方式将新写入的数据传输到多个节点,在数据流过编码节点的同时直接对数据进行渐进式编码并将中间数据缓存在内存中,随着数据的写入逐步地在多个编码节点上分别产生校验块,最终再存储到相应的节点上,既可获得最优的数据写入效率,也无需进行容错技术转换。通过调节编码节点的数量,PDCE可以灵活地权衡编码完成之前的容错能力与编码的网络传输开销。理论分析和单中心以及跨中心环境下的大量实验表明,PDCE能够在网络传输和磁盘读写量与数据读写效率之间取得更好的权衡。具体地,与已有的数据编码方法相比,PDCE在取得接近最优数据读写效率的同时,可将网络传输减少44.5\%\textendash 48.4\%,可将磁盘读写减少45.6\%\textendash 66.7\%。在已有的数据修复方法中,绝大部分数据传输都要经过网络拓扑中的瓶颈链路,如数据中心内部网络的核心层链路和数据中心之间的链路。这不仅严重限制了总体修复效率,也对系统中正常的数据读写造成了不利影响。针对此问题,本文面向单中心云存储和跨中心云存储研究提出了一种局部性感知的树型修复方法LATR。LATR先根据网络拓扑信息或节点之间延迟确定数据的局部性,然后根据局部性构建一棵以替代节点为根覆盖所有提供节点的最小生成树作为修复树。修复时,数据从修复树的叶节点开始向上传输,在内部节点合并后继续向上传输,依此类推,直至到达根节点完成修复。这使得距离较近的数据就近合并后再传输到较远的地方与其它数据合并,减少了经过上层链路的数据量。此外,LATR采用一种基于局部性的提供节点选择算法,可在有多种选择时迅速挑选出最优的提供节点组合。分析表明,LATR修复时的核心层流量比已有修复方法低20\%\textendash 61\%。大量实验表明,LATR可将主动修复吞吐率提高至少23\%,可将降级读取速度提升高达68\%。P2P云存储中节点的上传带宽常常远低于其下载带宽,使数据上传成为严重的性能瓶颈。已有数据修复方法均未考虑到这一特点,导致它们在P2P云存储中的数据修复效率较低。针对此问题,本文面向P2P云存储研究提出了一种基于分片的分布式星型修复方法FDSR。FDSR采用一种``分散-聚合''的双层修复框架,先将编码块分成多个大小相同的编码片,然后使用多个修复节点以星型修复方法并行地修复失效编码片,对于不同的失效编码片选用不同的提供节点组合,最后再将修复出的编码片聚合至替代节点完成修复。通过使尽可能多的可用节点作为提供节点,FDSR减少了单个提供节点需要上传的数据。采用星型方法作为底层修复方法使FDSR可以同时适用于单点失效和多点失效的修复,而多个修复节点分散修复的方式则避免了传统星型修复方法负载不均衡的问题。理论分析表明,FDSR中提供节点的上传数据量明显低于现有方法,并且FDSR的整体负载更加均衡。大量实验表明,与已有数据修复方法相比,FDSR可将单点失效时的数据修复速度提高33.2\%\textendash 87.8\%,将多点失效时的数据修复速度提高78.4\%\textendash 110.0\%。},
  collaborator = {王, 意洁},
  langid = {chinese},
  school = {国防科技大学},
  keywords = {Data Encoding,Data Fault-Tolerant,Data Recovery,Erasure Code,云存储,博士,数据修复 Cloud Storage,数据容错,数据编码,硕士🎓,纠删码},
  file = {F\:\\Zotero文献数据\\storage\\BZHXSZ82\\云存储中基于纠删码的数据容错技术研究_许方亮.caj}
}
% == BibTeX quality report for xuYunCunChuZhongJiYuJiuShanMaDeShuJuRongCuoJiShuYanJiu2019:
% ? unused Library catalog ("CNKI")
% ? unused Url ("https://kns.cnki.net/KCMS/detail/detail.aspx?dbcode=CDFD&dbname=CDFDLAST2021&filename=1020385908.nh&v=")

@article{yangFenBuShiCunChuXiTongZhongDeShuJuGaoXiaoHuanCunFangFa2021,
  title = {{分布式存储系统中的数据高效缓存方法}},
  author = {杨, 青霖 and 吴, 桂勇 and 张, 广艳},
  year = {2021},
  journal = {大数据},
  volume = {7},
  number = {02},
  pages = {147--157},
  issn = {2096-0271},
  abstract = {针对典型分布式存储系统存在的写放大、I/O路径过长、响应时延较高等问题,提出了一种基于SSD的分布式存储系统中数据高效缓存方法,采用读写旁路和懒惰缓存的缓存管理策略,以及兼顾最近访问时间和历史访问频率的缓存替换策略,并根据前台工作负载的变化情况,自适应地调整主动回刷脏数据的速率,显著提升了存储系统的读写性能。},
  langid = {chinese},
  keywords = {distributed data caching,distributed storage,lazy caching,read/write bypassing,replacement strategy,中文🌈,分布式存储,分布式数据缓存,懒惰缓存,替换策略,读写旁路},
  file = {F\:\\Zotero文献数据\\storage\\626H2END\\杨 et al_2021_分布式存储系统中的数据高效缓存方法.pdf}
}
% == BibTeX quality report for yangFenBuShiCunChuXiTongZhongDeShuJuGaoXiaoHuanCunFangFa2021:
% ? unused Library catalog ("CNKI")
% ? unused Url ("https://t.cnki.net/kcms/detail?v=2RSegAH8zSoKLpgMZLGxDUWpaXQWH_Kg0XgCBHrjSM_NsWgHuvS8qFjN04VxCylQzUs_6UFwAIzNZLVamnCNWAr1dQQV4HaskKbJ_wSXoQ-k4YkpdyGa15BkO60BZ1If&uniplatform=NZKPT")

@article{yangJiuShanMaCunChuXiTongZhongShuJuXiuFuFangFaZongShu2017,
  title = {{纠删码存储系统中数据修复方法综述}},
  author = {杨, 松霖 and 张, 广艳},
  year = {2017},
  journal = {计算机科学与探索},
  volume = {11},
  number = {10},
  pages = {1531--1544},
  issn = {1673-9418},
  abstract = {纠删码技术具有存储开销低的优势,然而在进行数据修复时面临修复时间长和对前端应用性能影响高的缺陷。给出纠删码技术中数据修复完成时间的计算模型,指出影响修复性能的关键因素,进而选取计算开销、读写开销、传输开销作为修复性能的评价标准;分析了现有研究工作如何降低计算、读写和传输3种开销,重点讨论了其关键性技术的优缺点;最后从修复性能、可靠性、存储开销等方面对现有编码方案进行对比,并指出未来可能的研究方向。},
  langid = {chinese},
  keywords = {⛔ No DOI found,data recovery,multiple replicas,performance improvement,可看🎈,多副本,性能优化 erasure codes,数据修复,纠删码},
  annotation = {17 citations(CNKI)[2022-2-18]{$<$}北大核心, CSCD{$>$}},
  file = {F\:\\Zotero文献数据\\storage\\C8UHF8DS\\杨_张_2017_纠删码存储系统中数据修复方法综述.pdf}
}
% == BibTeX quality report for yangJiuShanMaCunChuXiTongZhongShuJuXiuFuFangFaZongShu2017:
% ? unused Library catalog ("CNKI")
% ? unused Url ("https://kns.cnki.net/KCMS/detail/detail.aspx?dbcode=CJFD&dbname=CJFDLAST2017&filename=KXTS201710002&v=")

@article{yangJiYuCaiJiYuCe2020,
  title = {{基于``采集\textemdash 预测\textemdash 迁移\textemdash 反馈''机制的主动容错技术}},
  author = {杨, 洪章 and 杨, 雅辉 and 屠, 要峰 and 孙, 广宇 and 吴, 中海},
  year = {2020},
  journal = {计算机研究与发展},
  volume = {57},
  number = {02},
  pages = {306--317},
  issn = {1000-1239},
  abstract = {硬盘故障是数据中心最主要的故障,严重影响了可靠性.传统的数据容错技术一般都是通过增加数据冗余来实现的,存在缺陷.主动容错技术通过预测硬盘故障提前将数据迁移,成为研究热点.现有技术大多研究硬盘故障预测,缺乏采集、迁移、反馈的研究,难以商用.提出"采集\textemdash 预测\textemdash 迁移\textemdash 反馈"全流程主动容错机制,包括:分时硬盘信息采集方法、滑动窗口记录合并及样本构建方法、多类型硬盘故障预测方法、多盘联合数据迁移方法、预测结果二级验证及快速反馈方法.测试表明:采集硬盘信息对业务影响仅0.96\%,硬盘故障预测召回率达94.66\%,数据修复时间较传统方法减少55.10\%.该工作已在中兴通讯的数据中心稳定商用,满足了主动容错技术在高可靠、高智能、低干扰、低成本、广适用等核心目标.},
  langid = {chinese},
  keywords = {artificial intelligence,fault tolerance,operation \& maintenance,storage reliability,中文🌈,人工智能,存储可靠性,容错,硬盘故障,运维 disk failure},
  annotation = {1 citations(CNKI)[2021-07-19]{$<$}北大核心, EI, CSCD{$>$}},
  file = {F\:\\Zotero文献数据\\storage\\F4NB3AIF\\杨 et al_2020_基于“采集—预测—迁移—反馈”机制的主动容错技术.pdf}
}
% == BibTeX quality report for yangJiYuCaiJiYuCe2020:
% ? unused Library catalog ("CNKI")
% ? unused Url ("https://kns.cnki.net/KCMS/detail/detail.aspx?dbcode=CJFD&dbname=CJFDLAST2020&filename=JFYZ202002007&v=")

@article{yangSystematicPiggybackingDesign2015,
  title = {A {{Systematic Piggybacking Design}} for {{Minimum Storage Regenerating Codes}}},
  author = {Yang, Bin and Tang, Xiaohu and Li, Jie},
  year = {2015},
  journal = {IEEE Transactions on Information Theory},
  volume = {61},
  number = {11},
  pages = {5779--5786},
  issn = {00189448},
  doi = {10.1109/TIT.2015.2472524},
  abstract = {Piggybacking is an efficient method to decrease the repair bandwidth of maximum distance separable codes. In this paper, in order to reduce the repair bandwidth of parity nodes of the known minimum storage regenerating (MSR) codes with high rate, which is usually the whole amount of the original data, i.e., the maximal, a new systematic piggybacking design is proposed through an in-depth analysis of the design of piggybacking. As a result, new MSR codes are obtained with almost optimal repair bandwidth of parity nodes while retaining the optimal repair bandwidth of systematic nodes. Furthermore, MSR codes with balanced download during node repair process are presented based on the new piggybacking design.},
  keywords = {balanced download,Distributed storage,Excellent！,Inbox,MSR code,piggybacking,repair bandwidth},
  file = {F\:\\Zotero文献数据\\storage\\N623SVET\\Yang et al_2015_A Systematic Piggybacking Design for Minimum Storage Regenerating Codes.pdf}
}
% == BibTeX quality report for yangSystematicPiggybackingDesign2015:
% ? Title looks like it was stored in title-case in Zotero

@article{yeFabricZhongDeNiMingShenFenRenZhengJiShuYanJiu2021,
  title = {{Fabric中的匿名身份认证技术研究}},
  author = {叶, 岳洋 and 张, 兴兰},
  year = {2021},
  journal = {网络与信息安全学报},
  volume = {7},
  number = {03},
  pages = {134--140},
  issn = {2096-109X},
  abstract = {解决联盟链上用户的隐私问题成为加速区块链实际应用落地的关键。基于联盟链的典型代表Hyperledger Fabric平台设计了一套基于公钥基础设施的匿名身份认证方案。通过将私钥d分解为两部分,由不同的角色使用各自私钥对匿名证书生成联合签名的方式实现证书生成过程中的权限分离,并解决匿名证书追踪过程中的单点攻击问题。分析表明,改进后的方案能够以更低的计算和存储开销,实现比原有方案更高的安全性。},
  langid = {chinese},
  keywords = {anonymous identity authentication,asymmetric encryption,Hyperledger Fabric,PKI,中文🌈,公钥基础设施,匿名身份认证,网络与信息安全学报🌊,联盟链,超级账本,非对称加密 consortium blockchain},
  file = {F\:\\Zotero文献数据\\storage\\UVJMBFUD\\叶_张_2021_Fabric中的匿名身份认证技术研究.pdf}
}
% == BibTeX quality report for yeFabricZhongDeNiMingShenFenRenZhengJiShuYanJiu2021:
% ? unused Library catalog ("CNKI")
% ? unused Url ("https://kns.cnki.net/KCMS/detail/detail.aspx?dbcode=CJFD&dbname=CJFDLAST2021&filename=WXAQ202103012&v=")

@article{yeHybridCodesFlexible2020,
  title = {Hybrid {{Codes}}: {{Flexible Erasure Codes}} with {{Optimized Recovery Performance}}},
  shorttitle = {Hybrid {{Codes}}},
  author = {Ye, Liuqing and Feng, Dan and Hu, Yuchong and Wei, Xueliang},
  year = {2020},
  month = nov,
  journal = {ACM Transactions on Storage},
  volume = {16},
  number = {4},
  pages = {1--26},
  issn = {1553-3077, 1553-3093},
  doi = {10.1145/3407193},
  abstract = {Erasure codes are being extensively deployed in practical storage systems to prevent data loss with low redundancy. However, these codes require excessive disk I/Os and network traffic for recovering unavailable data. Among all erasure codes, Minimum Storage Regenerating (MSR) codes can achieve optimal repair bandwidth under the minimum storage during recovery, but some open issues remain to be addressed before applying them in real systems.             Facing with the huge burden during recovery, erasure-coded storage systems need to be developed with high repair efficiency. Aiming at this goal, a new class of coding scheme is introduced\textemdash Hybrid Regenerating Codes (Hybrid-RC). The codes utilize the superiority of MSR codes to compute a subset of data blocks while some other parity blocks are used for reliability maintenance. As a result, our design is near-optimal with respect to storage and network traffic and shows great improvements in recovery performance.},
  langid = {english},
  keywords = {可看🎈},
  file = {F\:\\Zotero文献数据\\storage\\W6P4WKHA\\Ye 等。 - 2020 - Hybrid Codes Flexible Erasure Codes with Optimize.pdf}
}
% == BibTeX quality report for yeHybridCodesFlexible2020:
% ? Title looks like it was stored in title-case in Zotero
% ? unused Journal abbreviation ("ACM Trans. Storage")
% ? unused Library catalog ("DOI.org (Crossref)")
% ? unused Url ("https://dl.acm.org/doi/10.1145/3407193")

@inproceedings{yeHybridRCFlexibleErasure2017,
  title = {Hybrid-{{RC}}: {{Flexible Erasure Codes}} with {{Optimized Recovery Performance}} and {{Low Storage Overhead}}},
  shorttitle = {Hybrid-{{RC}}},
  booktitle = {2017 {{IEEE}} 36th {{Symposium}} on {{Reliable Distributed Systems}} ({{SRDS}})},
  author = {Ye, Liuqing and Feng, Dan and Hu, Yuchong and Liu, Qing},
  year = {2017},
  month = sep,
  pages = {124--133},
  doi = {10/gjxkhx},
  abstract = {Erasure codes are widely used in practical storage systems to prevent disk failure and data loss. However, these codes require excessive disk I/Os and network traffic for recovering unavailable data. As a result, the recovery performance of erasure codes is suboptimal. Among all erasure codes, Minimum Storage Regenerating (MSR) codes can achieve optimal repair bandwidth under the minimum storage during recovery, but some open issues remain to be addressed before applying them in real systems. In this paper, we present Hybrid Regenerating Codes (Hybrid-RC), a new set of erasure codes with optimized recovery performance and low storage overhead. The codes utilize the superiority of MSR codes to compute a subset of data blocks while some other parity blocks are used for reliability maintenance. As a result, our design is near-optimal with respect to storage and network traffic. We show that Hybrid-RC reduces the reconstruction cost by up to 21\% compared to the Local Reconstruction Codes (LRC) with the same storage overhead. Most importantly, in Hybrid-RC, each block contributes only half the amount of data when processing a single block failure. Therefore, the number of I/Os consumed per block is reduced by 50\%, which is of great help to balance the network load and reduce the latency.},
  keywords = {Bandwidth,degraded read,Distributed databases,Encoding,erasure code,Galois fields,I/O latency,Maintenance engineering,Reading🌟,Reliability,Systematics,可看🎈},
  file = {F\:\\Zotero文献数据\\storage\\PLE2CFC2\\Ye et al_2017_Hybrid-RC.pdf;F\:\\Zotero文献数据\\storage\\DB4D8FN4\\8069075.html}
}
% == BibTeX quality report for yeHybridRCFlexibleErasure2017:
% ? Unsure about the formatting of the booktitle
% ? Title looks like it was stored in title-case in Zotero
% ? unused Library catalog ("IEEE Xplore")

@phdthesis{youFenBuShiCunChuXiTongZhongJiYuJiuShanMaDeBeiFenYuXiuFuJiShuYanJiu2015,
  type = {{博士}},
  title = {{分布式存储系统中基于纠删码的备份与修复技术研究}},
  author = {游, 鹏飞},
  year = {2015},
  abstract = {分布式存储系统通过多节点存储和管理数据,能够实现数据的海量存储。这类系统一般采用商用服务器节点构建,节点的频繁失效使得数据的可靠性较低。纠删码技术可以通过对数据进行编码,实现数据的冗余存储,提高数据的可靠性。然而,将纠删码应用于分布式存储系统时,会出现数据插入效率低、失效数据的修复开销高、修复时间长等问题。本文针对这些问题展开研究,取得了以下成果:针对传统纠删码方案下数据插入效率较低的问题,提出了一种面向数据插入的均衡分发方法,以有效减小数据插入时间,提高插入过程的吞吐量。该方法的基本思想是:将各数据块拆分为粒度更小的数据片,利用中间节点间的传输能力转发数据片,达到并行传输的效果;将并行传输下的数据块划分方案建模为一个二次规划问题,求解出最小插入时间,获得最优的数据块划分方案。实验表明,与传统的星型数据插入模式相比,该方法降低了数据插入时间,提高了插入过程的吞吐量,提高了数据插入效率。针对纠删码在数据修复时开销较高的问题,提出了一种交织层次复合码,称为IZSHC。采用IZSHC,以有效降低数据修复时从磁盘读取的数据量和数据传输量。构建IZSHC的基本思想是:通过分解IZS码的重复码结构得到最小的IZS编码组,将IZS编码组的数据修复开销小的基本特性融合到层次码中;利用层次码的层组结构对IZS编码组进行扩展,减少数据修复时参与修复的节点数目。该方法将IZS码的重复码可分解特性与层次码的分层分组模式结合起来,从总体上降低了修复开销。实验表明,与纠删码相比,IZSHC减少了数据修复中参与的节点数目,使得修复中的总磁盘开销与总传输带宽开销降低。针对纠删码下的单节点修复方法修复时间较长的问题,提出了一种协作式的多树修复方法,以有效减小单节点修复时间。该方法的基本思想是:通过将网络中更多的可用带宽组织成多树实现对单个数据块的协作修复模式,每个树单独修复数据块的一部分,加快修复过程;通过迭代式的边交换方式尽力提高每棵树的瓶颈带宽,实现对网络带宽的充分使用,进一步减小修复时间。实验表明,与基于网络编码的单树修复模式相比,能够减小失效节点的修复时间。针对纠删码下的多节点修复方法修复时间较长的问题,提出了一种基于MSR码的多树修复方法,以有效减小节点平均修复时间。该方法的基本思想是:依次为每个失效节点构造一棵极小最大瓶颈生成树;在每次构造单树时,在不减小当前树中瓶颈带宽的前提下,将其它带宽较大的边留给余下的树的构造,提高这些树获取更大瓶颈带宽边的机会。该方法有效利用了并行多树中瓶颈带宽之间的关联特点,实现了对网络中可用带宽的高利用率。实验表明,与现有的多节点并行修复方法相比,能够减小节点的平均修复时间。},
  collaborator = {彭, 宇行},
  langid = {chinese},
  school = {国防科学技术大学},
  keywords = {data redundancy,data repair,erasure code,分布式存储,博士,数据修复 distributed storage,数据冗余,硕士🎓,纠删码},
  annotation = {1 citations(CNKI)[2022-2-18]},
  file = {F\:\\Zotero文献数据\\storage\\VMAUMCYY\\分布式存储系统中基于纠删码的备份与修复技术研究_游鹏飞.caj}
}
% == BibTeX quality report for youFenBuShiCunChuXiTongZhongJiYuJiuShanMaDeBeiFenYuXiuFuJiShuYanJiu2015:
% ? unused Library catalog ("CNKI")
% ? unused Url ("https://kns.cnki.net/KCMS/detail/detail.aspx?dbcode=CDFD&dbname=CDFDLAST2017&filename=1017834234.nh&v=")

@article{yuAchievingLoadBalancedRedundancyFree2020,
  title = {Achieving {{Load-Balanced}}, {{Redundancy-Free Cluster Caching}} with {{Selective Partition}}},
  author = {Yu, Yinghao and Zhang, Jun},
  year = {2020},
  journal = {IEEE TRANSACTIONS ON PARALLEL AND DISTRIBUTED SYSTEMS},
  volume = {31},
  number = {2},
  pages = {16},
  doi = {10.1109/TPDS.2019.2931004},
  abstract = {Data-intensive clusters increasingly rely on in-memory storages to improve I/O performance. However, the routinely observed file popularity skew and load imbalance create hot spots, which significantly degrade the benefits of in- memory caching. Common approaches to tame load imbalance include copying multiple replicas of hot files and creating parity chunks using storage codes. Yet, these techniques either suffer from high memory overhead due to cache redundancy or incur non-trivial encoding/decoding complexity. In this paper, we propose an effective approach to achieve load balancing without cache redundancy or encoding/decoding overhead. Our solution, termed SP-Cache, selectively partitions files based on the loads they contribute and evenly caches those partitions across the cluster. We develop an efficient algorithm to determine the optimal number of partitions for a hot file\textemdash too few partitions are incapable of mitigating hot spots, while too many are susceptible to stragglers. We have implemented SP-Cache atop Alluxio, a popular in-memory distributed storage system, and evaluated its performance through EC2 deployment and tracedriven simulations. SP-Cache can quickly react to the changing load by dynamically re-balancing cache servers. Compared to the state-of-the-art solution, SP-Cache reduces the file access latency by up to 40 percent in both the mean and the tail, using 40 percent less memory.},
  langid = {english},
  file = {F\:\\Zotero文献数据\\storage\\AERVQXDZ\\Yu_Zhang_2020_Achieving Load-Balanced, Redundancy-Free Cluster Caching with Selective.pdf}
}
% == BibTeX quality report for yuAchievingLoadBalancedRedundancyFree2020:
% ? Title looks like it was stored in title-case in Zotero
% ? unused Library catalog ("Zotero")

@inproceedings{zengFAGREfficientFileaware2020,
  title = {{{FAGR}}: {{An Efficient File-aware Graph Recovery Scheme}} for {{Erasure Coded Cloud Storage Systems}}},
  shorttitle = {{{FAGR}}},
  booktitle = {2020 {{IEEE}} 38th {{International Conference}} on {{Computer Design}} ({{ICCD}})},
  author = {Zeng, H. and Zhang, C. and Wu, C. and Yang, G. and Li, J. and Xue, G. and Guo, M.},
  year = {2020},
  month = oct,
  pages = {105--112},
  issn = {2576-6996},
  doi = {10/gjrd97},
  abstract = {With the explosive growth of data in cloud storage systems, Erasure Codes (ECs) have become a typical data redundancy technology because of its low storage cost and high reliability. However, due to a large amount of complex computations and transmissions among massive data and parities, the recovery of lost data in erasure coded storage systems incurs high I/O latency. Although several fast recovery approaches devote to mitigating the recovery time from the application level or device level, the performance of file level recovery is still restricted. It is because a part of the complicated relationships among data, parity and files are ignored in the design of recovery process. To address the above problems, we propose a novel File-aware Graph Recovery (FAGR) scheme, to improve the file level recovery performance during the reconstruction process. The key idea of FAGR is establishing a graph with the mappings among files, blocks, stripes, parities, nodes and the access frequencies of files, and guides the recovery process from file point of view. A corresponding model is established to analyze the cost efficiency of recovery process, which guarantees that FAGR reconstructs the popular files in advance to accelerate the recovery. To demonstrate the effectiveness of FAGR, we conduct several numerical analysis and experiments in clusters. The results show that, compared to typical fast recovery methods, FAGR reduces the average response time of files by up to 81.63 \% and improves the throughput by up to 4.44 \texttimes.},
  keywords = {Aware♥️,Cloud computing,Erasure Codes,File Recovery,Graph Processing,Parallel processing,Performance evaluation,RAID Disk Arrays,Reading🌟,Redundancy,Reliability,Throughput,Time factors,可看🎈},
  annotation = {00000},
  file = {F\:\\Zotero文献数据\\storage\\ECQKNGPM\\Zeng et al_2020_FAGR.pdf;F\:\\Zotero文献数据\\storage\\R2XHBCJT\\9283614.html}
}
% == BibTeX quality report for zengFAGREfficientFileaware2020:
% ? Unsure about the formatting of the booktitle
% ? unused Library catalog ("IEEE Xplore")

@article{zhangFenBuShiCunChuXiTongZhongDeDiXiuFuChengBenJiuShanMa2020,
  title = {{分布式存储系统中的低修复成本纠删码}},
  author = {张, 航 and 刘, 善政 and 唐, 聃 and 蔡, 红亮},
  year = {2020},
  journal = {计算机应用},
  volume = {40},
  number = {10},
  pages = {2942--2950},
  issn = {1001-9081},
  abstract = {纠删码技术是分布式存储系统中典型的数据容错方法,与多副本技术相比,能够以较低的存储开销提供较高的数据可靠性;然而,纠删码修复成本过高的特点限制了其应用。针对现有纠删码修复成本高、编码复杂和灵活性差的问题,提出一种编码简单的低修复成本的纠删码\textemdash\textemdash 旋转分组修复码(RGRC)。RGRC首先将多个条带组合成条带集,然后利用条带之间的关联关系对条带集内的数据块进行分层旋转编码,以此得到相应的冗余块。RGRC大幅度地减少了单节点修复过程中所需要读取和传输的数据量,从而能节省大量的网络带宽资源。同时RGRC在解决单节点修复成本高的问题时,依然保留着较高的容错能力,且为满足分布式存储系统的不同需求,可以灵活地权衡系统的存储开销和修复成本。在分布式存储系统中进行的对比实验分析结果展示,与其他常用的RS(Reed-Solomon)码、LRC(Locally Repairable Codes)、basic-Pyramid、DLRC(Dynamic Local Reconstruction Codes)、pLRC(proactive Locally Repairable Codes)、GRC(Group Repairable Codes)、UFP-LRC(Unequal Failure Protection based Local Reconstruction Codes)相比,RGRC只需要增加少量的存储开销,就能降低单节点修复14\%～61\%的修复成本,同时减少14\%～58\%的修复时间。},
  langid = {chinese},
  keywords = {data recovery,erasure code,low repair cost,single-node repair,中文🌈,低修复成本 distributed storage system,分布式存储系统,单节点修复,数据修复,纠删码},
  annotation = {1 citations(CNKI)[2021-07-19]{$<$}北大核心, CSCD{$>$}},
  file = {F\:\\Zotero文献数据\\storage\\6CK5BH26\\张 et al_2020_分布式存储系统中的低修复成本纠删码.pdf}
}
% == BibTeX quality report for zhangFenBuShiCunChuXiTongZhongDeDiXiuFuChengBenJiuShanMa2020:
% ? unused Library catalog ("CNKI")
% ? unused Url ("https://kns.cnki.net/KCMS/detail/detail.aspx?dbcode=CJFD&dbname=CJFDLAST2020&filename=JSJY202010024&v=")

@article{zhangFenBuShiCunChuXiTongZhongDeDiXiuFuChengBenJiuShanMa2020a,
  title = {{分布式存储系统中的低修复成本纠删码}},
  author = {张, 航 and 刘, 善政 and 唐, 聃 and 蔡, 红亮},
  year = {2020},
  journal = {计算机应用},
  volume = {40},
  number = {10},
  pages = {2942--2950},
  issn = {1001-9081},
  abstract = {纠删码技术是分布式存储系统中典型的数据容错方法,与多副本技术相比,能够以较低的存储开销提供较高的数据可靠性;然而,纠删码修复成本过高的特点限制了其应用。针对现有纠删码修复成本高、编码复杂和灵活性差的问题,提出一种编码简单的低修复成本的纠删码\textemdash\textemdash 旋转分组修复码(RGRC)。RGRC首先将多个条带组合成条带集,然后利用条带之间的关联关系对条带集内的数据块进行分层旋转编码,以此得到相应的冗余块。RGRC大幅度地减少了单节点修复过程中所需要读取和传输的数据量,从而能节省大量的网络带宽资源。同时RGRC在解决单节点修复成本高的问题时,依然保留着较高的容错能力,且为满足分布式存储系统的不同需求,可以灵活地权衡系统的存储开销和修复成本。在分布式存储系统中进行的对比实验分析结果展示,与其他常用的RS(Reed-Solomon)码、LRC(Locally Repairable Codes)、basic-Pyramid、DLRC(Dynamic Local Reconstruction Codes)、pLRC(proactive Locally Repairable Codes)、GRC(Group Repairable Codes)、UFP-LRC(Unequal Failure Protection based Local Reconstruction Codes)相比,RGRC只需要增加少量的存储开销,就能降低单节点修复14\%～61\%的修复成本,同时减少14\%～58\%的修复时间。},
  langid = {chinese},
  keywords = {⛔ No DOI found,data recovery,erasure code,low repair cost,single-node repair,低修复成本 distributed storage system,分布式存储系统,单节点修复,可看🎈,数据修复,纠删码},
  annotation = {1 citations(CNKI)[2022-2-18]{$<$}北大核心, CSCD{$>$}},
  file = {F\:\\Zotero文献数据\\storage\\UMNFGXTE\\张 et al_2020_分布式存储系统中的低修复成本纠删码.pdf}
}
% == BibTeX quality report for zhangFenBuShiCunChuXiTongZhongDeDiXiuFuChengBenJiuShanMa2020a:
% ? unused Library catalog ("CNKI")
% ? unused Url ("https://kns.cnki.net/KCMS/detail/detail.aspx?dbcode=CJFD&dbname=CJFDLAST2020&filename=JSJY202010024&v=")

@article{zhangFenBuShiCunChuXiTongZhongDeYuCeShiJiuShanMaYanJiu,
  title = {{分布式存储系统中的预测式纠删码研究}},
  author = {张, 航 and 唐, 聃 and 蔡, 红亮},
  journal = {计算机科学},
  pages = {1--16},
  issn = {1002-137X},
  abstract = {纠删码消耗的存储空间较低，获得的数据可靠性较高，因此被分布式存储系统广泛采用。但纠删码在修复数据时较高的修复成本，限制了其应用。目前，为了降低纠删码的修复成本，研究人员在分组码和再生码上投入了大量的研究。但分组码和再生码属于被动容错方式。对于一些容易出现失效的节点，采用主动容错的方式能更好地降低修复成本，维护系统的可靠性。因此，提出了一种主动容错的预测式纠删（Proactive basic-Pyramid， PPyramid）码。PPyramid码利用硬盘故障预测方法来调整basic-Pyramid码中冗余块和数据块之间的关联，将预测出的即将出现故障的硬盘划分到同一小组，使得在修复数据时，所有的读取操作在小组内进行，从而减少读取数据块的个数，节省修复成本。在基于Ceph搭建的分布式存储系统中，在多个硬盘故障修复时，将其与其他常用的纠删码进行对比。实验结果表明，PPyramid码相比basic-Pyramid码，能降低6.3\%～34.9\%的修复成本和减少7.6\%～63.6\%的修复时间；PPyramid码相比LRC码、pLRC码、SHEC码、DLRC码，能降低8.6\%～52\%的修复成本和减少10.8\%～52.4\%的修复时间。同时，PPyramid码构造灵活，具有很强的实际应用价值。},
  langid = {chinese},
  keywords = {Data repair,Erasure codes,Failure prediction,Hard disk failure,中文🌈,分布式存储系统,故障预测 Distributed storage system,数据修复,硬盘故障,纠删码},
  annotation = {00000  {$<$}北大核心, CSCD{$>$}},
  file = {F\:\\Zotero文献数据\\storage\\DHDHZ8ZM\\张 et al_分布式存储系统中的预测式纠删码研究.pdf}
}
% == BibTeX quality report for zhangFenBuShiCunChuXiTongZhongDeYuCeShiJiuShanMaYanJiu:
% Missing required field 'year'
% ? unused Library catalog ("CNKI")
% ? unused Url ("https://kns.cnki.net/KCMS/detail/detail.aspx?dbcode=CAPJ&dbname=CAPJLAST&filename=JSJA2021011100P&v=")

@article{zhangFenBuShiCunChuXiTongZhongDeYuCeShiJiuShanMaYanJiu2021,
  title = {{分布式存储系统中的预测式纠删码研究}},
  author = {张, 航 and 唐, 聃 and 蔡, 红亮},
  year = {2021},
  journal = {计算机科学},
  volume = {48},
  number = {05},
  pages = {130--139},
  issn = {1002-137X},
  abstract = {纠删码消耗的存储空间较少,获得的数据可靠性较高,因此被分布式存储系统广泛采用。但纠删码在修复数据时较高的修复成本限制了其应用。为了降低纠删码的修复成本,研究人员在分组码和再生码上进行了大量的研究。由于分组码和再生码属于被动容错方式,对于一些容易出现失效的节点,采用主动容错的方式能更好地降低修复成本,维护系统的可靠性,因此,提出了一种主动容错的预测式纠删(Proactive basic-Pyramid, PPyramid)码。PPyramid码利用硬盘故障预测方法来调整basic-Pyramid码中冗余块和数据块之间的关联,将预测出的即将出现故障的硬盘划分到同一小组,使得在修复数据时,所有的读取操作在小组内进行,从而减少读取数据块的个数,节省修复成本。在基于Ceph搭建的分布式存储系统中,在修复多个硬盘故障时,将PPyramid码与其他常用的纠删码进行对比。实验结果表明,相比basic-Pyramid码,PPyramid码能降低6.3\%～34.9\%的修复成本和减少7.6\%～63.6\%的修复时间,相比LRC码、pLRC码、SHEC码、DLRC码,能降低8.6\%～52\%的修复成本和减少10.8\%～52.4\%的修复时间。同时,PPyramid码构造灵活,具有很强的实际应用价值。},
  langid = {chinese},
  keywords = {Data repair,Erasure codes,Failure prediction,Hard disk failure,中文🌈,分布式存储系统,故障预测 Distributed storage system,数据修复,硬盘故障,纠删码},
  annotation = {Chinese Core Journals: {$<$}北大核心, CSCD{$>$}},
  file = {F\:\\Zotero文献数据\\storage\\H3KY9SD6\\张 et al_2021_分布式存储系统中的预测式纠删码研究.pdf}
}
% == BibTeX quality report for zhangFenBuShiCunChuXiTongZhongDeYuCeShiJiuShanMaYanJiu2021:
% ? unused Library catalog ("CNKI")
% ? unused Url ("https://kns.cnki.net/KCMS/detail/detail.aspx?dbcode=CJFD&dbname=CJFDLAST2021&filename=JSJA202105017&v=")

@article{zhangJiuShanMaCunChuXiTongShuJuGengXinFangFaYanJiuZongShu2020,
  title = {{纠删码存储系统数据更新方法研究综述}},
  author = {张, 耀 and 储, 佳佳 and 翁, 楚良},
  year = {2020},
  journal = {计算机研究与发展},
  volume = {57},
  number = {11},
  pages = {2419--2431},
  issn = {1000-1239},
  abstract = {在分布式存储系统中,节点故障已成为一种常态,为了保证数据的高可用性,系统通常采用数据冗余的方式.目前主要有2种冗余机制:一种是多副本,另一种是纠删码.伴随着数据量的与日俱增,多副本机制带来的效益越来越低,人们逐渐将目光转向存储效率更高的纠删码.但是纠删码本身的复杂规则导致使用纠删码的分布式存储系统的读、写、更新操作的开销相比于多副本较大.所以纠删码通常被用于冷数据或者温数据的存储,热数据这种需要频繁访问更新的场景仍然用多副本机制存储.专注于纠删码存储系统内的数据更新,从硬盘I/O、网络传输、系统优化3方面综述了目前纠删码更新相关的优化工作,对目前具有代表性的编码方案的更新性能做了对比分析,最后展望了未来研究趋势.通过分析发现目前的纠删码更新方案仍然无法获得和多副本相近的更新性能.如何在纠删码更新规则和系统架构角度优化纠删码存储系统,使其能够替换掉热数据场景下的多副本机制,降低热数据存储开销仍是未来值得深入研究的问题.},
  langid = {chinese},
  keywords = {⛔ No DOI found,data update,distributed storage systems,multiple copies,storage overhead,分布式存储系统,可看🎈,多副本,存储开销 erasure codes,数据更新,纠删码},
  annotation = {1 citations(CNKI)[2022-2-23]{$<$}北大核心, EI, CSCD{$>$}},
  file = {F\:\\Zotero文献数据\\storage\\863IJN2M\\张 et al_2020_纠删码存储系统数据更新方法研究综述.pdf}
}
% == BibTeX quality report for zhangJiuShanMaCunChuXiTongShuJuGengXinFangFaYanJiuZongShu2020:
% ? unused Library catalog ("CNKI")
% ? unused Url ("https://kns.cnki.net/KCMS/detail/detail.aspx?dbcode=CJFD&dbname=CJFDLAST2020&filename=JFYZ202011013&v=")

@phdthesis{zhangJiYuJiuShanMaDeYunCunChuXiTongKuoZhanYuXiuFuXingNengDeYanJiu2020,
  type = {{博士}},
  title = {{基于纠删码的云存储系统扩展与修复性能的研究}},
  author = {张, 晓阳},
  year = {2020},
  abstract = {随着云存储规模的不断增大,云存储系统面临数据丢失的风险也不断提升,因此云存储系统中数据可靠性问题是当前学术界和工业界关注的一大热点。为了解决该问题,云存储系统通常使用具有低存储成本的纠删码技术。区别于一般存储系统,云存储系统需要满足海量用户复杂多变的存储需求,以及提供7 \texttimes{} 24高可用的存储服务,而这给云存储系统中纠删码技术带来两大关键性科学问题,分别是纠删码的存储扩展性能较低与频繁变化的存储扩展需求之间的矛盾,以及纠删码的数据修复性能较低与云存储服务高可用性之间的矛盾。因此,针对基于纠删码的云存储系统,围绕存储扩展和数据修复的性能开展了如下四方面的研究:基于纠删码的存储扩展一般会改变编码参数而产生大量的校验块更新,从而造成巨大的带宽开销,进而影响到云存储系统提供服务的能力。针对这一问题,对广泛使用的Reed Solomon(RS)码存储扩展问题进行了深入研究。在理论上,通过信息流图模型证明基于RS码的存储扩展所消耗带宽(记为``扩展传输量'')的理论下界,并提出一种可达到下界的最优扩展传输量的理论编码构造;在系统上,根据理论结果,设计了基于网络编码的快速存储扩展算法,可达到最优或接近最优的扩展传输量。实现一个基于网络编码的快速扩展算法的分布式存储原型系统NCScale。经Amazon云平台EC2上的实验证明,NCScale的扩展时间相对于当前的最优方案Scale-RS最多可减少50\%。由于云存储系统高可用的存储需求,一种可大幅减少修复操作带来的带宽消耗进而提升系统可用性的新型编码技术\textemdash\textemdash 再生码受到广泛关注。当前对于再生码的研究主要集中在数据修复问题上,而缺乏对云存储系统极为重要的存储扩展问题的研究。针对这一问题,对再生码的存储扩展问题进行了深入研究。对两类再生码MBR码以及MSR码的扩展问题,分别提出相应的编码扩展方案。这些方案利用MBR码及MSR码的编码结构以及局部更新技术来对扩展过程进行优化,从而大幅减少了扩展过程中的网络开销。在Hadoop分布式文件系统(HDFS)中实现这两种扩展方案,并在Amazon云平台EC2上进行实验。结果表明,相对于当前集中式的扩展方案,扩展传输量分别降低了 66.5\%和43.5\%。现有的主流基于纠删码的数据修复方案均设计为在静态的网络情况下来进行快速的数据修复,而难以应对云存储中异构且快速动态变化的网络。针对这一问题,对云存储网络带宽异构且快速动态变化情况下的基于纠删码的数据修复问题进行了深入研究,提出一种灵活的基于树的流水线修复方案FTPRepair。FTPRepair利用树状结构来避免拥堵的修复链路,从而在异构的网络中进行快速的修复;且FTPRepair进一步利用软件定义网络技术实现分片级的修复来灵活应对快速动态变化的网络。FTPRepair实现在模拟器Mininet以及真实系统ECPipe中,并在Amazon 云平台EC2上进行实验。模拟和实验结果表明,相对于传统修复以及当前最优修复方案Repair-Pipelining,FTPRepair可以明显提升降级读和节点修复的性能。云存储系统通常使用大规模的磁盘来存储海量的数据,这大幅增加了系统中出现磁盘故障的频率,且这些磁盘故障分布不均匀,从而影响到云存储的高可用性。针对这一问题,将磁盘故障预测的结果与微软Azure云存储中所使用的LRC(locally repairable codes)码相结合进行了深入研究,提出一类预测式的LRC(即Proactive LRC,记为pLRC)。pLRC利用基于决策树的磁盘故障预测方法来动态调整LRC码各个分组的大小,从而使得即将发生故障的数据块在更小的组内进行更快的修复。通过MTTDL建模分析pLRC的可靠性,结果表明,pLRC的可靠性相对LRC码最多可提升113\%。在Hadoop分布式文件系统(HDFS)中实现pLRC,并在Amazon云平台EC2上进行实验。结果表明,pLRC的降级读和磁盘修复性能相对LRC码最多可提高46.8\%和47.5\%。},
  collaborator = {胡, 燏翀},
  langid = {chinese},
  school = {华中科技大学},
  keywords = {Distributed Storage System,Erasure Coded Data Repair,Erasure Coded Storage Scaling,Erasure Coding,云存储,分布式存储系统 Cloud Storage,博士,硕士🎓,纠删码,纠删码存储扩展,纠删码数据修复},
  file = {F\:\\Zotero文献数据\\storage\\WEVCGDGE\\基于纠删码的云存储系统扩展与修复性能的研究_张晓阳.caj}
}
% == BibTeX quality report for zhangJiYuJiuShanMaDeYunCunChuXiTongKuoZhanYuXiuFuXingNengDeYanJiu2020:
% ? unused Library catalog ("CNKI")
% ? unused Url ("https://kns.cnki.net/KCMS/detail/detail.aspx?dbcode=CDFD&dbname=CDFDTEMP&filename=1020351487.nh&v=")

@phdthesis{zhangMianXiangReShuJuDeFenBuShiJiuShanMaCunChuXiTongYanJiuYuShiXian2020,
  type = {{硕士}},
  title = {{面向热数据的分布式纠删码存储系统研究与实现}},
  author = {张, 耀},
  year = {2020},
  abstract = {随着互联网技术的快速发展,世界进入大数据时代,每天都有海量数据的产生,这使得分布式存储系统的存储开销越来越大。分布式存储系统内保证数据高可用的冗余机制使得这种情况更加恶化。目前分布式存储系统内的数据冗余机制主要有两种:一种是多副本,另一种是纠删码。相比于多副本直接将数据备份多份,纠删码利用特定编码规则生成少量冗余数据,极大地减少了存储开销。但是纠删码自身的复杂规则导致分布式存储系统的读、写、更新操作会消耗更多的CPU、网络I/O、硬盘I/O资源,从而导致相应操作的延迟较大。因此,纠删码目前主要用于冷数据或者温数据的存储来减少存储开销,需要频繁访问、更新的热数据仍然用多副本方式存储,来保证热数据的操作性能。针对纠删码存储系统在热数据存储场景下延迟较大问题,本文设计了一种基于日志结构的存储策略,LSEC(Log-Structured Erasure Coding),从系统架构角度,结合多副本和纠删码各自的优点,在提高系统存储效率的同时,满足客户端对热数据存取的性能需求。本文的主要贡献如下:(1)针对在热数据存储场景下纠删码的写、更新操作高延迟问题,设计了LSEC存储策略,借助于日志结构存储,利用非易失性缓冲暂时存储数据,确保数据的持久化和请求的低响应延迟,通过异步纠删码操作降低系统存储开销。(2)为了降低日志结构带来的频繁的垃圾回收操作对系统性能的影响,提出一种分区垃圾回收方法,根据条带粒度将存储节点划分成多个分区,垃圾回收只在在本地分区内执行,进一步改善系统性能。(3)构建了一个系统原型,实现了提出的相关策略。实验结果表明相比于基于DRAM的纠删码存储系统和基于SSD的多副本存储系统,提出的LSEC策略能够降低写、更新操作延迟约1.7倍至20倍。实验结果也表明分区垃圾回收策略能够有效降低垃圾回收活动对系统性能的影响。},
  collaborator = {翁, 楚良},
  langid = {chinese},
  school = {华东师范大学},
  keywords = {data update,distributed storage sys-tems,hot data,multiple replicas,分布式存储系统,多副本,数据更新,热数据 erasure coding,硕士🎓,纠删码},
  annotation = {1 citations(CNKI)[2022-2-23]},
  file = {F\:\\Zotero文献数据\\storage\\7PVAV5T8\\面向热数据的分布式纠删码存储系统研究与实现_张耀.caj}
}
% == BibTeX quality report for zhangMianXiangReShuJuDeFenBuShiJiuShanMaCunChuXiTongYanJiuYuShiXian2020:
% ? unused Library catalog ("CNKI")
% ? unused Url ("https://kns.cnki.net/KCMS/detail/detail.aspx?dbcode=CMFD&dbname=CMFD202002&filename=1020636365.nh&v=")

@article{zhangSimEDCSimulatorReliability2019,
  title = {{{SimEDC}}: {{A Simulator}} for the {{Reliability Analysis}} of {{Erasure-Coded Data Centers}}},
  author = {Zhang, Mi and Han, Shujie and Lee, Patrick P C},
  year = {2019},
  journal = {IEEE TRANSACTIONS ON PARALLEL AND DISTRIBUTED SYSTEMS},
  volume = {30},
  number = {12},
  pages = {13},
  doi = {10.1109/TPDS.2019.2921551},
  abstract = {Modern data centers employ erasure coding to protect data storage against failures. Given the hierarchical nature of data centers, characterizing the effects of erasure coding and redundancy placement on the reliability of erasure-coded data centers is critical yet unexplored. This paper presents a discrete-event simulator called SIMEDC, which enables us to conduct a comprehensive simulation analysis of reliability on erasure-coded data centers. SIMEDC reports reliability metrics of an erasure-coded data center based on the configurable inputs of the data center topology, erasure codes, redundancy placement, and failure/repair patterns of different subsystems obtained from statistical models or production traces. It can further accelerate the simulation analysis via importance sampling. Our simulation analysis based on SIMEDC shows that placing erasure-coded data in fewer racks generally improves reliability by reducing cross-rack repair traffic, even though it sacrifices rack-level fault tolerance in the face of correlated failures.},
  langid = {english},
  keywords = {CUHK📕,Reading🌟},
  file = {F\:\\Zotero文献数据\\storage\\9HMIKTCA\\Zhang et al_2019_SimEDC.pdf}
}
% == BibTeX quality report for zhangSimEDCSimulatorReliability2019:
% ? Title looks like it was stored in title-case in Zotero
% ? unused Library catalog ("Zotero")

@article{zhangYiGeBanJianDuXueXiDeJinRongXinWenWenBenFenLeiSuanFa,
  title = {{一个半监督学习的金融新闻文本分类算法}},
  author = {张, 晓龙 and 支, 龙 and 高, 剑 and 苗, 仲辰 and 林, 越峰 and 项, 雅丽 and 熊, 贇},
  journal = {大数据},
  pages = {1--12},
  issn = {2096-0271},
  abstract = {对金融文本进行分类是一项常见的用于识别金融风险的任务。传统的金融新闻文本分类方法需要大量的已知类别文本来训练分类器，然而标注金融新闻文本标签不仅需要专业的金融背景知识，且耗时耗力。为了减少对已知类别文本的依赖，提出了一个基于半监督学习的金融文本分类算法，该算法采用有监督学习和无监督学习的一致性训练方式，以更好地利用未知类别的文本数据；针对金融领域文本引入无监督数据增强方法，即对特定任务使用特定目标的数据增强方法，以产生更有效的数据。在多个金融文本数据集上开展的实验证明，相比其他文本分类算法，提出的算法在有效性上有明显提升。},
  langid = {chinese},
  keywords = {finance,natural language processing,semi-supervised learning,text classification,中文🌈,半监督学习,文本分类,自然语言处理,金融},
  file = {F\:\\Zotero文献数据\\storage\\4XG8UINA\\张 et al_一个半监督学习的金融新闻文本分类算法.pdf}
}
% == BibTeX quality report for zhangYiGeBanJianDuXueXiDeJinRongXinWenWenBenFenLeiSuanFa:
% Missing required field 'year'
% ? unused Library catalog ("CNKI")
% ? unused Url ("https://t.cnki.net/kcms/detail?v=DTzs9WqFju-35C3B-IQdAbXVDo7qdDMFtX10DUmeovKAG14mP_05FvvBX1HQnomO3E4wMIj9l6tNO-BSDydENrti8gbZ0Pw-glYSt7ZViv5oQSQFeSQSqw==&uniplatform=NZKPT")

@article{zhangYunCunChuXiTongZhongDeYuCeShiJuBuXiuFuMa2019,
  title = {{云存储系统中的预测式局部修复码}},
  author = {张, 晓阳 and 许, 佳豪 and 胡, 燏翀},
  year = {2019},
  journal = {计算机研究与发展},
  volume = {56},
  number = {09},
  pages = {1988--2000},
  issn = {1000-1239},
  abstract = {为了保证客户访问数据的高可用性,一些云存储系统开始采用一类新型编码,即局部修复编码(locally repairable codes, LRC).例如Windows Azure和Facebook的HDFS RAID.与Reed-Solomon码相比,LRC修复效率高,因为它将每个条带的数据块分成多个组,每个组内额外生成一个校验块,因而组内就可以对单个故障块进行修复.LRC假设每组大小相同,这意味着每个故障块的修复所产生的组内数据传输量是相同的.但是,对于那些更易出现故障的磁盘,它们所造成丢失的数据块理应被系统更有效地修复.借助基于决策树的磁盘故障预测方法来动态调整LRC中组的大小,从而构造一类预测式LRC(proactive LRC, pLRC),使得即将发生故障的磁盘存储的数据块所在的组的长度变小,以便这些数据块可以在更小的组内进行更快地修复,同时保持和传统LRC相同的存储开销和编码结构.不仅通过MTTDL建模分析pLRC的可靠性,还在Facebook的Hadoop HDFS平台中实现了pLRC并进行了性能测试.结果表明,比起LRC,pLRC的可靠性最多可提升113\%,同时降级读和磁盘修复性能最多可提高46.8\%和47.5\%.},
  langid = {chinese},
  keywords = {decision tree,disk failures,locally repairable codes(LRC),machine learning,中文🌈,云存储,决策树 cloud storage,局部修复码,机器学习,磁盘故障},
  annotation = {3 citations(CNKI)[2021-07-19]{$<$}北大核心, EI, CSCD{$>$}},
  file = {F\:\\Zotero文献数据\\storage\\QTTA3RFG\\张 et al_2019_云存储系统中的预测式局部修复码.pdf}
}
% == BibTeX quality report for zhangYunCunChuXiTongZhongDeYuCeShiJuBuXiuFuMa2019:
% ? unused Library catalog ("CNKI")
% ? unused Url ("https://kns.cnki.net/KCMS/detail/detail.aspx?dbcode=CJFD&dbname=CJFDLAST2019&filename=JFYZ201909020&v=")

@phdthesis{zhongYiGouCunChuXiTongZhongDeJiuShanMaShuJuXiuFuJiShuYanJiu2019,
  type = {{硕士}},
  title = {{异构存储系统中的纠删码数据修复技术研究}},
  author = {钟, 凤艳},
  year = {2019},
  abstract = {在大规模分布式存储系统中,由于节点数目规模庞大且单个节点可靠性不高,致使存储节点失效事件频发。为了确保数据的高可靠性和高可用性,云存储系统必须采取一定的数据冗余技术。纠删码容错技术因具有可靠性高和存储空间开销低等优点对提高分布式存储系统的数据可靠性、降低经济成本具有重大意义。目前针对纠删码的冗余数据放置和数据修复研究大多无差别对待每个存储节点,然而真实的分布式存储系统中节点一般存在存储成本、传输成本等方面的差异性,这些资源的异构性对系统的存储成本开销和数据修复的通信成本开销影响很大。针对纠删码数据放置存储成本开销高以及数据修复通信开销高等问题,本文对纠删码的低存储成本数据放置技术和低通信开销数据修复技术进行了研究,主要研究内容与贡献如下:对于纠删码随机放置数据技术中存在系统存储成本高的问题,提出了基于成本感知的数据放置算法。研究内容主要包括:首先,对系统存储成本的建模分析,把优化系统存储成本的问题转化为一个线性规划问题,并提出了算法CPA来解决这个问题,CPA算法在选择存储节点时,同时考虑了节点的可靠性,选取存储成本低且可靠性高的节点作为存储节点,按照存储成本由低到高的顺序排序,依据节点的存储成本放置不等量数据;最后,对分布式存储系统的副本放置技术、传统纠删码的放置技术和CPA进行仿真比较和数值分析,实验结果表明,CPA能够有效地降低系统的存储成本39\%至42\%。对于纠删码数据修复过程中忽略节点传输成本而传输等量数据的修复方式存在修复代价高的问题,即通信代价高的问题。在储存量异构场景下考虑了传输成本的差异性,提出了存储量异构场景下的纠删码树型修复过程,以优化纠删码数据修复的通信开销。研究内容主要包括:首先对系统的通信代价建模分析;其次,提出供应节点组合选择算法OpNTree,该算法依据链路传输成本与其上数据的传输量选择供应节点,并构建树型修复过程,从而降低数据修复的通信开销;最后,比较了传统再生码的星型修复方法、IFR码的修复方法和OpNTree,大量的模拟实验结果表明,对比于现有的星型修复方法和IFR码的无编码修复方法,OpNTree可将再生码数据修复的通信代价降低30\%-45\%。},
  collaborator = {王, 艳},
  langid = {chinese},
  school = {华东交通大学},
  keywords = {data placement,erasure code,failure recovery,node heterogeneity,storage cost,transmission cost,传输成本,分布式存储,存储成本,数据修复 distributed storage,数据放置,硕士🎓,纠删码,节点异构},
  file = {F\:\\Zotero文献数据\\storage\\SI887QW6\\异构存储系统中的纠删码数据修复技术研究_钟凤艳.caj}
}
% == BibTeX quality report for zhongYiGouCunChuXiTongZhongDeJiuShanMaShuJuXiuFuJiShuYanJiu2019:
% ? unused Library catalog ("CNKI")
% ? unused Url ("https://kns.cnki.net/KCMS/detail/detail.aspx?dbcode=CMFD&dbname=CMFD202102&filename=1019605160.nh&v=")

@article{zhongYiGouHuanJingXiaJiuShanMaDeShuJuXiuFuFangFaZongShu2019,
  title = {{异构环境下纠删码的数据修复方法综述}},
  author = {钟, 凤艳 and 王, 艳 and 李, 念爽},
  year = {2019},
  journal = {计算机应用研究},
  volume = {36},
  number = {8},
  pages = {2241-2249+2255},
  issn = {1001-3695},
  doi = {10.19734/j.issn.1001-3695.2018.04.0269},
  abstract = {在大规模云存储系统中,由于磁盘或网络故障造成的存储节点失效事件频发,系统需要数据冗余技术以保证数据的可靠性和可用性。目前针对纠删码的冗余数据修复研究大多是无差别地对待每个存储节点,然而在实际分布式存储系统中,节点通常在带宽资源、计算资源、存储容量资源等方面存在差异性,这些资源的异构性对冗余数据修复性能影响很大。指出了影响修复性能的关键因素,选取带宽开销、磁盘访问开销、修复时间、参与修复的节点数量和修复代价作为修复性能的评价标准;分析了现有研究方法如何降低这五种开销,重点讨论了这些方法的优缺点;阐述了当前异构分布式存储系统中纠删码修复技术的研究现状,并指出了纠删码数据修复技术中尚未解决的一些难题和未来纠删码修复技术可能的发展方向。},
  langid = {chinese},
  keywords = {data recovery,erasure code,heterogeneity,performance improvement,可看🎈,存储系统,异构,性能优化 storage systems,数据修复,纠删码},
  annotation = {4 citations(CNKI)[2022-2-23]{$<$}北大核心, CSCD{$>$}},
  file = {F\:\\Zotero文献数据\\storage\\Y3TSJD2U\\钟 et al_2019_异构环境下纠删码的数据修复方法综述.pdf}
}
% == BibTeX quality report for zhongYiGouHuanJingXiaJiuShanMaDeShuJuXiuFuFangFaZongShu2019:
% ? unused Library catalog ("CNKI")
% ? unused Url ("https://kns.cnki.net/KCMS/detail/detail.aspx?dbcode=CJFD&dbname=CJFDLAST2019&filename=JSYJ201908001&v=")

@article{zhou,
  title = {Multi-Level Forwarding and Scheduling Recovery Algorithm in Rapidly-Changing Network for Erasure-Coded Clusters},
  author = {Zhou, Hai and Feng, Dan and Hu, Yuchong},
  pages = {11},
  abstract = {A key design goal of erasure-coded clusters is to reduce the repair time. The existing Erasure-coded data repair schemes are roughly classified into two categories: 1. Designing rapid data repair (e.g., PPR) in a homogeneous environment. 2. Constructing data repair (e.g., PPT) based on bandwidth in a heterogeneous environment. However, these solutions are difficult to cope with the heterogeneous and Rapidly-changing network in erasure-coded clusters. To address this problem, a bandwidth-aware multi-level forwarding repair algorithm, called BMFRepair, is proposed. BMFRepair monitors the network bandwidth in real time when data is forwarded, and selects idle nodes with high-bandwidth links to assist in forwarding. Thus, it can reduce the time bottleneck caused by low link transmission. At the same time, multi-node repair becomes very complicated when the bandwidth changes drastically. A multi-node scheduling repairing algorithm, called MSRepair, is proposed for multi-node repairing problems, which can repair multiple failed blocks in parallel by scheduling node resources. The two algorithms can flexibly adapt to the rapidly changing network environment and make full use of the bandwidth resources of idle nodes. Most importantly, algorithms can continuously adjust the repair plan according to the bandwidth change in fast and dynamic network. The algorithms have been evaluated by both simulations on Mininet and real experiments on Aliyun cloud platform ECS. Results show that compared with the state-of-the-art repair schemes PPR and PPT, the algorithms can significantly reduce the repair time in rapidly-changing network.},
  langid = {english},
  keywords = {Reading🌟},
  file = {F\:\\Zotero文献数据\\storage\\9AGVGLCX\\Zhou et al_Multi-level forwarding and scheduling recovery algorithm in rapidly-changing.pdf}
}
% == BibTeX quality report for zhou:
% Missing required field 'journal'
% Missing required field 'year'
% ? unused Library catalog ("Zotero")

@article{zhouFastErasureCoding2020,
  title = {Fast {{Erasure Coding}} for {{Data Storage}}: {{A Comprehensive Study}} of the {{Acceleration Techniques}}},
  shorttitle = {Fast {{Erasure Coding}} for {{Data Storage}}},
  author = {Zhou, Tianli and Tian, Chao},
  year = {2020},
  month = feb,
  journal = {ACM Transactions on Storage},
  volume = {16},
  number = {1},
  pages = {1--24},
  issn = {1553-3077, 1553-3093},
  doi = {10.1145/3375554},
  abstract = {Various techniques have been proposed in the literature to improve erasure code computation efficiency, including optimizing bitmatrix design and computation schedule, common XOR (exclusive-OR) operation reduction, caching management techniques, and vectorization techniques. These techniques were largely proposed individually, and, in this work, we seek to use them jointly. To accomplish this task, these techniques need to be thoroughly evaluated individually and their relation better understood. Building on extensive testing, we develop methods to systematically optimize the computation chain together with the underlying bitmatrix. This led to a simple design approach of optimizing the bitmatrix by minimizing a weighted computation cost function, and also a straightforward coding procedure\textemdash follow a computation schedule produced from the optimized bitmatrix to apply XOR-level vectorization. This procedure provides better performances than most existing techniques (e.g., those used in ISA-L and Jerasure libraries), and sometimes can even compete against well-known but less general codes such as EVENODD, RDP, and STAR codes. One particularly important observation is that vectorizing the XOR operations is a better choice than directly vectorizing finite field operations, not only because of the flexibility in choosing finite field size and the better encoding throughput, but also its minimal migration efforts onto newer CPUs.},
  langid = {english},
  keywords = {可看🎈},
  file = {F\:\\Zotero文献数据\\storage\\MYMDIX73\\Zhou 和 Tian - 2020 - Fast Erasure Coding for Data Storage A Comprehens.pdf}
}
% == BibTeX quality report for zhouFastErasureCoding2020:
% ? Title looks like it was stored in title-case in Zotero
% ? unused Journal abbreviation ("ACM Trans. Storage")
% ? unused Library catalog ("DOI.org (Crossref)")
% ? unused Url ("https://dl.acm.org/doi/10.1145/3375554")

@article{zhouJiYuTeZhengXuanZeDeJuBuMinGanHaXiWeiXuanZeSuanFa,
  title = {{基于特征选择的局部敏感哈希位选择算法}},
  author = {周, 文桦 and 刘, 华文 and 李, 恩慧},
  journal = {大数据},
  pages = {1--12},
  issn = {2096-0271},
  abstract = {局部敏感哈希是目前主流的信息检索方法之一。但局部敏感哈希需要生成较长的哈希位才能达到检索要求。然而，使用较长的哈希位需要巨大的存储空间和高额的计算成本。因此，如何生成简短、信息量丰富的哈希位成为哈希学习中的研究热点。目前已有的很多哈希算法均致力于设计哈希函数来生成哈希位，却忽略了已生成哈希位中的冗余情况。为了解决此问题，本文首次采用特征工程中10种简单、高效的选择方式从局部敏感哈希所生成的哈希位中提取信息量最大的哈希位，并将其与初始长度的哈希位进行比较。在4个常用数据集上的实验结果表明，选择后的哈希位与原哈希位的性能几乎相同，且其约简比率能达到20\%至60\%。},
  langid = {chinese},
  keywords = {approximate nearest neighbor search,dimensionality reduction,feature selection,hash bit selection,hashing learning,中文🌈,哈希位选择,哈希学习,特征选择,近似近邻搜索,降维},
  file = {F\:\\Zotero文献数据\\storage\\JNZ7YB3M\\周 et al_基于特征选择的局部敏感哈希位选择算法.pdf}
}
% == BibTeX quality report for zhouJiYuTeZhengXuanZeDeJuBuMinGanHaXiWeiXuanZeSuanFa:
% Missing required field 'year'
% ? unused Library catalog ("CNKI")
% ? unused Url ("https://t.cnki.net/kcms/detail?v=DTzs9WqFju9e3g-9JAzXJn4whcC87L7oOXZn5Jk0uvJp4Wyuk9J1Wn6xoBkpYm5Z_qZcKjIUSfSFO9r0L9urSGfewaCfUoWMm5JKZmsCyjMIUdy5yUgUWg==&uniplatform=NZKPT")

@article{zhouKuaiSuXiangYingDeGaoXiaoDuoZhiBaiZhanTingGongShiFangAn2021,
  title = {{快速响应的高效多值拜占庭共识方案}},
  author = {周, 旺 and 胡, 红钢 and 俞, 能海},
  year = {2021},
  journal = {网络与信息安全学报},
  volume = {7},
  number = {01},
  pages = {57--64},
  issn = {2096-109X},
  abstract = {由于网络设备的增多和传输环境的不确定性,消息时延同样具有不确定性,异步共识协议发挥出更多优势。Miller等于2016年提出第一个异步共识协议HoneyBadgerBFT,但其在实现高吞吐量的同时传输效率依然可以再优化。针对HoneyBadgerBFT中的广播协议进行改进,减少广播过程中的消息复杂度,同时增加可选的消息请求过程,以达到快速响应和高效传输的效果。},
  langid = {chinese},
  keywords = {Byzantine protocol,consensus scheme,efficient transmission,中文🌈,共识方案 rapid response,快速响应,拜占庭协议,网络与信息安全学报🌊,高传输效率},
  file = {F\:\\Zotero文献数据\\storage\\2LGMWP6U\\周 et al_2021_快速响应的高效多值拜占庭共识方案.pdf}
}
% == BibTeX quality report for zhouKuaiSuXiangYingDeGaoXiaoDuoZhiBaiZhanTingGongShiFangAn2021:
% ? unused Library catalog ("CNKI")
% ? unused Url ("https://kns.cnki.net/KCMS/detail/detail.aspx?dbcode=CJFD&dbname=CJFDLAST2021&filename=WXAQ202101006&v=")

@article{zhuFenBuShiCunChuXiTongZhongJiuShanMaShuJuXiuFuSuanFaYouHuaYuShiXian2020,
  title = {{分布式存储系统中纠删码数据修复算法优化与实现}},
  author = {朱, 盼盼 and 张, 彤 and 郑, 宇宁 and 李, 姝},
  year = {2020},
  journal = {计算机应用研究},
  volume = {37},
  number = {S1},
  pages = {140--142},
  issn = {1001-3695},
  abstract = {网络每天都会产生海量的数据,人们已然迈入了海量数据时代。分布式存储系统为了保障数据的可靠性采用数据容错技术,多副本技术和纠删码技术是最常用的数据容错技术。多副本技术因其修复简单而应用广泛,但是随着数据的增多,企业将无法承受多副本技术带来的高额存储成本。纠删码技术在达到与多副本技术相同数据可靠性的同时,可以有效地降低数据存储消耗。为了提高纠删码的修复速度,提出了基于带宽和网络距离的最优生成树算法,在选择出节点的同时,提高了纠删码修复的速度。},
  langid = {chinese},
  keywords = {⛔ No DOI found,修复模型,分布式存储系统,可看🎈,数据修复,纠删码},
  annotation = {1 citations(CNKI)[2022-2-18]{$<$}北大核心, CSCD{$>$}},
  file = {F\:\\Zotero文献数据\\storage\\KYYU7DSW\\分布式存储系统中纠删码数据修复算法优化与实现_朱盼盼.pdf}
}
% == BibTeX quality report for zhuFenBuShiCunChuXiTongZhongJiuShanMaShuJuXiuFuSuanFaYouHuaYuShiXian2020:
% ? unused Library catalog ("CNKI")
% ? unused Url ("https://kns.cnki.net/KCMS/detail/detail.aspx?dbcode=CJFD&dbname=CJFDLAST2020&filename=JSYJ2020S1047&v=")

@article{zhuOnlineCodeRate,
  title = {Online {{Code Rate Adaptation}} in {{Cloud Storage Systems}} with {{Multiple Erasure Codes}}},
  author = {Zhu, Rui and Niu, Di and Li, Zongpeng},
  pages = {6},
  abstract = {Erasure codes have been adopted for cloud storage systems. While achieving higher reliability at lower storage overhead as compared to replication, erasure codes usually incur high reading cost when recovering an unavailable block. Although local reconstruction code constructions have been proposed to reduce recovery cost, additional benefits can be achieved by adopting erasure codes with different code rates for data blocks with different popularity. In this paper, we study the problem of code rate selection and adaptation in cloud storage systems that adopt multiple erasure codes via online learning. Unlike offline optimization, which requires the knowledge or estimation of future demands, the online learning algorithms can make decisions only based on past observations and dynamically adapt to demand changes. To avoid solving a hard integer program, we perform a stochastic relaxation to the formulated online learning problem and solve it using a exponentiated gradient algorit{$\surd$}hm, resulting in sparse solutions. We show a regret bound of O( T ) of the proposed algorithm by showing that our algorithm is a special case of the FTRL online learning framework. Through trace-driven simulations based on real request traces from Windows Azure Storage, we show that our online algorithm performs close to the best fixed offline policy, and trades off between recovery cost during degraded reads and storage overhead.},
  langid = {english},
  keywords = {AdaptiveCode🌏,Reading🌟},
  annotation = {00000},
  file = {F\:\\Zotero文献数据\\storage\\II5NRIMG\\Zhu et al_Online Code Rate Adaptation in Cloud Storage Systems with Multiple Erasure Codes.pdf}
}
% == BibTeX quality report for zhuOnlineCodeRate:
% Missing required field 'journal'
% Missing required field 'year'
% ? Title looks like it was stored in title-case in Zotero
% ? unused Library catalog ("Zotero")


% Required packages:
% * textcomp

